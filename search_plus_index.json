{"./":{"url":"./","title":"Introduction","keywords":"","body":"Java实用笔记 Devops Docker docker安装 docker实战1 docker实战3-运行和查看 docker实战4-挂载目录 docker实战5-曲线拉取国外镜像 Jenkins Jenkins全局工具配置 Kettle kettle数据同步技术攻克 Maven maven打包 maven命令行推送jar包 maven引入lib文件夹下jar包并且打包 maven更改版本号 maven私服配置并且推送jar包 Redis redis在windows下安装 Uml 建模工具plantuml介绍 运维 window端口占用查询 Elasticsearch es实战 es实战1-常见命令 es实战2-查询命令 es实战3-综合查询案例 es实战4-java常见查询实例 es实战5-聚合分组查询案例 es实战6-springboot2.0集成elasticsearch6 es实战7-elasticsearch实现springboot自动配置 es知识点 Elasticsearch学习 和Elasticsearch交互 Java Java 8 java8新特性 Spring spring事件 Swagger 更改swagger上下文 Util Http RestTemplate用法 Json json序列化和反序列化工具 日志 logback日志文件配置 Xxl Job xxl-job定时任务教程 数据源 动态数据源 缓存 Guava guava缓存简单使用三部曲 Micro Service Rabbitmq rabbitmq学习 Springboot springboot整合hikari数据源 springboot整合log4j打印mybatis的sql日志 springboot整合redisTemplate 文档管理 japidoc文档管理 配置中心 Appollo apollo客户端配置使用.md Nacos nacos-spring-cloud学习 nacos安装和入门学习 限流 Sentinel 基础 sentinel学习 sentinel通过spi方式注册数据源 控制台 sentinel控制台 源码分析 SentinelResource注解源码分析 sentinel命名空间namespace分析 集群流控 sentinel集群流控 sentinel集群流控之配置说明 sentinel集群流控-ServerTransportConfig sentinel集群流控之TransportConfig sentinel集群流控-ClusterClientAssignConfig sentinel集群流控之心跳检测 Python python入门 python小牛试刀-获取微信关注用户信息 中间件 Mybatis Plus mybatis-plus生成器相关问题 Redis redis和redisson自动装配 Shardingsphere sharding-jdbc实现读写分离 Spring spring-core工具包 前端 Angular angular基础 angular-generate命令 jquery基础 jquery按钮用法 Json 前端json字符串和js对象转换 Node node学习 Vue vue待学习 后台模板 ngx-admin后台模板学习 弹窗 Layer layer弹窗 博客 Gitbook gitbook教程 Hugo hugo教程 各种问题 Http http400问题 http415问题 Java 指针引用问题和List删除元素 Springboot springboot排除数据源自动装配失效问题 springboot日志问题 springboot配置属性DataSource问题 前端 form表单序列化后中文乱码问题 单元测试 单元测试获取不到数据库连接问题 定时任务 xxl-job打印日志问题 配置 redisTemplate配置问题 开发工具 Excel excel拼接字符串 Git git打tag git提交注释规范 git新建项目常见操作 Idea idea-git操作 idea中文乱码 idea快捷键 idea插件 ieda快捷生成代码 模板引擎 freemarker模板语法 常见工具 数据库 Mysql mysql版本升级 Oracle oracle常见查询语句 Postgres postgres创建序列 导数据 导出数百万级别数据 "},"devops/docker/docker-install.html":{"url":"devops/docker/docker-install.html","title":"docker安装","keywords":"","body":"CentOS 7 (使用yum进行安装) # step 1: 安装必要的一些系统工具 sudo yum install -y yum-utils device-mapper-persistent-data lvm2 # Step 2: 添加软件源信息 sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # Step 3: 更新并安装 Docker-CE sudo yum makecache fast sudo yum -y install docker-ce # Step 4: 开启Docker服务 sudo service docker start # 注意： # 官方软件源默认启用了最新的软件，您可以通过编辑软件源的方式获取各个版本的软件包。例如官方并没有将测试版本的软件源置为可用，你可以通过以下方式开启。同理可以开启各种测试版本等。 # vim /etc/yum.repos.d/docker-ee.repo # 将 [docker-ce-test] 下方的 enabled=0 修改为 enabled=1 # # 安装指定版本的Docker-CE: # Step 1: 查找Docker-CE的版本: # yum list docker-ce.x86_64 --showduplicates | sort -r # Loading mirror speeds from cached hostfile # Loaded plugins: branch, fastestmirror, langpacks # docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable # docker-ce.x86_64 17.03.1.ce-1.el7.centos @docker-ce-stable # docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable # Available Packages # Step2 : 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.0.ce.1-1.el7.centos) # sudo yum -y install docker-ce-[VERSION] docker阿里安装 https://yq.aliyun.com/articles/110806 将docker加入随主机自启动列表：sudo chkconfig docker on [root@localhost hoby]# sudo chkconfig docker on Note: Forwarding request to 'systemctl enable docker.service'. Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service. [root@localhost hoby]# "},"devops/docker/docker实战1.html":{"url":"devops/docker/docker实战1.html","title":"docker实战1","keywords":"","body":" 运行docker cd /opt/zch docker build . --tag=\"tobe/pc-admin-web:v1.0.0\" docker run -d -p 9096:9096 -v /usr/local/logs/:/opt/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 firewall-cmd --zone=public --add-port=9096/tcp --permanent firewall-cmd --reload docker ps 拉取镜像 命令格式为： docker pull [选项] [Docker Registry地址]: Docker Registry地址：地址的格式一般是 [:端口号]。默认地址是 Docker Hub。 例如： docker pull ubuntu:14.04 公司的: docker pull 192.168.1.1/tobe/java:8-jre 镜像构建 docker build 命令进行镜像构建。其格式为： docker build [选项] $ docker build -t nginx:v3 . 在这里我们指定了最终镜像的名称 -t nginx:v3 ，构建成功后，我们可以像之前运行 nginx:v2 那样来运行这个镜像，其结果会和 nginx:v2 一样。 镜像运行 docker run --name web2 -d -p 81:80 nginx:v2 这里我们命名为新的服务为 web2 ，并且映射到 81 端口。如果是 Docker for Mac/Windows 或 Linux 桌面的话，我们就可以直接访问 http://localhost:81 看到结果，其内容应该和之前修 改后的 webserver 一样。 docker run --name webserver -d -p 80:80 nginx 这条命令会用 nginx 镜像启动一个容器，命名为 webserver ，并且映射了 80 端口，这样我 们可以用浏览器去访问这个 nginx 服务器。 Docker重命名镜像名称和TAG # docker tag IMAGEID(镜像id) REPOSITORY:TAG（仓库：标签） [root@localhost hoby]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE dohoby/kubernetes 3.1.12 0c14773001c8 16 minutes ago 193MB [root@localhost hoby]# docker tag 0c14773001c8 k8s.gcr.io/etcd-amd64:3.1.12 [root@localhost hoby]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE dohoby/kubernetes 3.1.12 0c14773001c8 16 minutes ago 193MB k8s.gcr.io/etcd-amd64 3.1.12 0c14773001c8 16 minutes ago 193MB "},"devops/docker/docker实战3-运行和查看.html":{"url":"devops/docker/docker实战3-运行和查看.html","title":"docker实战3-运行和查看","keywords":"","body":" Dockerfile FROM java:8-jre MAINTAINER tobe ADD pc-admin-web.jar /usr/local/tobe/pc/ CMD [\"java\", \"-Xms500m\", \"-Xmx1024m\", \"-jar\", \"/usr/local/tobe/pc/pc-admin-web.jar\"] EXPOSE 8080 运行docker步骤 cd /opt/zch docker build . --tag=\"tobe/pc-admin-web:v1.0.0\" docker run -d -p 8080:8080 -v /usr/local/logs/:/opt/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 注：经实战，发现必须配置成8080:8080，而且Dockfile文件里也是8080才能访问 问题1：-v是挂载宿主主机的目录，实战发现那个目录下没有日志文件， 问题2：删除容器和重新docker run都发现项目接口没有更新，是不是只能重新build个镜像 docker run -d -p 8080:8080 -v /usr/local/logs/:/var/lib/docker/containers/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 docker run -d -p 8080:8080 -v /usr/local/logs/:/opt/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 开放防火墙 firewall-cmd --zone=public --add-port=9096/tcp --permanent firewall-cmd --reload 查看容器 docker ps -a 查看日志 docker logs -f 容器名，用docker ps查看，比如 docker logs -f pc-admin-web-1.0.0 docker logs -f fullfilment --tail=500 访问： curl -v http://172.16.17.250:8080/swagger-ui.html 删除容器 删除容器 docker rmi 容器id 停止所有容器（删除容器才能删除images）： docker stop $(docker ps -a -q) 删除所有容器： docker rm $(docker ps -a -q) 删除镜像 删除images docker rmi 删除untagged images，也就是那些id为的image docker rmi $(docker images | grep \"^\" | awk \"{print $3}\") 删除全部image docker rmi $(docker images -q) Linux上tobe项目做的操作 vi pc-admin-web/src/main/resources/application.yaml cp pc-admin-web/target/pc-admin-web.jar /opt/zch 下面的是实战，可以不看 docker build [root@localhost zch]# pwd /opt/zch [root@localhost zch]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hello-world latest 05a3bd381fc2 7 weeks ago 1.84kB 192.168.1.1/tobe/java 8-jre e44d62cf8862 9 months ago 311MB [root@localhost zch]# docker build . --tag=\"tobe/pc-admin-web:v1.0.0\" Sending build context to Docker daemon 32.74MB Step 1/5 : FROM java:8-jre 8-jre: Pulling from library/java Digest: sha256:b91008e234402fc87e7889d6af1f36b6ece844c05989236d83d1f658a6f329b0 Status: Downloaded newer image for java:8-jre ---> e44d62cf8862 Step 2/5 : MAINTAINER tobe ---> Running in bd1e3b4e96c1 ---> 77598a1df94a Removing intermediate container bd1e3b4e96c1 Step 3/5 : ADD pc-admin-web.jar /usr/local/tobe/pc/ ---> 31ce18cf19af Step 4/5 : CMD java -Xms500m -Xmx1024m -jar /usr/local/tobe/pc/pc-admin-web.jar ---> Running in d68f92bec092 ---> 75c9a968da39 Removing intermediate container d68f92bec092 Step 5/5 : EXPOSE 9096 ---> Running in 219782caa18b ---> 1bd7a778ba13 Removing intermediate container 219782caa18b Successfully built 1bd7a778ba13 Successfully tagged tobe/pc-admin-web:v1.0.0 [root@localhost zch]# 看下面的，看到最终构建的是上面运行docker中的 docker build . --tag=\"tobe/pc-admin-web:v1.0.0\" 这个命令打的tag标签,如果上面命令报错，尝试把逗号放最后:分号前面对应REPOSITORY，分号后面对应TAG [root@localhost zch]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE tobe/pc-admin-web v1.0.0 1bd7a778ba13 4 minutes ago 344MB hello-world latest 05a3bd381fc2 7 weeks ago 1.84kB 192.168.1.1/tobe/java 8-jre e44d62cf8862 9 months ago 311MB java 8-jre e44d62cf8862 9 months ago 311MB [root@localhost zch]# docker run： [root@localhost zch]# docker run -d -p 9096:9096 -v /usr/local/logs/:/opt/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 f9a08bb82e2650bebed3eb3185a383ec121114ce3ef79ee2166d7a46329ced85 [root@localhost zch]# 经实战，发现必须配置成8080:8080，而且Dockfile文件里也是8080才能访问 docker run -d -p 8080:8080 -v /usr/local/logs/:/opt/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 [root@localhost zch]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f9a08bb82e26 tobe/pc-admin-web:v1.0.0 \"java -Xms500m -Xm...\" 2 minutes ago Up 2 minutes pc-admin-web-1.0.0 [root@localhost zch]# [root@localhost zch]# firewall-cmd --zone=public --add-port=9096/tcp --permanent FirewallD is not running [root@localhost zch]# firewall-cmd --reload FirewallD is not running [root@localhost zch]# 移除容器和镜像 http://www.cnblogs.com/q4486233/p/6482711.html 1.停止所有的container，这样才能够删除其中的images： docker stop $(docker ps -a -q) 如果想要删除所有container的话再加一个指令： docker rm $(docker ps -a -q) 2.查看当前有些什么images docker images 3.删除images，通过image的id来指定删除谁 docker rmi 想要删除untagged images，也就是那些id为的image的话可以用 docker rmi $(docker images | grep \"^\" | awk \"{print $3}\") 要删除全部image的话 docker rmi $(docker images -q) 实战 命令必须加-a才会显示容器出来 ， docker ps -a 查询出来用下面命令删除某个容器 docker rm 容器id [root@localhost zch]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 11b8d5b0a241 tobe/pc-admin-web:v1.0.0 \"java -Xms500m -Xm...\" 2 days ago Exited (143) 5 minutes ago pc-admin-web-1.0.0 [root@localhost zch]# docker rm 11b8d5b0a241 11b8d5b0a241 [root@localhost zch]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 查看日志 docker logs -f pc-admin-web-1.0.0 "},"devops/docker/docker实战4-挂载目录.html":{"url":"devops/docker/docker实战4-挂载目录.html","title":"docker实战4-挂载目录","keywords":"","body":" 查看容器的详细信息 docker inspect 容器id [root@localhost zch]# docker inspect 65db9b511573 [ { \"Id\": \"65db9b511573294c25d5ab42e7f9f14c44b12d562037d111b6a385d43c2f0fa1\", \"Created\": \"2017-11-06T01:32:39.592582918Z\", \"Path\": \"java\", \"Args\": [ \"-Xms500m\", \"-Xmx1024m\", \"-jar\", \"/usr/local/tobe/pc/pc-admin-web.jar\" ], \"State\": { \"Status\": \"running\", \"Running\": true, \"Paused\": false, \"Restarting\": false, \"OOMKilled\": false, \"Dead\": false, \"Pid\": 4042, \"ExitCode\": 0, \"Error\": \"\", \"StartedAt\": \"2017-11-06T01:32:39.729399639Z\", \"FinishedAt\": \"0001-01-01T00:00:00Z\" }, \"Image\": \"sha256:d7f0891abbd7a77169fa646ab1da8778ee15643a64322b982bf512b01fd080d0\", \"ResolvConfPath\": \"/var/lib/docker/containers/65db9b511573294c25d5ab42e7f9f14c44b12d562037d111b6a385d43c2f0fa1/resolv.conf\", \"HostnamePath\": \"/var/lib/docker/containers/65db9b511573294c25d5ab42e7f9f14c44b12d562037d111b6a385d43c2f0fa1/hostname\", \"HostsPath\": \"/var/lib/docker/containers/65db9b511573294c25d5ab42e7f9f14c44b12d562037d111b6a385d43c2f0fa1/hosts\", \"LogPath\": \"/var/lib/docker/containers/65db9b511573294c25d5ab42e7f9f14c44b12d562037d111b6a385d43c2f0fa1/65db9b511573294c25d5ab42e7f9f14c44b12d562037d111b6a385d43c2f0fa1-json.log\", \"Name\": \"/pc-admin-web-1.0.0\", \"RestartCount\": 0, \"Driver\": \"overlay\", \"Platform\": \"linux\", \"MountLabel\": \"\", \"ProcessLabel\": \"\", \"AppArmorProfile\": \"\", \"ExecIDs\": null, \"HostConfig\": { \"Binds\": [ \"/usr/local/logs/:/opt/\" ], \"ContainerIDFile\": \"\", \"LogConfig\": { \"Type\": \"json-file\", \"Config\": {} }, \"NetworkMode\": \"host\", \"PortBindings\": { \"8080/tcp\": [ { \"HostIp\": \"\", \"HostPort\": \"8080\" } ] }, \"RestartPolicy\": { \"Name\": \"no\", \"MaximumRetryCount\": 0 }, \"AutoRemove\": false, \"VolumeDriver\": \"\", \"VolumesFrom\": null, \"CapAdd\": null, \"CapDrop\": null, \"Dns\": [], \"DnsOptions\": [], \"DnsSearch\": [], \"ExtraHosts\": null, \"GroupAdd\": null, \"IpcMode\": \"\", \"Cgroup\": \"\", \"Links\": null, \"OomScoreAdj\": 0, \"PidMode\": \"\", \"Privileged\": false, \"PublishAllPorts\": false, \"ReadonlyRootfs\": false, \"SecurityOpt\": null, \"UTSMode\": \"\", \"UsernsMode\": \"\", \"ShmSize\": 67108864, \"Runtime\": \"runc\", \"ConsoleSize\": [ 0, 0 ], \"Isolation\": \"\", \"CpuShares\": 0, \"Memory\": 0, \"NanoCpus\": 0, \"CgroupParent\": \"\", \"BlkioWeight\": 0, \"BlkioWeightDevice\": [], \"BlkioDeviceReadBps\": null, \"BlkioDeviceWriteBps\": null, \"BlkioDeviceReadIOps\": null, \"BlkioDeviceWriteIOps\": null, \"CpuPeriod\": 0, \"CpuQuota\": 0, \"CpuRealtimePeriod\": 0, \"CpuRealtimeRuntime\": 0, \"CpusetCpus\": \"\", \"CpusetMems\": \"\", \"Devices\": [], \"DeviceCgroupRules\": null, \"DiskQuota\": 0, \"KernelMemory\": 0, \"MemoryReservation\": 0, \"MemorySwap\": 0, \"MemorySwappiness\": null, \"OomKillDisable\": false, \"PidsLimit\": 0, \"Ulimits\": null, \"CpuCount\": 0, \"CpuPercent\": 0, \"IOMaximumIOps\": 0, \"IOMaximumBandwidth\": 0 }, \"GraphDriver\": { \"Data\": { \"LowerDir\": \"/var/lib/docker/overlay/259ae4941ced45fa1397474685a29b680143b2017c59079aa4cc79360f2974f2/root\", \"MergedDir\": \"/var/lib/docker/overlay/f6fc30704f20c0538c159a9e388ddbde79696b0c841d2cf6ee3a57ec92b4210a/merged\", \"UpperDir\": \"/var/lib/docker/overlay/f6fc30704f20c0538c159a9e388ddbde79696b0c841d2cf6ee3a57ec92b4210a/upper\", \"WorkDir\": \"/var/lib/docker/overlay/f6fc30704f20c0538c159a9e388ddbde79696b0c841d2cf6ee3a57ec92b4210a/work\" }, \"Name\": \"overlay\" }, \"Mounts\": [ { \"Type\": \"bind\", \"Source\": \"/usr/local/logs\", \"Destination\": \"/opt\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" } ], \"Config\": { \"Hostname\": \"localhost.localdomain\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"ExposedPorts\": { \"8080/tcp\": {} }, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\", \"LANG=C.UTF-8\", \"JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre\", \"JAVA_VERSION=8u111\", \"JAVA_DEBIAN_VERSION=8u111-b14-2~bpo8+1\", \"CA_CERTIFICATES_JAVA_VERSION=20140324\" ], \"Cmd\": [ \"java\", \"-Xms500m\", \"-Xmx1024m\", \"-jar\", \"/usr/local/tobe/pc/pc-admin-web.jar\" ], \"ArgsEscaped\": true, \"Image\": \"tobe/pc-admin-web:v1.0.0\", \"Volumes\": null, \"WorkingDir\": \"\", \"Entrypoint\": null, \"OnBuild\": null, \"Labels\": {} }, \"NetworkSettings\": { \"Bridge\": \"\", \"SandboxID\": \"8ec994d4adf3a820ccfff026d220506e4fe28a1542f72321eac09319da4ec386\", \"HairpinMode\": false, \"LinkLocalIPv6Address\": \"\", \"LinkLocalIPv6PrefixLen\": 0, \"Ports\": {}, \"SandboxKey\": \"/var/run/docker/netns/default\", \"SecondaryIPAddresses\": null, \"SecondaryIPv6Addresses\": null, \"EndpointID\": \"\", \"Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"IPAddress\": \"\", \"IPPrefixLen\": 0, \"IPv6Gateway\": \"\", \"MacAddress\": \"\", \"Networks\": { \"host\": { \"IPAMConfig\": null, \"Links\": null, \"Aliases\": null, \"NetworkID\": \"dac528ad522ee4f3d29f73d3c8e25bf85891cedfd4d21e8a9f2cd6d573268b23\", \"EndpointID\": \"d8545b90b5730af9e28649144d3774a23a0b1d7d0a6f9b3fb14aab66b75bf795\", \"Gateway\": \"\", \"IPAddress\": \"\", \"IPPrefixLen\": 0, \"IPv6Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"MacAddress\": \"\", \"DriverOpts\": null } } } } ] [root@localhost zch]# 进入容器 -it 命令是以交互方式进入容器 [root@localhost zch]# docker run -it -p 8080:8080 -v /usr/local/logs/:/opt/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 /bin/bash 列出容器的目录 root@localhost:/# ls bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var root@localhost:/# 查看Dockerfile文件复制进去的jar包 Dockerfile文件中有句： ADD pc-admin-web.jar /usr/local/tobe/pc/ 查看 root@localhost:/# ls /usr/local/tobe/pc/ pc-admin-web.jar 检查挂载是否成功 docker run命令中有个参数，冒号前面是宿主主机的目录，冒号后面是容器的目录，是将宿主主机的目录挂载到容器的/opt/目录下， -v /usr/local/logs/:/opt/ 检查，在容器的/opt/目录下新建个a文件，然后到宿主主机上发现有个a文件,同样，在宿主主机新建个b文件，然后在容器里发现也有b文件 后台进程运行容器，如何进入容器 docker exec -i -t ea0928cfcad2 /bin/bash 从容器拷贝文件到宿主机 拷贝方式为： docker cp 容器名：容器中要拷贝的文件名及其路径 要拷贝到宿主机里面对应的路径 docker cp sp-comm:/logs/192.168.1.1mon/192.168.1.1mon.log . docker cp sp-comm:/logs/192.168.1.1mon/20180907/192.168.1.1mon.0.log.zip . 参考：https://blog.csdn.net/dongdong9223/article/details/71425077 "},"devops/docker/docker实战5-曲线拉取国外镜像.html":{"url":"devops/docker/docker实战5-曲线拉取国外镜像.html","title":"docker实战5-曲线拉取国外镜像","keywords":"","body":"创建镜像仓库 安装k8s需要很多镜像，这些镜像，若翻墙不了或者公司禁止上谷歌的镜像仓库，就没法获取，这里就需要曲线拉取镜像了， 如 [root@k8s-node-2 flannel]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE k8s.gcr.io/kube-proxy-amd64 v1.10.3 4261d315109d 2 weeks ago 97.1 MB k8s.gcr.io/kube-apiserver-amd64 v1.10.3 e03746fe22c3 2 weeks ago 225 MB k8s.gcr.io/kube-scheduler-amd64 v1.10.3 353b8f1d102e 2 weeks ago 50.4 MB k8s.gcr.io/kube-controller-manager-amd64 v1.10.3 40c8d10b2d11 2 weeks ago 148 MB k8s.gcr.io/etcd-amd64 3.1.12 52920ad46f5b 2 months ago 193 MB quay.io/coreos/flannel v0.10.0-amd64 f0fad859c909 4 months ago 44.6 MB k8s.gcr.io/pause-amd64 3.1 da86e6ba6ca1 5 months ago 742 kB docker.io/kubernetes/pause latest f9d5de079539 3 years ago 240 kB gcr.io/google_containers/pause-amd64 3.0 f9d5de079539 3 years ago 240 kB 根据上面所需要的镜像，制作Dockerfile，并且上传到github仓库，参考我的https://github.com/dohoby/kubernetes 制作镜像 https://hub.docker.com 登录此网站，参考：https://blog.csdn.net/sjyu_ustc/article/details/79990858 构建镜像 拉取镜像 新建拉取镜像脚本 #!/bin/bash images=(kube-apiserver-amd64:v1.10.3 kube-controller-manager-amd64:v1.10.3 kube-proxy-amd64:v1.10.3 kube-scheduler-amd64:v1.10.3 pause-amd64:3.1 etcd-amd64:3.1.12) for image in ${images[@]} ; do docker pull dohoby/$image docker tag dohoby/$image k8s.gcr.io/$image docker rmi dohoby/$image done 拉取结果： [root@localhost hoby]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE k8s.gcr.io/etcd-amd64 3.1.12 a63d07bcb093 29 minutes ago 193MB k8s.gcr.io/pause-amd64 3.1 623c4d30c6b4 32 minutes ago 742kB k8s.gcr.io/kube-scheduler-amd64 v1.10.3 788f5b9849cd 35 minutes ago 50.4MB k8s.gcr.io/kube-proxy-amd64 v1.10.3 0dce35f14844 39 minutes ago 97.1MB k8s.gcr.io/kube-controller-manager-amd64 v1.10.3 298bb46456e1 43 minutes ago 148MB k8s.gcr.io/kube-apiserver-amd64 v1.10.3 d866c9b24ddd About an hour ago 225MB "},"devops/jenkins/Jenkins全局工具配置.html":{"url":"devops/jenkins/Jenkins全局工具配置.html","title":"Jenkins全局工具配置","keywords":"","body":" 因为是在下面配置了全局工具，所以Jenkins能识别java命令，git命令和mvn命令，但是没有配置node相关的npm命令， 所以Jenkins跑node项目时会报错，但是不知道为什么docker的不用配置就可以 "},"devops/kettle/kettle数据同步技术攻克.html":{"url":"devops/kettle/kettle数据同步技术攻克.html","title":"kettle数据同步技术攻克","keywords":"","body":" 项目需求 通过在Linux下命令行启动kettle作业实现从sql server到mysql的同步，其中mysql库中完全没有任何表，需要创建 技术攻克 1、数据库动态设置 kettle数据库同步必须指定从哪个库同步到哪个库，在开发时每个作业和转换中都要设置数据库，而在测试环境和生产环境中这些库都不一样，所以有必要进行数据库动态设置 推荐阅读： http://blog.itpub.net/27120361/viewspace-1412216/ 实战：http://note.youdao.com/noteshare?id=14eb2648fe33ad61c237e30768ecb1d3 2、命令行启动作业（包括日志配置、定时） 3、动态同步所有表 可以动态同步所有表，但是有问题1、如果2张表的定义不一样，数据有问题则会导致报错，进而同步失败 ，比如mysql中有个字段设置不能未空，但sql server中的数据有空则报错2、第一次同步过去没问题，第二次则发生错误，原因是使用了表输出，但是表输出貌似是不能更新的， 推荐阅读：http://ainidehsj.iteye.com/blog/1735434 4、mysql数据库创建(与kettle无关) 通过脚本或者Java代码实现 http://www.cnblogs.com/avivaye/p/4938592.html 5、异常处理 控制到每张表的同步，尽量减少同步错误，而且一有错误立刻邮件通知，避免错误 6、乱码 http://duguyiren3476.iteye.com/blog/1345358 7、要预防的问题 http://pentahochina.com:8080/biforum/topic-29-1.html 感悟 需要用心，静下心去看错误，不要急，不要害怕，要相信能实现这功能，除非用尽办法还是解决不了 "},"devops/maven/maven打包/maven命令行推送jar包.html":{"url":"devops/maven/maven打包/maven命令行推送jar包.html","title":"maven命令行推送jar包","keywords":"","body":" 1、命令格式： mvn deploy:deploy-file -Dfile= -DgroupId= -DartifactId= -Dversion= -Dpackaging=jar -Durl=file:./maven-repository/ -DrepositoryId=maven-repository -DupdateReleaseInfo=true 2、可以（执行命令在D:\\1） mvn deploy:deploy-file -Dfile=d:\\1\\kettle-core-7.0.0.0-25.jar -DgroupId=pentaho-kettle -DartifactId=kettle-core -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases mvn clean deploy:deploy-file -Dfile=d:\\1\\kettle-core-7.0.0.0-25.jar -DgroupId=pentaho-kettle -DartifactId=kettle-core -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases 上面命令推送过一次后，想再推送，必须改版本后才能推送，因为没法更新release的版本的，会报下面的错误 3、也可以（和上面命令不同的地方就是执行命令和jar包所在位置不一样，执行命令在D:\\idea-workspace2\\ebaysdk） mvn deploy:deploy-file -Dfile=d:\\1\\kettle-core-7.0.0.0-25.jar -DgroupId=pentaho-kettle -DartifactId=kettle-core -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases 报下面错，不能从本地的版本库位置deploy，必须像上面那样将jar包和pom包复制到其他目录下 4、未授权错误分析 mvn deploy:deploy-file -Dfile=d:\\1\\kettle-dbdialog-7.0.0.0-25.jar -DgroupId=pentaho-kettle -DartifactId=kettle-dbdialog -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releasess 和2的除了jar包名一样，为什么报下面的错，401未授权 注意是-DrepositoryId=nexus-releases这个后面多了个s, 这个-DrepositoryId的值必须和D:\\maven\\apache-maven-3.5.0\\conf\\settings.xml中配置的id一样 5、其他jar包 mvn deploy:deploy-file -Dfile=d:\\1\\kettle-dbdialog-7.0.0.0-25.jar -DgroupId=pentaho-kettle -DartifactId=kettle-dbdialog -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases mvn deploy:deploy-file -Dfile=d:\\1\\kettle-engine-7.0.0.0-25.jar -DgroupId=pentaho-kettle -DartifactId=kettle-engine -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases mvn deploy:deploy-file -Dfile=d:\\1\\kettle-jdbc-5.0.0.jar -DgroupId=pentaho-kettle -DartifactId=kettle-jdbc -Dversion=5.0.0 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases mvn deploy:deploy-file -Dfile=d:\\1\\metastore-7.0.0.0-25.jar -DgroupId=pentaho -DartifactId=metastore -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases 参考： http://www.trinea.cn/dev-tools/maven-sonatype-nexus-return-401-which-settings-xml-maven-is-using/ https://blog.csdn.net/zzb5682119/article/details/54137986 mvn deploy:deploy-file -Dfile=C:/Users/zhangzubin/Desktop/EisAPIForHA-2.1.jar -DgroupId=cn.evun -DartifactId=EisAPIForHA -Dversion=2.0 -Durl=http://218.75.72.114:8081/nexus/content/repositories/releases -DrepositoryId=nexus-release 关于安装第三方jar到Artifact, 从Artifact的官方上看到其实有很多种方法(请看这里),最简单的就是从Archiva的web 页面上找到Upload Artifact这个功能. 我使用的方法是maven的 deploy:deploy-file 命令,这种方法时要注意的是如果你要安装的jar和pom是位于本地repository的目录下,这个命令就会出错 (Cannot deploy artifact from the local repository…), 解决方法:将要安装的jar和pom copy到其它目录再安装,只要不在本地仓库目录都应该可以. https://www.jianshu.com/p/515fdbf92656 "},"devops/maven/maven打包/maven引入lib文件夹下jar包.html":{"url":"devops/maven/maven打包/maven引入lib文件夹下jar包.html","title":"maven引入lib文件夹下jar包并且打包","keywords":"","body":" pom文件添加依赖 其中${pom.basedir}是指根目录，将外部jar包添加到根目录下的lib文件夹下pom文件添加依赖 pentaho-kettle kettle-jdbc 5.0.0 system ${pom.basedir}/lib/kettle-jdbc-5.0.0.jar 打包时或idea中启动Tomcat时发现没添加lib文件夹下的jar包解决办法 springboot下 org.springframework.boot spring-boot-maven-plugin true https://www.cnblogs.com/xiang--liu/p/11451521.html https://www.cnblogs.com/musarona/p/11204179.html 旧的打war包情况下 org.apache.maven.plugins maven-war-plugin ${project.basedir}/src/lib WEB-INF/lib/ **/*.jar 实际案例： org.apache.maven.plugins maven-war-plugin 2.1.1 fzsiotcard true src/main/profile WEB-INF src/main/webapp --> **/web.xml ${pom.basedir}/lib WEB-INF/lib/ **/*.jar src/main/webapp src/main/webapp/WEB-INF/web.xml false "},"devops/maven/maven打包/maven更改版本号.html":{"url":"devops/maven/maven打包/maven更改版本号.html","title":"maven更改版本号","keywords":"","body":" 1、pom添加versions-maven-plugin插件 org.codehaus.mojo versions-maven-plugin false 2、设置新版本号 注意要在父项目下执行，子项目才会一起更改版本号，不是这个项目的子项目的不会更改 mvn versions:set -DnewVersion=2.1.0 3、更新所有子 Module 的版本 mvn versions:update-child-modules 4、更新顶级项目的parent版本 在使用Spring Boot的多Module项目时，我们可能需要更新项目所依赖的Spring Boot版本。我们可以使用如下命令来进行更新。 mvn versions:update-parent 参考： https://blog.csdn.net/u012921921/article/details/107557880 ``` "},"devops/maven/maven打包/maven私服配置并且推送jar包.html":{"url":"devops/maven/maven打包/maven私服配置并且推送jar包.html","title":"maven私服配置并且推送jar包","keywords":"","body":" maven settings.xml修改 C:\\Users\\hoby.m2/settings.xml thirdparty admin Admin!@# releases admin Admin!@# snapshots admin Admin!@# 在需要上传jar包到私服的模块的父模块(父模块就可以，不用子模块)下添加下面的 releases http://10.20.150.115:8081/nexus/content/repositories/releases snapshots http://10.20.150.115:8081/nexus/content/repositories/snapshots 其中distributionManagement在project下 点击deploy上传 "},"devops/redis/redis在windows下安装.html":{"url":"devops/redis/redis在windows下安装.html","title":"redis在windows下安装","keywords":"","body":" 1、 https://www.cnblogs.com/zhaoyongjie-z/p/12548304.html 2、 3、 ``` "},"devops/uml/建模工具plantuml介绍.html":{"url":"devops/uml/建模工具plantuml介绍.html","title":"建模工具plantuml介绍","keywords":"","body":" 前言 听说过写程序画图吗，没听错吧，一般不是通过powerdesigner。没错，就是写程序画图。哈哈，本文就简单介绍下平时在项目开发中最常用的通过写程序来进行数据库建模，十分简单实用。 听说过写程序画图吗？ 没听错吧，一般不是通过powerdesigner或者visual studio来画吗，写程序怎么画 哈哈，你没听错，下面就让我简单介绍下plantuml给你 首先了解下UML是统一建模语言的意思，而PlantUML可以画UML各种图，比如类图、对象图、用例图、时序图等 那怎么开始用呢 首先要知道在很多软件上，比如sublime、notepad++、eclipse或者命令行上都可以使用PlantUML，但是必须得装一些必须的依赖软件，如果你在window下，则必须安装graphviz，下面列出安装的步骤 1、下载graphviz并安装 下载地址：http://www.graphviz.org/Download_windows.php安装目录：D:\\Program Files\\graphviz下 2、设置graphviz环境变量 a、新建GRAPHVIZ_DOT系统变量，设置其值为graphviz安装目录下的bin目录下的dot.exe文件路径D:\\Program Files\\graphviz\\bin\\dot.exeb、修改path变量，在后面添加D:\\Program Files\\graphviz\\bin; 3、验证安装和设置 进入windows命令行界面，输入dot -version，若显示graphviz相关信息即为安装和配置成功 eclipse下怎么使用呢 eclipse使用下首先得安装插件 打开 Eclipse，Help->install new software...。填入相应的 URL：http://plantuml.sourceforge.net/updatesite/搜索出来后安装即可，然后在window->show view下搜索出PlantUML然后在eclipse中显示相应的面板 那它有什么语法呢 它的语法很简单，下面就介绍下其语法以及平时开发常用的数据建模，也就是对象图 1、首先在任意工程下，新建一个后缀名为uml的文件2、该uml文件具有如下语法，先看个简单例子 @startuml class jd_doctor{ -id:String -skills:String } note left 这是个备注 end note @enduml https://www.ibm.com/developerworks/cn/opensource/os-cn-ecl-plantuml/ http://www.135editor.com/ http://plantuml.com/object-diagram http://bj.96weixin.com/ demo 待学习 PlantUML画类图(一) 类与类之间的关系 https://blog.csdn.net/u_ranfa/article/details/89646218 Java 类与类之间的关系 https://blog.csdn.net/u_ranfa/article/details/89645757 "},"devops/运维/window端口占用查询.html":{"url":"devops/运维/window端口占用查询.html","title":"window端口占用查询","keywords":"","body":" 查看端口 netstat -ano netstat -ano |grep 8090 netstat -ano |findstr \"8719\" 查看端口对应那个任务 tasklist|findstr \"17752\" 例子： C:\\Users\\hoby λ netstat -ano |grep 8090 TCP 0.0.0.0:8090 0.0.0.0:0 LISTENING 17752 TCP [::]:8090 [::]:0 LISTENING 17752 C:\\Users\\hoby λ netstat -ano |grep 8719 TCP 0.0.0.0:8719 0.0.0.0:0 LISTENING 17752 TCP [::]:8719 [::]:0 LISTENING 17752 C:\\Users\\hoby λ netstat -ano |findstr \"8719\" TCP 0.0.0.0:8719 0.0.0.0:0 LISTENING 17752 TCP [::]:8719 [::]:0 LISTENING 17752 C:\\Users\\hoby λ tasklist|findstr \"17752\" java.exe 17752 Console 10 430,904 K 参考： windows本地端口占用查看 "},"elasticsearch/es实战/es实战1-常见命令.html":{"url":"elasticsearch/es实战/es实战1-常见命令.html","title":"es实战1-常见命令","keywords":"","body":" 1、增加索引 curl -XPUT '192.168.1.1:9200/twitter/tweet/1?pretty' -H 'Content-Type: application/json' -d'{ \"platformNo\": 19,\"user\" : \"kimchy\",\"post_date\" : \"2009-11-15T14:12:12\",\"message\" : \"trying out Elasticsearch\"}' 2、删除索引 curl -XDELETE '192.168.1.1:9200/pg.nsp.192.168.1.1mon.sp_on_sale_goods' 3、更新索引 重复的自动覆盖 curl -XPUT '192.168.1.1:9200/pg.nsp1/tweet/1?pretty' -H 'Content-Type: application/json' -d'{ \"platformNo\": 19,\"reason\" : \"苹果\",\"post_date\" : \"2009-11-15T14:12:12\",\"message\" : \"trying out Elasticsearch\"}' 4、查询索引 curl -XGET '192.168.1.1:9200/posts/doc/1' 5、查看集群健康 curl -XGET '192.168.1.146:9200/_cat/health?v&pretty' 6、查看索引 curl -XGET '192.168.1.1:9200/_cat/indices?v&pretty' 7、查看process curl http://192.168.1.146:9200/_nodes/process?pretty 8、查看_settings curl -XGET '192.168.1.146:9200/pg.nsp.sp_oa.oa_sp_listing/_settings?pretty' 9、设置_settings（max_result_window） curl -XPUT '192.168.1.146:9200/pg.nsp.sp_oa.oa_sp_listing/_settings?pretty' -H 'Content-Type:application/json' -d'{ \"index\" : { \"max_result_window\" : 100000001}}' 10、查看_mapping curl -XGET '192.168.1.146:9200/pg.nsp.sp_oa.oa_sp_listing/_mapping?pretty' 11、设置_mapping 备注：若要在windows下的cmder下测试，改为双引号 curl -XPUT \"192.168.1.1:9200/twitter/tweet/1?pretty\" -H \"Content-Type: application/json\" -d\"{ \\\"platformNo\\\": 19,\\\"user\\\" : \\\"kimchy\\\",\\\"post_date\\\" : \\\"2009-11-15T14:12:12\\\",\\\"message\\\" : \\\"trying out Elasticsearch\\\"}\" { \"_index\" : \"twitter\", \"_type\" : \"tweet\", \"_id\" : \"1\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"_seq_no\" : 0, \"_primary_term\" : 1 } "},"elasticsearch/es实战/es实战2-查询命令.html":{"url":"elasticsearch/es实战/es实战2-查询命令.html","title":"es实战2-查询命令","keywords":"","body":" 、精确查询(词条查询) 、匹配查询 、多个匹配查询 、短语匹配查询 GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 100, \"query\": { \"bool\": { \"must\": [ { \"multi_match\": { \"query\": \"Lightning Purple\", \"minimum_should_match\": \"100\", \"fields\": [ \"title^1.0\", \"description^1.0\", \"keywords^1.0\" ], \"type\": \"phrase\", \"operator\": \"and\", \"slop\": 0, \"prefix_length\": 0, \"max_expansions\": 50, \"zero_terms_query\": \"NONE\", \"auto_generate_synonyms_phrase_query\": true, \"fuzzy_transpositions\": true, \"boost\": 1 } } ], \"adjust_pure_negative\": true, \"boost\": 1 } } } GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 100, \"query\": { \"bool\": { \"must\": [ { \"multi_match\": { \"query\": \"SEA FAIRIES\", \"minimum_should_match\": \"100\", \"fields\": [ \"title^1.0\", \"description^1.0\", \"keywords^1.0\" ], \"type\": \"phrase\", \"operator\": \"and\", \"slop\": 0, \"prefix_length\": 0, \"max_expansions\": 50, \"zero_terms_query\": \"NONE\", \"auto_generate_synonyms_phrase_query\": true, \"fuzzy_transpositions\": true, \"boost\": 1 } } ], \"adjust_pure_negative\": true, \"boost\": 1 } } } https://blog.csdn.net/dm_vincent/article/details/41941659?utm_source=tuicool 、正则表达式查询 、聚合查询(distinct) 场景：当需要获取某个字段上的所有可用值时，可以使用terms聚合查询完成 第一个size是hits那部分数据的大小，这里聚合不需要hits那部分，第二个size是聚合所需要查询的数据site.keyword是你想对那个字段进行不同值查询group_by_site是随意起的值 类似于sql的select distinct site, count(*) from sp_oa.oa_sp_listing GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 0, \"aggregations\": { \"group_by_site\": { \"terms\": { \"field\": \"site.keyword\", \"size\": 1000, \"min_doc_count\": 1, \"shard_min_doc_count\": 0, \"show_term_doc_count_error\": false, \"order\": [ { \"_count\": \"desc\" }, { \"_key\": \"asc\" } ] } } } } https://www.cnblogs.com/qijiu/p/6876096.html 、聚合数目查询(cardinality) 类似于sql的select count( ) from (select distinct from table) GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 0, \"aggregations\": { \"count_site\": { \"cardinality\": { \"field\": \"site.keyword\" } } } } 结果： { \"took\": 1, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 16548333, \"max_score\": 0, \"hits\": [] }, \"aggregations\": { \"count_site\": { \"value\": 17 } } } "},"elasticsearch/es实战/es实战3-综合查询案例.html":{"url":"elasticsearch/es实战/es实战3-综合查询案例.html","title":"es实战3-综合查询案例","keywords":"","body":" 1、产品侵权查询 背景：将在售的侵权的sku（某些平台下的）搜索出来 1、短语匹配查询2、词条精确查询3、in查询 GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 10000, \"timeout\": \"10m\", \"query\": { \"bool\": { \"must\": [ { \"match_phrase\": { \"product_code\": { \"query\": \"SKU778231\", \"slop\": 0, \"boost\": 1 } } }, { \"term\": { \"sales_status\": { \"value\": \"online\", \"boost\": 1 } } }, { \"terms\": { \"platform\": [ \"ebay\", \"amazon\", \"aliexpress\", \"newegg\", \"wish\", \"linio\" ], \"boost\": 1 } } ], \"adjust_pure_negative\": true, \"boost\": 1 } } } 2、侵权品牌查询 1、多字段短语匹配查询 短语可以多个字符串组合在一起，而且位置固定才会搜索出来，比如Abercrombie & Fitch，特别适合短语查询 2、词条精确查询3、in查询 { \"from\": 0, \"size\": 10000, \"timeout\": \"10m\", \"query\": { \"bool\": { \"must\": [ { \"multi_match\": { \"query\": \"Abercrombie & Fitch\", \"fields\": [ \"description^1.0\", \"keywords^1.0\", \"title^1.0\" ], \"type\": \"phrase\", \"operator\": \"AND\", \"slop\": 0, \"prefix_length\": 0, \"max_expansions\": 50, \"zero_terms_query\": \"NONE\", \"auto_generate_synonyms_phrase_query\": true, \"fuzzy_transpositions\": true, \"boost\": 1 } }, { \"terms\": { \"platform\": [ \"Joom\", \"NewChic\", \"11Street\", \"Linio\", \"Lazada\", \"JD\", \"Yilinker\", \"eBay\", \"WholeSale\" ], \"boost\": 1 } } ], \"adjust_pure_negative\": true, \"boost\": 1 } } } GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 10000, \"timeout\": \"20m\", \"query\": { \"bool\": { \"must\": [ { \"multi_match\": { \"query\": \"segway\", \"fields\": [ \"description^1.0\", \"title^1.0\" ], \"type\": \"phrase\", \"operator\": \"AND\", \"slop\": 0, \"prefix_length\": 0, \"max_expansions\": 50, \"zero_terms_query\": \"NONE\", \"auto_generate_synonyms_phrase_query\": true, \"fuzzy_transpositions\": true, \"boost\": 1 } }, { \"term\": { \"sales_status\": { \"value\": \"online\", \"boost\": 1 } } }, { \"term\": { \"platform\": { \"value\": \"wish\", \"boost\": 1 } } }, { \"term\": { \"product_code\": { \"value\": \"sku894685\", \"boost\": 1 } } } ], \"adjust_pure_negative\": true, \"boost\": 1 } } } 3、es列表搜索查询 "},"elasticsearch/es实战/es实战4-java常见查询实例.html":{"url":"elasticsearch/es实战/es实战4-java常见查询实例.html","title":"es实战4-java常见查询实例","keywords":"","body":" 查询 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.from(from); searchSourceBuilder.size(size); searchSourceBuilder.query(boolQueryBuilder); //超时时间 searchSourceBuilder.timeout(new TimeValue(10, TimeUnit.MINUTES)); SearchResult searchResult = elasticSearchService.search(SpListingEsInfo.class, searchSourceBuilder); 布尔查询 BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); searchSourceBuilder.query(boolQueryBuilder); 词条精确查询 TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(\"sales_status\", \"online\"); boolQueryBuilder.must(termQueryBuilder); 词条精确查询（in范围查询） 类似sql的in查询 List countryShortCodes, List platformNames if (!platformNames.isEmpty()) { TermsQueryBuilder termsQueryBuilder = QueryBuilders.termsQuery(\"platform\", platformNames); boolQueryBuilder.must(termsQueryBuilder); } if (!countryShortCodes.isEmpty()) { TermsQueryBuilder termsQueryBuilder2 = QueryBuilders.termsQuery(\"site\", countryShortCodes); boolQueryBuilder.must(termsQueryBuilder2); } 短语查询(多字符串查询) MatchPhraseQueryBuilder matchPhraseQueryBuilder = QueryBuilders.matchPhraseQuery(\"product_code\", productInfringe.getProductCode()); boolQueryBuilder.must(matchPhraseQueryBuilder); 多字段短语匹配查询(多字段多字符串查询) MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(infringeBrand.getName(), \"title\", \"description\", \"keywords\"). operator(Operator.AND).type(MultiMatchQueryBuilder.Type.PHRASE); boolQueryBuilder.must(multiMatchQueryBuilder); 正则查询 BoolQueryBuilder boolQueryBuilder2 = QueryBuilders.boolQuery(); RegexpQueryBuilder regexpQueryBuilder = new RegexpQueryBuilder(\"description.keyword\", \".*\" + spListingPageQueryVo.getSearchText().trim() + \".*\"); boolQueryBuilder2.should(regexpQueryBuilder); RegexpQueryBuilder regexpQueryBuilder2 = new RegexpQueryBuilder(\"title.keyword\", \".*\" + spListingPageQueryVo.getSearchText().trim() + \".*\"); boolQueryBuilder2.should(regexpQueryBuilder2); RegexpQueryBuilder regexpQueryBuilder3 = new RegexpQueryBuilder(\"keywords.keyword\", \".*\" + spListingPageQueryVo.getSearchText().trim() + \".*\"); boolQueryBuilder2.should(regexpQueryBuilder3); boolQueryBuilder2.minimumShouldMatch(1); boolQueryBuilder.must(boolQueryBuilder2); 排序 if (!StringUtils.isEmpty(spListingPageQueryVo.getSortKey())) { FieldSortBuilder fieldSortBuilder = new FieldSortBuilder(spListingPageQueryVo.getSortKey()+\".keyword\"); if (spListingPageQueryVo.getSortType()) {//TRUE降序 fieldSortBuilder.order(SortOrder.DESC); } else { fieldSortBuilder.order(SortOrder.ASC); } searchSourceBuilder.sort(fieldSortBuilder); } 聚合查询（aggregation） int from=0; int size=0;//这里设置为0是不用返回hits那部分内容 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.from(from); searchSourceBuilder.size(size); searchSourceBuilder.aggregation(AggregationBuilders.terms(\"group_by_site\").field(\"site.keyword\").size(1000));//group_by_site这个只是个名字，可以随便起的 聚合查询（cardinality） int from=0; int size=0;//这里设置为0是不用返回hits那部分内容 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.from(from); searchSourceBuilder.size(size); searchSourceBuilder.aggregation(AggregationBuilders.cardinality(\"group_by_site\").field(\"site.keyword\"));//group_by_site这个只是个名字，可以随便起的 "},"elasticsearch/es实战/es实战5-聚合分组查询案例.html":{"url":"elasticsearch/es实战/es实战5-聚合分组查询案例.html","title":"es实战5-聚合分组查询案例","keywords":"","body":" 需求背景 对在售商品按照sku,平台platform来查询每个sku在对应平台下的最大价格price，sql如下 SELECT platform,product_code,max(price) from test_listing GROUP BY platform,product_code 其他辅助查询 SELECT platform,product_code,max(price) from test_listingwhere product_code='SKU466577' GROUP BY platform,product_code SELECT platform,product_code,price from test_listingwhere product_code='SKU466577' and platform='lazada' order by price desc kibana查询 思路：先对sku进行聚合，再添加平台platform的子聚合，最后再统计最大价格price GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 0, \"aggregations\": { \"product_code_agg\": { \"terms\": { \"field\": \"product_code.keyword\", \"size\": 10, \"min_doc_count\": 1, \"shard_min_doc_count\": 0, \"show_term_doc_count_error\": false, \"order\": [ { \"_count\": \"desc\" }, { \"_key\": \"asc\" } ] }, \"aggregations\": { \"plaform_agg\": { \"terms\": { \"field\": \"platform.keyword\", \"size\": 10, \"min_doc_count\": 1, \"shard_min_doc_count\": 0, \"show_term_doc_count_error\": false, \"order\": [ { \"_count\": \"desc\" }, { \"_key\": \"asc\" } ] }, \"aggregations\": { \"price_max\": { \"max\": { \"field\": \"price\" } } } } } } } } 查询结果： { \"took\": 501, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 10125828, \"max_score\": 0, \"hits\": [] }, \"aggregations\": { \"product_code_agg\": { \"doc_count_error_upper_bound\": 3284, \"sum_other_doc_count\": 10094565, \"buckets\": [ { \"key\": \"SKU466577\", \"doc_count\": 5949, \"plaform_agg\": { \"doc_count_error_upper_bound\": 0, \"sum_other_doc_count\": 0, \"buckets\": [ { \"key\": \"lazada\", \"doc_count\": 5493, \"price_max\": { \"value\": 356000 } }, { \"key\": \"shopee\", \"doc_count\": 451, \"price_max\": { \"value\": 304600 } }, { \"key\": \"wish\", \"doc_count\": 5, \"price_max\": { \"value\": 0 } } ] } }, { \"key\": \"SKU564470\", \"doc_count\": 4856, \"plaform_agg\": { \"doc_count_error_upper_bound\": 0, \"sum_other_doc_count\": 0, \"buckets\": [ { \"key\": \"lazada\", \"doc_count\": 4478, \"price_max\": { \"value\": 3048000 } }, { \"key\": \"shopee\", \"doc_count\": 361, \"price_max\": { \"value\": 295400 } }, { \"key\": \"wish\", \"doc_count\": 9, \"price_max\": { \"value\": 16 } }, { \"key\": \"Aliexpress\", \"doc_count\": 6, \"price_max\": { \"value\": 28.540000915527344 } }, { \"key\": \"eBay\", \"doc_count\": 2, \"price_max\": { \"value\": 8.489999771118164 } } ] } } ] } } } 单元测试 @Test public void testAggsQuery5() { BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); int from = 0; int size = 0;//这里设置为0是不用返回hits那部分内容 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.from(from); searchSourceBuilder.size(size); TermsAggregationBuilder termsAggregationBuilder1=AggregationBuilders.terms(\"plaform_agg\").field(\"platform.keyword\"); TermsAggregationBuilder termsAggregationBuilder2=AggregationBuilders.terms(\"product_code_agg\").field(\"product_code.keyword\"); termsAggregationBuilder2.subAggregation(termsAggregationBuilder1); MaxAggregationBuilder maxAggregationBuilder= AggregationBuilders.max(\"price_max\").field(\"price\"); termsAggregationBuilder1.subAggregation(maxAggregationBuilder); searchSourceBuilder.aggregation(termsAggregationBuilder2); log.info(\"aggregations:{}\", searchSourceBuilder.toString()); SearchAggResult searchResult = elasticSearchService.searchMaxAgg(searchSourceBuilder, \"pg.nsp.sp_oa.oa_sp_listing\", \"_doc\"); System.out.println(searchResult.getTotal()); System.out.println(searchResult.getSearchBuckets()); } 参考：https://blog.csdn.net/sxf_123456/article/details/79482041 "},"elasticsearch/es实战/es实战6-springboot2.0集成elasticsearch6.html":{"url":"elasticsearch/es实战/es实战6-springboot2.0集成elasticsearch6.html","title":"es实战6-springboot2.0集成elasticsearch6","keywords":"","body":" pom.xml org.elasticsearch elasticsearch 6.2.4 org.elasticsearch.client rest 6.0.0-alpha1 org.elasticsearch.client elasticsearch-rest-high-level-client 6.2.4 ElasticSearchConfig package com.tobe.spcommon.common.config; import lombok.Data; import org.apache.http.HttpHost; import org.elasticsearch.client.RestClient; import org.elasticsearch.client.RestHighLevelClient; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.util.Assert; import java.util.List; @Configuration public class ElasticSearchConfig { @Autowired Hosts hosts; @Bean(\"restHighLevelClient\") public RestHighLevelClient clientFactory() { Assert.notEmpty(hosts.hosts, \"the host of elastic search cann't be null\"); HttpHost[] httpHosts = new HttpHost[hosts.hosts.size()]; for (int i = 0; i hosts; } @Data public static class Host { private String host; private int port; private String protocol; } } properties #----------------------- # ES new config #----------------------- es.hosts[0].host=192.168.1.1 es.hosts[0].port=9200 es.hosts[0].protocol=http ESTest package com.tobe.spcommon.es; import com.tobe.spcommon.common.config.ElasticSearchConfig; import com.tobe.spcommon.common.service.ElasticSearchService; import com.tobe.spcommon.dao.InfringeWordRepository; import com.tobe.spcommon.pojo.view.req.infringeword.InfringeWordAddVo; import com.tobe.spcommon.pojo.view.req.infringeword.InfringeWordEsInfo; import lombok.extern.slf4j.Slf4j; import org.apache.http.Header; import org.apache.http.HttpHost; import org.apache.http.message.BasicHeader; import org.elasticsearch.ElasticsearchException; import org.elasticsearch.action.bulk.BulkResponse; import org.elasticsearch.action.index.IndexRequest; import org.elasticsearch.action.index.IndexResponse; import org.elasticsearch.client.RestClient; import org.elasticsearch.client.RestHighLevelClient; import org.elasticsearch.common.xcontent.XContentType; import org.elasticsearch.index.query.QueryStringQueryBuilder; import org.elasticsearch.rest.RestStatus; import org.junit.Test; import org.junit.runner.RunWith; import org.omg.PortableInterceptor.INACTIVE; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.autoconfigure.EnableAutoConfiguration; import org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration; import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration; import org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import javax.annotation.Resource; import java.io.IOException; import java.util.ArrayList; import java.util.Iterator; import java.util.List; /** * @author Wuxi * @date 2018/5/14 */ @Slf4j @RunWith(SpringRunner.class) @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) public class ESTest { @Resource ElasticSearchService elasticSearchService; @Test public void testBulkInsert() { List infringeWordEsInfos = new ArrayList<>(); InfringeWordEsInfo infringeWordEsInfo = new InfringeWordEsInfo(); infringeWordEsInfo.setId(\"9\"); infringeWordEsInfo.setName(\"苹果9\"); infringeWordEsInfo.setFullCategory(1); infringeWordEsInfo.setPlatformNo(1); log.info(infringeWordEsInfo.toString()); InfringeWordEsInfo infringeWordEsInfo2 = new InfringeWordEsInfo(); infringeWordEsInfo2.setId(\"10\"); infringeWordEsInfo2.setName(\"苹果10\"); infringeWordEsInfo2.setFullCategory(1); infringeWordEsInfo2.setPlatformNo(1); log.info(infringeWordEsInfo2.toString()); InfringeWordEsInfo infringeWordEsInfo3 = new InfringeWordEsInfo(); infringeWordEsInfo3.setId(\"3\"); infringeWordEsInfo3.setName(\"苹果3\"); infringeWordEsInfo3.setFullCategory(1); infringeWordEsInfo3.setPlatformNo(0); log.info(infringeWordEsInfo3.toString()); InfringeWordEsInfo infringeWordEsInfo4 = new InfringeWordEsInfo(); infringeWordEsInfo4.setId(\"4\"); infringeWordEsInfo4.setName(\"苹果4\"); infringeWordEsInfo4.setFullCategory(1); infringeWordEsInfo4.setPlatformNo(0); log.info(infringeWordEsInfo4.toString()); InfringeWordEsInfo infringeWordEsInfo19 = new InfringeWordEsInfo(); infringeWordEsInfo19.setId(\"19\"); infringeWordEsInfo19.setName(\"苹果19\"); infringeWordEsInfo19.setFullCategory(1); infringeWordEsInfo19.setPlatformNo(19); log.info(infringeWordEsInfo19.toString()); infringeWordEsInfos.add(infringeWordEsInfo); infringeWordEsInfos.add(infringeWordEsInfo2); infringeWordEsInfos.add(infringeWordEsInfo3); infringeWordEsInfos.add(infringeWordEsInfo4); infringeWordEsInfos.add(infringeWordEsInfo19); //infringeWordEsInfo3 infringeWordEsInfo4不会被更新 try { BulkResponse bulkItemResponses = elasticSearchService.bulkInsert(infringeWordEsInfos); log.info(\"{}\",bulkItemResponses); } catch (Exception e) { e.printStackTrace(); } // elasticSearchService.update(infringeWordEsInfo3); } @Test public void testInsert() { InfringeWordEsInfo infringeWordEsInfo = new InfringeWordEsInfo(); infringeWordEsInfo.setId(\"6\"); infringeWordEsInfo.setName(\"苹果2\"); infringeWordEsInfo.setFullCategory(1); log.info(infringeWordEsInfo.toString()); //infringeWordRepository.save(infringeWordEsInfo); try { elasticSearchService.insert(infringeWordEsInfo); } catch (Exception e) { e.printStackTrace(); } } @Test public void test() throws IOException { RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\"192.168.1.1\", 9200, \"http\"), new HttpHost(\"192.168.1.1\", 9201, \"http\"))); String queryString = \"apple\";//搜索关键字 IndexRequest request = new IndexRequest( \"posts\", \"doc\", \"3\"); String jsonString = \"{\" + \"\\\"user\\\":\\\"kimchy\\\",\" + \"\\\"postDate\\\":\\\"2013-01-30\\\",\" + \"\\\"message\\\":\\\"trying out Elasticsearch\\\"\" + \"}\"; request.source(jsonString, XContentType.JSON); try { //RequestOptions.DEFAULT.getHeaders() IndexResponse response = client.index(request);//new RequestOptions.DEFAULT.ReqHeader());new BasicHeader() log.info(\"------------------响应：{}\", response); } catch (ElasticsearchException e) { if (e.status() == RestStatus.CONFLICT) { log.error(\"\", e); } } finally { client.close(); } } } ElasticSearchServiceImpl package com.tobe.spcommon.common.service.impl; import com.tobe.spcommon.common.exception.SearchException; import com.tobe.spcommon.common.service.ElasticSearchService; import com.tobe.spcommon.common.utils.ElasticSearchUtil; import com.tobe.spcommon.common.utils.JsonUtil; import lombok.extern.slf4j.Slf4j; import org.elasticsearch.action.bulk.BulkRequest; import org.elasticsearch.action.bulk.BulkResponse; import org.elasticsearch.action.delete.DeleteRequest; import org.elasticsearch.action.delete.DeleteResponse; import org.elasticsearch.action.get.GetRequest; import org.elasticsearch.action.get.GetResponse; import org.elasticsearch.action.get.MultiGetRequest; import org.elasticsearch.action.get.MultiGetResponse; import org.elasticsearch.action.index.IndexRequest; import org.elasticsearch.action.index.IndexResponse; import org.elasticsearch.action.search.SearchRequest; import org.elasticsearch.action.search.SearchResponse; import org.elasticsearch.action.update.UpdateRequest; import org.elasticsearch.action.update.UpdateResponse; import org.elasticsearch.client.RestHighLevelClient; import org.elasticsearch.common.xcontent.XContentType; import org.elasticsearch.search.builder.SearchSourceBuilder; import org.springframework.stereotype.Component; import javax.annotation.Resource; import java.io.IOException; import java.util.List; @Slf4j @Component public class ElasticSearchServiceImpl implements ElasticSearchService { @Resource RestHighLevelClient restHighLevelClient; public IndexResponse insert(T value) { log.info(\"请求index：{}\", value); try { ElasticSearchUtil.EsDataInfo esDataInfo = ElasticSearchUtil.assertAndReturnEsDataInfo(value); IndexRequest request = new IndexRequest( esDataInfo.getIndex(), esDataInfo.getType(), esDataInfo.getId()); request.source(JsonUtil.stringify(value), XContentType.JSON); IndexResponse response = restHighLevelClient.index(request); log.info(\"响应index：{}\", response); return response; } catch (IOException | IllegalAccessException e) { log.error(\"\", e); throw new SearchException(e); } } public DeleteResponse delete(T value) { log.info(\"请求delete：{}\", value); try { ElasticSearchUtil.EsDataInfo esDataInfo = ElasticSearchUtil.assertAndReturnEsDataInfo(value); DeleteRequest request = new DeleteRequest( esDataInfo.getIndex(), esDataInfo.getType(), esDataInfo.getId()); DeleteResponse response = restHighLevelClient.delete(request); log.info(\"响应delete：{}\", response); return response; } catch (IOException | IllegalAccessException e) { log.error(\"\", e); throw new SearchException(e); } } public UpdateResponse update(T value) { log.info(\"请求update：{}\", value); try { ElasticSearchUtil.EsDataInfo esDataInfo = ElasticSearchUtil.assertAndReturnEsDataInfo(value); UpdateRequest request = new UpdateRequest( esDataInfo.getIndex(), esDataInfo.getType(), esDataInfo.getId()); request.doc(JsonUtil.stringify(value), XContentType.JSON); UpdateResponse response = restHighLevelClient.update(request); log.info(\"响应update：{}\", response); return response; } catch (IOException | IllegalAccessException e) { log.error(\"\", e); throw new SearchException(e); } } public GetResponse get(T t) { log.info(\"请求get：{}\", t); try { ElasticSearchUtil.EsDataInfo esDataInfo = ElasticSearchUtil.assertAndReturnEsDataInfo(t); GetRequest request = new GetRequest( esDataInfo.getIndex(), esDataInfo.getType(), esDataInfo.getId()); GetResponse response = restHighLevelClient.get(request); log.info(\"响应delete：{}\", response); return response; } catch (IOException | IllegalAccessException e) { log.error(\"\", e); throw new SearchException(e); } } public MultiGetResponse multiGet(List values) { log.info(\"请求multiGet：{}\", values); try { MultiGetRequest request = new MultiGetRequest(); for (T t : values) { ElasticSearchUtil.EsDataInfo esDataInfo = ElasticSearchUtil.assertAndReturnEsDataInfo(t); request.add(esDataInfo.getIndex(), esDataInfo.getType(), esDataInfo.getId()); } MultiGetResponse response = restHighLevelClient.multiGet(request); log.info(\"响应delete：{}\", response); return response; } catch (IOException | IllegalAccessException e) { log.error(\"\", e); throw new SearchException(e); } } public BulkResponse bulkInsert(List values) { log.info(\"请求bulkInsert：{}\", values); BulkRequest request = new BulkRequest(); try { for (Object object : values) { ElasticSearchUtil.EsDataInfo esDataInfo = ElasticSearchUtil.assertAndReturnEsDataInfo(object); IndexRequest indexRequest = new IndexRequest( esDataInfo.getIndex(), esDataInfo.getType(), esDataInfo.getId()); indexRequest.source(JsonUtil.stringify(object), XContentType.JSON); request.add(indexRequest); } BulkResponse response = restHighLevelClient.bulk(request); log.info(\"响应bulkInsert：{}\", response); return response; } catch (IOException | IllegalAccessException e) { log.error(\"\", e); throw new SearchException(e); } } public SearchResponse search(List values) { log.info(\"请求multiGet：{}\", values); try { SearchRequest request = new SearchRequest(); SearchSourceBuilder source = new SearchSourceBuilder(); request.source(source); SearchResponse response = restHighLevelClient.search(request); log.info(\"响应delete：{}\", response); return response; } catch (IOException e) { log.error(\"\", e); throw new SearchException(e); } } } "},"elasticsearch/es实战/es实战7-elasticsearch实现springboot自动配置.html":{"url":"elasticsearch/es实战/es实战7-elasticsearch实现springboot自动配置.html","title":"es实战7-elasticsearch实现springboot自动配置","keywords":"","body":" 1、新建ElasticSearchProperties package com.basic.elasticsearch.autoconfigure; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; import java.util.List; @Data @Configuration @ConfigurationProperties(prefix = \"elastic\") public class ElasticSearchProperties { List hosts; } package com.basic.elasticsearch.autoconfigure; import lombok.Data; @Data public class Host { private String host; private int port; private String protocol; } 2、新建ElasticSearchAutoConfiguration自动配置类 package com.basic.elasticsearch.autoconfigure; import com.basic.elasticsearch.service.ElasticSearchService; import com.basic.elasticsearch.service.ElasticSearchTransportClientService; import com.basic.elasticsearch.service.impl.ElasticSearchServiceImpl; import com.basic.elasticsearch.service.impl.ElasticSearchTransportClientServiceImpl; import org.apache.http.HttpHost; import org.elasticsearch.client.RestClient; import org.elasticsearch.client.RestHighLevelClient; import org.elasticsearch.client.transport.TransportClient; import org.elasticsearch.common.settings.Settings; import org.elasticsearch.common.transport.TransportAddress; import org.elasticsearch.transport.client.PreBuiltTransportClient; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.autoconfigure.condition.ConditionalOnClass; import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean; import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty; import org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.util.Assert; import java.net.InetAddress; import java.net.UnknownHostException; /** * https://www.cnblogs.com/xyzmy/p/9776037.html */ @Configuration @EnableConfigurationProperties(ElasticSearchProperties.class) @ConditionalOnClass({ElasticSearchService.class, ElasticSearchTransportClientService.class}) @ConditionalOnProperty(prefix = \"elastic\", value = \"enabled\", matchIfMissing = false) //判断配置文件中是否存在elastic开头的配置,如果不存在配置，如果配置matchIfMissing为true,即使我们配置文件中配置elastic.enabled=true，也是默认生效的； // matchIfMissing必须设置为false，配置文件不存在时则不自动配置,若配置文件存在，则再判断elastic.enabled为true才会自动配置 public class ElasticSearchAutoConfiguration { @Autowired ElasticSearchProperties elasticSearchProperties; static { System.setProperty(\"es.set.netty.runtime.available.processors\", \"false\"); } @Bean @ConditionalOnMissingBean public RestHighLevelClient restHighLevelClient() { Assert.notEmpty(elasticSearchProperties.hosts, \"the host of elastic search cann't be null\"); HttpHost[] httpHosts = new HttpHost[elasticSearchProperties.hosts.size()]; for (int i = 0; i 3、在resource/METE-INF文件夹下新建spring.factories文件 文件内容如下 # Auto Configure org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.basic.elasticsearch.autoconfigure.ElasticSearchAutoConfiguration 4、用法 引入pom依赖(注意排除掉一些不要的依赖) com.basic.search elasitcsearch-starter 1.0.0 org.slf4j slf4j-log4j12 org.springframework.boot spring-boot-starter-data-elasticsearch 新建application-es.properties # ES new config elastic.hosts[0].host=192.168.1.146 elastic.hosts[0].port=9200 elastic.hosts[0].protocol=http elastic.enabled=true 测试 @Test public void testInsert() { InfringeWordEsInfo infringeWordEsInfo = new InfringeWordEsInfo(); infringeWordEsInfo.setId(\"6\"); infringeWordEsInfo.setName(\"苹果2\"); infringeWordEsInfo.setFullCategory(1); log.info(infringeWordEsInfo.toString()); //infringeWordRepository.save(infringeWordEsInfo); try { elasticSearchService.insert(infringeWordEsInfo); } catch (Exception e) { e.printStackTrace(); } } 4、另一种引入方式EnableElasticSearch 新建EnableElasticSearch.java package com.basic.elasticsearch.autoconfigure; import org.springframework.context.annotation.Import; import java.lang.annotation.*; @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Import({ElasticSearchAutoConfiguration.class}) public @interface EnableElasticSearch { } 引入 @EnableElasticSearch "},"elasticsearch/es知识点/Elasticsearch学习.html":{"url":"elasticsearch/es知识点/Elasticsearch学习.html","title":"Elasticsearch学习","keywords":"","body":" 待学习 时间范围查询 https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-range-query.html#querying-range-fields https://www.cnblogs.com/shoufeng/p/11266136.html "},"elasticsearch/es知识点/和Elasticsearch交互.html":{"url":"elasticsearch/es知识点/和Elasticsearch交互.html","title":"和Elasticsearch交互","keywords":"","body":" Java可以使用 Elasticsearch 内置的两个客户端： 节点客户端（Node client） 节点客户端作为一个非数据节点加入到本地集群中。换句话说，它本身不保存任何数据，但是它知道数据在集群中的哪个节点中，并且可以把请求转发到正确的节点。 传输客户端（Transport client） 轻量级的传输客户端可以将请求发送到远程集群。它本身不加入集群，但是它可以将请求转发到集群中的一个节点上。 两个 Java 客户端都是通过 9300 端口并使用 Elasticsearch 的原生 传输 协议和集群交互。集群中的节点通过端口 9300 彼此通信。如果这个端口没有打开，节点将无法形成一个集群。 客户端连接elasticsearch代码 @Bean(\"transportClient\") public TransportClient transportClient() throws UnknownHostException { Assert.notEmpty(hosts.hosts, \"the host of elastic search cann't be null\"); TransportAddress[] transportAddress = new TransportAddress[hosts.hosts.size()]; for (int i = 0; i 更多代码参考本站的【springboot2.0集成elasticsearch6】或者本站搜索ElasticSearchConfig 参考： https://www.elastic.co/guide/cn/elasticsearch/guide/cn/_talking_to_elasticsearch.html https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/transport-client.html 特别注意：本环境使用的elasticsearch为6.4.2，貌似7.x后该方法为过期了，8.x后删除了，若用更高版本，自行在官网查询对应的方法 "},"java/java8/java8新特性.html":{"url":"java/java8/java8新特性.html","title":"java8新特性","keywords":"","body":" 1、java8接口可以有默认方法 接口可以有实现体，但必须是默认实现，所以要在方法前加上default字段表示默认方法 public interface SmartApplicationListener extends ApplicationListener, Ordered { /** * Determine whether this listener actually supports the given event type. * @param eventType the event type (never {@code null}) */ boolean supportsEventType(Class eventType); /** * Determine whether this listener actually supports the given source type. * The default implementation always returns {@code true}. * @param sourceType the source type, or {@code null} if no source */ default boolean supportsSourceType(@Nullable Class sourceType) { return true; } /** * Determine this listener's order in a set of listeners for the same event. * The default implementation returns {@link #LOWEST_PRECEDENCE}. */ @Override default int getOrder() { return LOWEST_PRECEDENCE; } } 2、 3、 "},"java/spring/spring事件.html":{"url":"java/spring/spring事件.html","title":"spring事件","keywords":"","body":" 定义事件 自定义事件,继承ApplicationEvent package com.basic.eventlistener.event; import com.basic.eventlistener.model.JumiaListing; import lombok.Data; import org.springframework.context.ApplicationEvent; import java.util.List; @Data public class ListingSaveEvent extends ApplicationEvent { private List jumiaListings; /** * 这里参数可以自己定义，可以多个 */ public ListingSaveEvent(Object source, List jumiaListings) { super(source); this.jumiaListings = jumiaListings; } } 定义Listener监听器(业务处理) 在方法上加上@Async和 @EventListener主键即可 package com.basic.eventlistener.listener; import com.basic.eventlistener.model.JumiaListing; import com.basic.eventlistener.event.ListingSaveEvent; import lombok.extern.slf4j.Slf4j; import org.springframework.context.event.EventListener; import org.springframework.scheduling.annotation.Async; import org.springframework.stereotype.Component; import java.util.List; @Slf4j @Component public class ListingSaveListener { @Async @EventListener public void listingSave(ListingSaveEvent listingSaveEvent) { log.info(\"线程名称：\", Thread.currentThread().getName()); List jumiaListings = listingSaveEvent.getJumiaListings(); if (jumiaListings == null) { return; } } } 调用 package com.basic.eventlistener; import com.basic.eventlistener.event.ListingSaveEvent; import com.basic.eventlistener.model.JumiaListing; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.ApplicationContext; import org.springframework.stereotype.Component; import java.util.ArrayList; import java.util.List; @Component public class EventDemo { @Autowired private ApplicationContext applicationContext; public void publishEvent() { // 业务处理 List listingList = new ArrayList<>(); // 发布订阅模式，有一个业务 event 专门存储这些数据到数据库 applicationContext.publishEvent(new ListingSaveEvent(this, listingList)); } } 实体 package com.basic.eventlistener.model; import com.baomidou.mybatisplus.extension.activerecord.Model; import lombok.Data; @Data public class JumiaListing extends Model { private static final long serialVersionUID = -7585917820758380041L; private String id; private String productCode; private String propertyCode; } "},"java/swagger/更改swagger上下文.html":{"url":"java/swagger/更改swagger上下文.html","title":"更改swagger上下文","keywords":"","body":" 由于应用配置的请求上下文地址和swagger里的地址有可能不同，比如线上的是/business/tobe/country/getList 而本地的则是/country/getList,所以有必要配置swagger的上下文地址 pom.xml 2.7.0 io.springfox springfox-swagger2 ${swagger.version} io.springfox springfox-swagger-ui ${swagger.version} properties swagger.context=/ SwaggerConfig package com.tobe.spcommon.common.config; import com.tobe.spcommon.common.bean.AppcliationSwaggerPathProvider; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.ParameterBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.schema.ModelRef; import springfox.documentation.service.ApiInfo; import springfox.documentation.service.Contact; import springfox.documentation.service.Parameter; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; import javax.annotation.Resource; import java.util.ArrayList; import java.util.List; @Configuration @EnableSwagger2 public class SwaggerConfig { public static final String BASE_PACKAGE_PREFFIX = \"com.tobe.spcommon.controller\"; @Resource AppcliationSwaggerPathProvider appcliationSwaggerPathProvider; private ApiInfo apiInfo() { // TODO: 修改下面描叙 return new ApiInfoBuilder().title(\"侵权项目\").description(\"侵权项目\") .termsOfServiceUrl(\"\") .contact(new Contact(\"liangqingxiang\", \"\", \"liangqingxiang@tobe.com\")).version(\"1.0.0\").build(); } @Bean public Docket createRestApi() { ParameterBuilder ticketPar = new ParameterBuilder(); List pars = new ArrayList(); ticketPar.name(\"Auth\").description(\"侵权接口授权码\") .modelRef(new ModelRef(\"string\")).parameterType(\"header\") .required(false).build(); //header中的ticket参数非必填，传空也可以 pars.add(ticketPar.build()); //根据每个方法名也知道当前方法在设置什么参数 return getDocketInstance(\"0、全部接口\", BASE_PACKAGE_PREFFIX) .pathProvider(appcliationSwaggerPathProvider) ;//.globalOperationParameters(pars); } /*@Bean public Docket groupRestApi1() { return getDocketInstance(\"1、订单模块\", BASE_PACKAGE_PREFFIX + \".order\"); } }*/ private Docket getDocketInstance(String groupName, String basePackage) { return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo()).groupName(groupName).select() .apis(RequestHandlerSelectors.basePackage(basePackage)).paths(PathSelectors.any()) .build(); } } AppcliationSwaggerPathProvider package com.tobe.spcommon.common.bean; import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Component; import springfox.documentation.spring.web.paths.AbstractPathProvider; /* https://www.jianshu.com/p/a62aa157942c */ @Component public class AppcliationSwaggerPathProvider extends AbstractPathProvider { @Value(\"${swagger.context}\") private String swaggerContext; public AppcliationSwaggerPathProvider() { } @Override protected String applicationPath() { return swaggerContext;//\"/business/tobe\"; } @Override protected String getDocumentationPath() { return swaggerContext;//\"/business/tobe\"; } } "},"java/util/http/RestTemplate用法.html":{"url":"java/util/http/RestTemplate用法.html","title":"RestTemplate用法","keywords":"","body":" 引用 @Autowired private RestTemplate restTemplate; 简单get请求 Map uriVariables = new HashMap<>(); HttpHeaders requestHeaders = new HttpHeaders(); HttpEntity requestEntity = new HttpEntity<>(requestHeaders); ResponseEntity response = restTemplate.exchange(url, org.springframework.http.HttpMethod.GET, requestEntity, String.class, uriVariables); HttpStatus status = response.getStatusCode(); String responseBody = response.getBody(); 简单post请求（不带参数） Map uriVariables = new HashMap<>(); HttpHeaders requestHeaders = new HttpHeaders(); HttpEntity requestEntity = new HttpEntity<>(requestHeaders); ResponseEntity response = restTemplate.exchange(url, org.springframework.http.HttpMethod.GET, requestEntity, String.class, uriVariables); HttpStatus status = response.getStatusCode(); String responseBody = response.getBody(); 简单post请求（带参数） Map uriVariables = new HashMap<>(); HttpHeaders requestHeaders = new HttpHeaders(); HttpEntity requestEntity = new HttpEntity<>(requestHeaders); ResponseEntity response = restTemplate.exchange(url, org.springframework.http.HttpMethod.GET, requestEntity, String.class, uriVariables); HttpStatus status = response.getStatusCode(); String responseBody = response.getBody(); 设置请求头 HttpHeaders requestHeaders = new HttpHeaders(); requestHeaders.add(\"Authorization\", \"Basic \" + Base64.getEncoder().encodeToString(Authorization.getBytes(\"utf-8\"))); requestHeaders.add(\"Accept\", \"application/json\"); 设置form表单提交（请求参数要用MultiValueMap） HttpHeaders requestHeaders = new HttpHeaders(); requestHeaders.setContentType(org.springframework.http.MediaType.APPLICATION_FORM_URLENCODED); 注意请求参数要用MultiValueMap MultiValueMap postParameters = new LinkedMultiValueMap<>(); postParameters.add(\"grant_type\", \"client_credentials\"); HttpEntity> requestEntity = new HttpEntity<>(postParameters, requestHeaders); "},"java/util/json/json序列化和反序列化工具.html":{"url":"java/util/json/json序列化和反序列化工具.html","title":"json序列化和反序列化工具","keywords":"","body":" 利用TypeReference将json反序列化成复杂对象 用法如下: String responseBody = \"\"; CommonResult resultCommonResult = JsonUtil.getObjectMapper() .readValue(responseBody, new TypeReference>() { }); 其中CommonResult如下 package com.basic.bean; import com.fasterxml.jackson.databind.PropertyNamingStrategy; import com.fasterxml.jackson.databind.annotation.JsonNaming; import lombok.Data; import lombok.extern.slf4j.Slf4j; import java.util.List; /** * 通用结果 */ @Slf4j @Data @JsonNaming(PropertyNamingStrategy.SnakeCaseStrategy.class) public class CommonResult { private String targetUrl = null; private T result = null; private boolean success = false; private boolean authorizedRequest = false; private List errorInfos; private String seqNo; private long costTime = -1L; } "},"java/util/日志/logback日志文件配置.html":{"url":"java/util/日志/logback日志文件配置.html","title":"logback日志文件配置","keywords":"","body":" level设置为DEBUG,则下面2个日志都打印出来 log.debug(\"这个是debug日志\"); log.info(\"这个是info日志\"); 若设置为info，则只打印 log.info(\"这个是info日志\"); 若想设置不同环境不同级别，则利用springProfile,如下： logback.xml demo %d %t %p %C{3000}:%L [%t] %m%n%n /logs/basic-server/basic-server.log /logs/basic-server/%d{YYYYMMdd}/basic-server.%i.log.zip 20MB 300 %d %p %C{30}:%L [%t] %m%n%n /logs/basic-server/basic-server_interface.log /logs/basic-server/%d{YYYYMMdd}/basic-server_interface.%i.log.zip 20MB 300 %d %m%n 0 512 true 0 512 true 　 参考：https://blog.csdn.net/qq_27886997/article/details/83178948 阅读： springboot日志变量配置 "},"java/xxl-job/xxl-job定时任务教程.html":{"url":"java/xxl-job/xxl-job定时任务教程.html","title":"xxl-job定时任务教程","keywords":"","body":" 1、pom引入 com.xuxueli xxl-job-core 1.9.0 2、配置文件 xxl: job: admin: addresses: http://192.168.1.1:8480/xxl-job-admin #调度中心url executor: appname: accountTask #当前任务器的名字 ip: port: 9502 #调度中心调度任务的端口 logpath: ../logs/xxl-job-executor-demo/ # 日志位置 accessToken: emVuZ3FpLWJhbmdnb29k #简单安全AccessToken package com.tobe.erp.fit.account.config; import com.xxl.job.core.executor.XxlJobExecutor; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration //@ComponentScan(basePackages = \"com.tobe.erp.cashweb.task\") public class XxlJobConfig { private Logger logger = LoggerFactory.getLogger(XxlJobConfig.class); @Value(\"${xxl.job.admin.addresses}\") private String addresses; @Value(\"${xxl.job.executor.appname}\") private String appname; @Value(\"${xxl.job.executor.ip}\") private String ip; @Value(\"${xxl.job.executor.port}\") private int port; @Value(\"${xxl.job.executor.logpath}\") private String logpath; @Value(\"${xxl.job.accessToken}\") private String accessToken; @Bean(initMethod = \"start\", destroyMethod = \"destroy\") public XxlJobExecutor xxlJobExecutor() { logger.info(\">>>>>>>>>>> xxl-job config init.\"); XxlJobExecutor xxlJobExecutor = new XxlJobExecutor(); xxlJobExecutor.setIp(ip); xxlJobExecutor.setPort(port); xxlJobExecutor.setAppName(appname); xxlJobExecutor.setAdminAddresses(addresses); xxlJobExecutor.setLogPath(logpath); xxlJobExecutor.setAccessToken(accessToken); return xxlJobExecutor; } } 3、调用 package com.tobe.erp.fit.account.task; import com.xxl.job.core.biz.model.ReturnT; import com.xxl.job.core.handler.IJobHandler; import com.xxl.job.core.handler.annotation.JobHandler; import com.xxl.job.core.log.XxlJobLogger; import fit.basic.convert.StringToDateConvert; import fit.basic.util.aop.WebExceptionConfig; import fit.basic.util.idwork.IdUtil; import org.springframework.stereotype.Component; import org.springframework.util.StringUtils; import java.util.Date; @JobHandler(value=\"notifyTask\") @Component public class notifyTask extends IJobHandler { @Override public ReturnT execute(String param) throws Exception { Date excuteDate = new Date(); StringBuffer message = new StringBuffer(); XxlJobLogger.log(\"开始任务。\"); try{ }catch (Exception e){ XxlJobLogger.log(\"信息: \"+ WebExceptionConfig.printStackTraceToString(e),e); } XxlJobLogger.log(\"结束任务\"); return SUCCESS; } } 官网：http://www.xuxueli.com/xxl-job/#/?id=%e6%ba%90%e7%a0%81%e4%bb%93%e5%ba%93%e5%9c%b0%e5%9d%80 "},"java/数据源/动态数据源.html":{"url":"java/数据源/动态数据源.html","title":"动态数据源","keywords":"","body":" 数据源相关属性配置 package com.tobe.spbusiness.common.config.datasource; import lombok.Data; @Data public class DynamicDatasourceProperty { public String driverClassname; public String maxWait; public String minIdle; public String initialSize; public String url; public String username; public String password; public String removeAbandoned; public String removeAbandonedTimeout; public String logAbandoned; public String opType; public String lookupkey; public boolean defaultDb=false; } 数据源相关属性配置列表 package com.tobe.spbusiness.common.config.datasource; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; import java.util.List; @Configuration @ConfigurationProperties(prefix = \"springplus\") @Data public class DynamicDatasourcePropertyList { List dynamicDatasources; } 动态数据源 package com.tobe.spbusiness.common.config.datasource; import com.alibaba.druid.pool.DruidDataSource; import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource; import org.springframework.lang.Nullable; import javax.sql.DataSource; public class DynamicDatasource extends AbstractRoutingDataSource { @Nullable @Override protected Object determineCurrentLookupKey() { return DynamicDatasourceThreadLocal.getLookupkey(); } protected DataSource determineTargetDataSource() { DataSource dataSource = super.determineTargetDataSource(); if (this.logger.isDebugEnabled()) { if (dataSource != null && dataSource instanceof DruidDataSource) { DruidDataSource druidDataSource = (DruidDataSource) dataSource; this.logger.debug(\"Current dataSource [\" + druidDataSource.getDbType() + \"],url=\" + druidDataSource.getUrl()); } } if (this.logger.isDebugEnabled()) { Object lookupKey = determineCurrentLookupKey(); this.logger.debug(\"Current lookupKey [\" + lookupKey + \"]\"); } return dataSource; } } } 数据源本地线程 package com.tobe.spbusiness.common.config.datasource; import org.springframework.context.annotation.Configuration; //@Configuration public class DynamicDatasourceThreadLocal { static ThreadLocal lookupkeyThreadLocal = new ThreadLocal<>(); public static String getLookupkey() { return lookupkeyThreadLocal.get(); } public static void setLookupkey(String lookupkey) { lookupkeyThreadLocal.set(lookupkey); } } 数据源切面 package com.tobe.spbusiness.common.config.datasource; import lombok.extern.slf4j.Slf4j; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.core.annotation.AnnotationUtils; import org.springframework.core.annotation.Order; import org.springframework.stereotype.Component; import java.lang.reflect.Method; @Order(0) @Component @Slf4j @Aspect public class DatasourceAspect { // @Resource // DynamicDatasourceThreadLocal dynamicDatasourceHolder; @Pointcut(\"execution(* com.tobe.spbusiness..service..*.impl..*.*(..))\") public void choiceTargetDBPointcut() { } @Around(\"choiceTargetDBPointcut()\") public Object choiceTargetDB(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { Method method = ((MethodSignature) proceedingJoinPoint.getSignature()).getMethod(); Object target = proceedingJoinPoint.getTarget(); Method realMethod = target.getClass().getMethod(method.getName(), method.getParameterTypes()); TargetDB targetDB = AnnotationUtils.findAnnotation(realMethod, TargetDB.class); if (targetDB != null) { String lookupkey = targetDB.lookupkey(); DynamicDatasourceThreadLocal.setLookupkey(lookupkey); } else { } try { return proceedingJoinPoint.proceed(); } catch (Throwable throwable) { throwable.printStackTrace(); return null; } finally { //DynamicDatasourceThreadLocal.setLookupkey(null); } } } 数据源注解 package com.tobe.spbusiness.common.config.datasource; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface TargetDB { String lookupkey(); //OpType opType() default OpType.WRITE; } 数据源配置 package com.tobe.spbusiness.common.config.datasource; import com.alibaba.druid.pool.DruidDataSource; import com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceBuilder; import com.baomidou.mybatisplus.spring.MybatisSqlSessionFactoryBean; import com.baomidou.mybatisplus.spring.boot.starter.MybatisPlusProperties; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.SqlSessionTemplate; import org.mybatis.spring.annotation.MapperScan; import org.springframework.beans.BeanUtils; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.io.support.PathMatchingResourcePatternResolver; import org.springframework.jdbc.datasource.DataSourceTransactionManager; import org.springframework.transaction.PlatformTransactionManager; import javax.annotation.Resource; import javax.sql.DataSource; import java.util.HashMap; import java.util.List; import java.util.Map; @Configuration @MapperScan(basePackages = {\"com.tobe.spbusiness.catchorder.mapper.**\"}, sqlSessionFactoryRef = \"sqlSessionFactory\") public class DataSourceConfig { @Resource DynamicDatasourcePropertyList dynamicDatasourcePropertyList; @Autowired MybatisPlusProperties mybatisPlusProperties; @Bean(\"datasource\") public DataSource datasource() { DynamicDatasource dynamicDatasource = new DynamicDatasource(); Map targetDataSources = new HashMap<>(); List dynamicDatasourceProperties = dynamicDatasourcePropertyList.getDynamicDatasources(); if (dynamicDatasourceProperties != null && !dynamicDatasourceProperties.isEmpty()) { dynamicDatasourceProperties.forEach(e -> { DruidDataSource druidDataSource = DruidDataSourceBuilder.create().build(); BeanUtils.copyProperties(e, druidDataSource); //validateConn(druidDataSource, \"select now()\");//特别注意sql server没有select now() targetDataSources.put(e.getLookupkey(), druidDataSource); if (e.isDefaultDb()) { dynamicDatasource.setDefaultTargetDataSource(druidDataSource); } }); } dynamicDatasource.setTargetDataSources(targetDataSources); return dynamicDatasource; } @Bean(name = \"dsTransactionManager\") public PlatformTransactionManager dsTransactionManager(){//(@Qualifier(\"dataSource\") DataSource dataSource) { DataSourceTransactionManager dataSourceTransactionManager = new DataSourceTransactionManager(datasource()); return dataSourceTransactionManager; } @Bean public SqlSessionFactory sqlSessionFactory() throws Exception { MybatisSqlSessionFactoryBean factoryBean = new MybatisSqlSessionFactoryBean(); //DataSourceConfig.java里配置必须配置dataSource数据源对应的事务，否则事务失效 factoryBean.setDataSource(datasource()); org.springframework.core.io.Resource[] mapperLocations = new PathMatchingResourcePatternResolver() .getResources(\"classpath*:**/*Mapper.xml\"); factoryBean.setMapperLocations(mapperLocations); factoryBean.setConfiguration(mybatisPlusProperties.getConfiguration()); return factoryBean.getObject(); } @Bean public SqlSessionTemplate sqlSessionTemplate() throws Exception { SqlSessionTemplate template = new SqlSessionTemplate(sqlSessionFactory()); return template; } private void validateConn(DruidDataSource druidDataSource, String sql) { druidDataSource.setValidationQuery(sql); druidDataSource.setTestWhileIdle(true); druidDataSource.setTestOnBorrow(false); druidDataSource.setTestOnReturn(false); } } property属性配置 springplus.dynamicDatasources[0].driverClassName=org.postgresql.Driver springplus.dynamicDatasources[0].maxWait=5000 springplus.dynamicDatasources[0].minIdle=5 springplus.dynamicDatasources[0].initialSize=5 springplus.dynamicDatasources[0].url=jdbc:postgresql://172.16.11.31:5432/nsp_dev springplus.dynamicDatasources[0].username=postgres springplus.dynamicDatasources[0].password=postgres springplus.dynamicDatasources[0].removeAbandoned=true springplus.dynamicDatasources[0].removeAbandonedTimeout=18000 springplus.dynamicDatasources[0].logAbandoned=true springplus.dynamicDatasources[0].opType=write springplus.dynamicDatasources[0].lookupkey=pgwrite springplus.dynamicDatasources[0].defaultDb=true springplus.dynamicDatasources[1].driverClassName=com.microsoft.sqlserver.jdbc.SQLServerDriver springplus.dynamicDatasources[1].maxWait=5000 springplus.dynamicDatasources[1].minIdle=5 springplus.dynamicDatasources[1].initialSize=5 springplus.dynamicDatasources[1].url=jdbc:sqlserver://sqltest.tobe.cn:1433;DatabaseName=192.168.1.1mon;sendStringParametersAsUnicode=false; springplus.dynamicDatasources[1].username=skb-test springplus.dynamicDatasources[1].password=tobe!@#123 springplus.dynamicDatasources[1].removeAbandoned=true springplus.dynamicDatasources[1].removeAbandonedTimeout=18000 springplus.dynamicDatasources[1].logAbandoned=true springplus.dynamicDatasources[1].opType=read springplus.dynamicDatasources[1].lookupkey=sqlserverRead springplus.dynamicDatasources[1].defaultDb=false 用法 @TargetDB(lookupkey = \"pgwrite\") @Transactional(value = \"dsTransactionManager\") public Long add(ShopAddVo shopAddVo) { Shop shop = new Shop(); BeanUtils.copyProperties(shopAddVo, shop); boolean result = insert(shop, false); if (!result) { throw new SOAException(\"添加失败\"); } Long shopId = shop.getId(); return shopId; } "},"java/缓存/guava/guava缓存简单使用三部曲.html":{"url":"java/缓存/guava/guava缓存简单使用三部曲.html","title":"guava缓存简单使用三部曲","keywords":"","body":" 1、pom com.google.guava guava 28.1-jre 2、定义缓存变量 static LoadingCache caches = CacheBuilder.newBuilder() .expireAfterWrite(7, TimeUnit.DAYS) .build( new CacheLoader() { public String load(String key) {//key是infringeUrl log.info(\"缓存key:{}\", key); if (!StringUtils.isEmpty(key)) { } return null; } }); 3、put设值到缓存 caches.put(\"infringeUrl\", item.getItemValue()); 4、获取使用缓存 String url=caches.getUnchecked(\"infringeUrl\"); 5、存在问题 https://blog.csdn.net/codingtu/article/details/89577316 "},"micro-service/rabbitmq/rabbitmq学习.html":{"url":"micro-service/rabbitmq/rabbitmq学习.html","title":"rabbitmq学习","keywords":"","body":" rabbitmq channel参数详解 RabbitMQ的下载和安装 spring.rabbitmq.publisher-confirms过时解决 rabbitmq：publisher confirms发送消息确认扩展 spring.rabbitmq.publisher-confirm-type详解 Spring Boot系列(8)——RabbitMQ确认、退回模式及死信队列——RabbitMQ确认、退回模式及死信队列) RabbitMQ（四）消息Ack确认机制 ``` "},"micro-service/springboot/springboot整合hikari数据源.html":{"url":"micro-service/springboot/springboot整合hikari数据源.html","title":"springboot整合hikari数据源","keywords":"","body":" 缺少hikari相关配置问题 刚开始配置数据源是下面这样，hikari相关的没配置,其他也没配置 spring.datasource.driver-class-name=oracle.jdbc.driver.OracleDriver spring.datasource.url = jdbc:oracle:thin:@ (DESCRIPTION =(ADDRESS = (PROTOCOL = TCP)(HOST = 10.20.100.63)(PORT = 1521))(CONNECT_DATA =(SERVER = DEDICATED)(SERVICE_NAME = fzsdbdev))) spring.datasource.username = UIOTSYSTEM_DEV spring.datasource.password = fzs123321 然后同事发现偶尔出现下面错误： Invalid Operation, NOT Connected). Possibly consider using a shorter maxLifetime value 数据源自动装配分析 org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration org.springframework.boot.autoconfigure.jdbc.DataSourceConfiguration.Hikari @Configuration(proxyBeanMethods = false) @ConditionalOnClass(HikariDataSource.class) @ConditionalOnMissingBean(DataSource.class) @ConditionalOnProperty(name = \"spring.datasource.type\", havingValue = \"com.zaxxer.hikari.HikariDataSource\", matchIfMissing = true) static class Hikari { @Bean @ConfigurationProperties(prefix = \"spring.datasource.hikari\") HikariDataSource dataSource(DataSourceProperties properties) { HikariDataSource dataSource = createDataSource(properties, HikariDataSource.class); if (StringUtils.hasText(properties.getName())) { dataSource.setPoolName(properties.getName()); } return dataSource; } } com.zaxxer.hikari.HikariConfig SpringBoot：关于默认连接池Hikari的源码剖析 Hikari 数据库连接池配置详解 ``` "},"micro-service/springboot/springboot整合log4j打印mybatis的sql日志.html":{"url":"micro-service/springboot/springboot整合log4j打印mybatis的sql日志.html","title":"springboot整合log4j打印mybatis的sql日志","keywords":"","body":" pom文件中假如依赖 org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-logging org.springframework.boot spring-boot-starter-log4j 1.3.8.RELEASE 在application.yml中配置mybatis输出日志： yml mybatis: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl property #mybatis.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl mybatis.configuration.log-impl=org.apache.ibatis.logging.log4j.Log4jImpl 上面2个StdOutImpl和Log4jImpl选其中一个就可以 配置扫描的包路径，不配置打印不了 logging.level.com.fzs.iotcard.common.business.mapper=DEBUG 参考： SpringBoot+MyBatis如何配置log4j日志输出（sql） "},"micro-service/springboot/springboot整合redisTemplate.html":{"url":"micro-service/springboot/springboot整合redisTemplate.html","title":"springboot整合redisTemplate","keywords":"","body":" import com.fasterxml.jackson.annotation.JsonAutoDetect; import com.fasterxml.jackson.annotation.PropertyAccessor; import com.fasterxml.jackson.databind.ObjectMapper; import com.fasterxml.jackson.databind.jsontype.impl.LaissezFaireSubTypeValidator; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.RedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; @Configuration public class RedisTemplateConfig { /** * redisTemplate 默认序列化使用的 jdkSerializeable, 存储二进制字节码, 所以一般需要自定义序列化类 * https://www.cnblogs.com/puzhiwei/p/12519304.html * @return */ @Bean public RedisTemplate redisTemplateSerializer(LettuceConnectionFactory lettuceConnectionFactory) { // 设置序列化 Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper objectMapper = new ObjectMapper(); // 指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和public objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer等会跑出异常 objectMapper.activateDefaultTyping(LaissezFaireSubTypeValidator.instance, ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); RedisSerializer stringSerializer = new StringRedisSerializer(); // 配置redisTemplate RedisTemplate redisTemplate = new RedisTemplate(); redisTemplate.setConnectionFactory(lettuceConnectionFactory); // key序列化 redisTemplate.setKeySerializer(stringSerializer); // value序列化 redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); // Hash key序列化 redisTemplate.setHashKeySerializer(stringSerializer); // Hash value序列化 redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; } } 参考： https://www.cnblogs.com/puzhiwei/p/12519304.html "},"micro-service/文档管理/japidoc文档管理.html":{"url":"micro-service/文档管理/japidoc文档管理.html","title":"japidoc文档管理","keywords":"","body":" pom引入 io.github.yedaxia japidocs 1.4.4 新建个测试类来执行就可以 package com.tobe.apidoc; import io.github.yedaxia.apidocs.Docs; import io.github.yedaxia.apidocs.DocsConfig; import io.github.yedaxia.apidocs.plugin.markdown.MarkdownDocPlugin; public class JapiDocTest { public static void main(String args[]) { DocsConfig config = new DocsConfig(); // 项目根目录 config.setProjectPath(\"D:\\\\idea-workspace-blog\\\\lqx-project-demo-github\\\\basic-server\"); // 项目名称 config.setProjectName(\"japi-docs\"); // 声明该API的版本 config.setApiVersion(\"V1.2\"); // 生成API 文档所在目录 config.setDocsPath(\"d:\\\\japi\"); // 配置自动生成 config.setAutoGenerate(Boolean.TRUE); //导出markdown config.addPlugin(new MarkdownDocPlugin()); // 执行生成文档 Docs.buildHtmlDocs(config); } } 查看结果 "},"micro-service/配置中心/appollo/apollo客户端配置使用.html":{"url":"micro-service/配置中心/appollo/apollo客户端配置使用.html","title":"apollo客户端配置使用.md","keywords":"","body":" 1、pom添加依赖 com.ctrip.framework.apollo apollo-client 1.4.0 2、启动类添加@EnableApolloConfig @SpringBootApplication(exclude = {DataSourceAutoConfiguration.class, HibernateJpaAutoConfiguration.class, DruidDataSourceAutoConfigure.class}) @EnableSwagger2 @EnableApolloConfig public class FzsIotCardApplication { public static void main(String[] args) { SpringApplication app = new SpringApplication(FzsIotCardApplication.class); app.setBannerMode(Banner.Mode.OFF); app.run(args); } } 3、application.properties增加配置 # 方式1 springboot的配置properties或yml文件添加下面的 app.id=fzs_iot_card2 # 方式2：环境变量里加-Dapp.id=YOUR-APP-ID # 方式3：classpath:/META-INF/app.properties文件存在 内容：app.id=YOUR-APP-ID apollo.meta=http://config-service-url:port ##下面这个不配也可以的 #env=DEV 4.使用 新建controller，里面通过${}引用，例如${swagger.context} @Slf4j @Api(value = \"API\", description = \"API\") @RestController @RequestMapping(\"/tIotCard\") public class TIotCardController { @Value(\"${swagger.context}\") private String swaggerContext; @Value(\"${test.testabc}\") private String testabc; @GetMapping(value = \"/get\") @ApiOperation(value = \"获取\", notes = \"\") public String get() { return swaggerContext+testabc; } } 使用参考： https://github.com/ctripcorp/apollo/wiki/Java%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97#3213-spring-boot%E9%9B%86%E6%88%90%E6%96%B9%E5%BC%8F%E6%8E%A8%E8%8D%90 "},"micro-service/配置中心/nacos/nacos-spring-cloud学习.html":{"url":"micro-service/配置中心/nacos/nacos-spring-cloud学习.html","title":"nacos-spring-cloud学习","keywords":"","body":" 1、 2、 3、 ``` "},"micro-service/配置中心/nacos/nacos安装和入门学习.html":{"url":"micro-service/配置中心/nacos/nacos安装和入门学习.html","title":"nacos安装和入门学习","keywords":"","body":" 安装和配置启动 1、下载nacos 下载地址： https://github.com/alibaba/nacos/releases 解压到某目录，cd 到nacos\\conf文件夹下 2、修改nacos\\conf\\application.properties配置数据库信息 文件内容如下： ### Count of DB: db.num=1 ### Connect URL of DB: db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC db.user=root db.password=root 3、执行nacos\\conf\\nacos-mysql.sql数据库脚本 在mysql中创建nacos数据库，然后执行nacos\\conf\\nacos-mysql.sql数据库脚本 4、 startup.cmd -m standalone启动nacos cd到nacos\\bin目录，执行 startup.cmd -m standalone 注意单机模式下要加上参数 -m standalone 否则启动失败的 5、登录Console看后台 启动完成后，登录http://10.20.11.161:8848/nacos/index.html 默认用户名和密码都是nacos 服务注册&发现和配置管理 1、服务注册 curl -X POST \"http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName&ip=20.18.7.10&port=8080\" 2、服务发现 curl -X GET \"http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=nacos.naming.serviceName\" 返回 {\"dom\":\"nacos.naming.serviceName\",\"hosts\":[],\"name\":\"DEFAULT_GROUP@@nacos.naming.serviceName\",\"cacheMillis\":3000,\"lastRefTime\":1600085004554,\"checksum\":\"7f882d81002bc22181203d423a20a16d\",\"useSpecifiedURL\":false,\"clusters\":\"\",\"env\":\"\",\"metadata\":{}} 3、发布配置 curl -X POST \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&group=test&content=HelloWorld\" 4、获取配置 curl -X GET \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&group=test\" 参考： https://nacos.io/zh-cn/docs/quick-start.html "},"micro-service/限流/sentinel/基础/sentinel学习.html":{"url":"micro-service/限流/sentinel/基础/sentinel学习.html","title":"sentinel学习","keywords":"","body":" 技术攻克 本地测试流量控制(流量规则存在内存中) 控制台如何发送规则到应用的，发送的规则是什么样的格式的 应用如何连到控制台,心跳检测怎么实现 本地测试流量控制(流量规则配置在apollo) 控制台如何设置规则并发送到Apollo的原理，发送到apollo的数据是怎么样的 应用集群如何配置， springboot下，流量规则在Apollo，如何初始化流量规则 外来流量，在账号授权情况下，如何控制某账号的速率 集群失效，单机默认限流规则 调接口后异常处理 项目启动，自动获取Apollo上的集群配置信息，而不用手动触发推送 sentinel如何做到有访问流量时，才实例化集群?? 故障切换如何实现 集群总体阀值原理 http://localhost:19988/testBlock?t=-1 http://localhost:8719/getRules?type=flow 相关文档 新手指南 注解支持 Sentinel 控制台 启动配置项 控制台接入 动态规则扩展 在生产环境中使用 Sentinel 如何使用 Sentinel工作主流程 博客学习 Spring Cloud Alibaba Sentinel 集群流控 Sentinel 控制台（集群流控管理） com.alibaba.csp.sentinel.slots.block.flow.FlowRuleUtil#isValidRule "},"micro-service/限流/sentinel/基础/sentinel通过spi方式注册数据源.html":{"url":"micro-service/限流/sentinel/基础/sentinel通过spi方式注册数据源.html","title":"sentinel通过spi方式注册数据源","keywords":"","body":" 1、 Sentinel初始化之InitFunc实现类加载 参考： https://github.com/alibaba/Sentinel/wiki/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%99%E6%89%A9%E5%B1%95 ApolloDataSourceProperties SentinelProperties sentinel加载Apollo数据源相关入口 SentinelWebAutoConfiguration com.alibaba.cloud.sentinel.custom.SentinelDataSourceHandler com.alibaba.cloud.sentinel.custom.SentinelDataSourceHandler#afterSingletonsInstantiated com.alibaba.cloud.sentinel.datasource.factorybean.ApolloDataSourceFactoryBean#getObject com.alibaba.csp.sentinel.datasource.apollo.ApolloDataSource#ApolloDataSource private void loadAndUpdateRules() { try { T newValue = this.loadConfig(); if (newValue == null) { RecordLog.warn(\"[ApolloDataSource] WARN: rule config is null, you may have to check your data source\", new Object[0]); } this.getProperty().updateValue(newValue); } catch (Throwable var2) { RecordLog.warn(\"[ApolloDataSource] Error when loading rule config\", var2); } } 其他：少量参考，有些配置不适用 http://blog.didispace.com/spring-cloud-alibaba-sentinel-2-2/ 2、 3、 ``` "},"micro-service/限流/sentinel/控制台/sentinel控制台.html":{"url":"micro-service/限流/sentinel/控制台/sentinel控制台.html","title":"sentinel控制台","keywords":"","body":" 启动和访问控制台： java -Dserver.port=9090 -Dcsp.sentinel.dashboard.server=localhost:9090 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard-1.8.0.jar 默认用户名和密码都是 sentinel 应用连接 Sentinel 控制台 Sentinel 开源控制台支持实时监控和规则管理。接入控制台的步骤如下： （1）下载控制台 jar 包并在本地启动：可以参见 此处文档。 （2）客户端接入控制台，需要： 客户端需要引入 Transport 模块来与 Sentinel 控制台进行通信。您可以通过 pom.xml 引入 JAR 包: com.alibaba.csp sentinel-transport-simple-http 1.8.0 启动时加入 JVM 参数 -Dcsp.sentinel.dashboard.server=consoleIp:port 指定控制台地址和端口。更多的参数参见 启动参数文档。 确保应用端有访问量 比如我的： 在edit configurations -> vm opitons添加如下即可： -Dcsp.sentinel.dashboard.server=localhost:9090 -Dserver.port=8091 -Dcsp.sentinel.log.use.pid=true springboot的或者cloud可以在配置文件中指定控制台的地址和端口，参考如下： Spring Cloud Alibaba Sentinel 参考： Sentinel 控制台 启动配置项 注意：若在本地启动多个 Demo 示例，需要加上 -Dcsp.sentinel.log.use.pid=true 参数，否则控制台显示监控会不准确。 1、 2、 3、 ``` "},"micro-service/限流/sentinel/源码分析/sentinel源码解析1-SentinelResource注解源码分析.html":{"url":"micro-service/限流/sentinel/源码分析/sentinel源码解析1-SentinelResource注解源码分析.html","title":"SentinelResource注解源码分析","keywords":"","body":" SentinelResource注解切面处理类源码如下： com.alibaba.csp.sentinel.annotation.aspectj.SentinelResourceAspect @Aspect public class SentinelResourceAspect extends AbstractSentinelAspectSupport { @Pointcut(\"@annotation(com.alibaba.csp.sentinel.annotation.SentinelResource)\") public void sentinelResourceAnnotationPointcut() { } @Around(\"sentinelResourceAnnotationPointcut()\") public Object invokeResourceWithSentinel(ProceedingJoinPoint pjp) throws Throwable { Method originMethod = resolveMethod(pjp); SentinelResource annotation = originMethod.getAnnotation(SentinelResource.class); if (annotation == null) { // Should not go through here. throw new IllegalStateException(\"Wrong state for SentinelResource annotation\"); } String resourceName = getResourceName(annotation.value(), originMethod); EntryType entryType = annotation.entryType(); int resourceType = annotation.resourceType(); Entry entry = null; try { entry = SphU.entry(resourceName, resourceType, entryType, pjp.getArgs()); Object result = pjp.proceed(); return result; } catch (BlockException ex) { return handleBlockException(pjp, annotation, ex); } catch (Throwable ex) { Class[] exceptionsToIgnore = annotation.exceptionsToIgnore(); // The ignore list will be checked first. if (exceptionsToIgnore.length > 0 && exceptionBelongsTo(ex, exceptionsToIgnore)) { throw ex; } if (exceptionBelongsTo(ex, annotation.exceptionsToTrace())) { traceException(ex); return handleFallback(pjp, annotation, ex); } // No fallback function can handle the exception, so throw it out. throw ex; } finally { if (entry != null) { entry.exit(1, pjp.getArgs()); } } } } 分析： 可以看到，关键入口都是 entry = SphU.entry(resourceName, resourceType, entryType, pjp.getArgs()); 其中resourceName是从注解那里获取的，所以在这个步骤上，如果我们要实现账号级别的 限流控制，可以这样设计：1、定义一个账号-资源关联表，缓存起来2、SentinelResource注解标注在controller或serviceImpl层，resourceName可以固定某个字符串，但是这个还不是真正的 资源名称，3、自己写个类似SentinelResourceAspect的，请求进来时，从请求头中获取账号信息，从缓存(步骤1)中获取账号对应的资源，将resourceName(步骤2)加上资源 这个才是真正要限流的资源 举例子： @SentinelResource(value = \"flowSyncResource\",blockHandler = \"sayHelloBlockHandler\") public String sayHello(String name) { System.out.println(getCurrentMachineId() + \",\" + name + \",\" + new Date()); return \"Hello, \" + name; } 然后自己定义个MySentinelResourceAspect,在里面组装资源名为flowSyncResource-AAA等 ``` "},"micro-service/限流/sentinel/源码分析/sentinel源码解析2-sentinel命名空间namespace分析.html":{"url":"micro-service/限流/sentinel/源码分析/sentinel源码解析2-sentinel命名空间namespace分析.html","title":"sentinel命名空间namespace分析","keywords":"","body":" Namespace注册和获取以及设值 appName取值 设值入口com.alibaba.csp.sentinel.config.SentinelConfig#resolveAppName 取值顺序逻辑如下： 环境变量system env中取csp.sentinel.app.name property中取csp.sentinel.app.name property中取project.name 从property中取sun.java.command(正在执行的类) 根据上面的取值，我们可以如下配置启动参数，这个会影响sentinel的namespace 例如启动参数配置： -Dserver.port=19988 -Dproject.name=ClusterDemoApplication -Dcsp.sentinel.log.use.pid=true -Dcsp.sentinel.app.name=SYS_IOT.flow-sync-sentinel -Dserver.port=19989 -Dproject.name=ClusterDemoApplication2 -Dcsp.sentinel.log.use.pid=true -Dcsp.sentinel.app.name=SYS_IOT.flow-sync-sentinel -Dserver.port=19990 -Dproject.name=ClusterDemoApplication3 -Dcsp.sentinel.log.use.pid=true -Dcsp.sentinel.app.name=SYS_IOT.flow-sync-sentinel 上面由于设置了-Dcsp.sentinel.app.name=SYS_IOT.flow-sync-sentinel 所以在sentinel-dashbord控制台上左边菜单栏看到的是SYS_IOT.flow-sync-sentinel 另外启动参数配置的，参考类SentinelConfig appName用途 入口：com.alibaba.csp.sentinel.cluster.server.SentinelDefaultTokenServer#handleEmbeddedStart 嵌入式集群启动 com.alibaba.csp.sentinel.cluster.server.SentinelDefaultTokenServer#handleEmbeddedStart 配置供应者注册器获取Namespace com.alibaba.csp.sentinel.cluster.registry.ConfigSupplierRegistry#getNamespaceSupplier 配置供应者注册器返回默认Namespace com.alibaba.csp.sentinel.cluster.registry.ConfigSupplierRegistry#DEFAULT_APP_NAME_SUPPLIER 配置供应者注册器实际上返回AppNameUtil.getAppName() com.alibaba.csp.sentinel.util.AppNameUtil#getAppName AppNameUtil.getAppName()里返回的是SentinelConfig#getAppName com.alibaba.csp.sentinel.config.SentinelConfig#getAppName namespace加载分析 namespace 入口：com.alibaba.csp.sentinel.cluster.server.SentinelDefaultTokenServer#handleEmbeddedStart private void handleEmbeddedStart() { //先从环境变量参数，配置文件属性里，或者启动的类中获取namespace String namespace = ConfigSupplierRegistry.getNamespaceSupplier().get();//(1) if (StringUtil.isNotEmpty(namespace)) { // Mark server global mode as embedded. ClusterServerConfigManager.setEmbedded(true);//(2) if (!ClusterServerConfigManager.getNamespaceSet().contains(namespace)) {//(3) Set namespaceSet = new HashSet<>(ClusterServerConfigManager.getNamespaceSet()); namespaceSet.add(namespace); ClusterServerConfigManager.loadServerNamespaceSet(namespaceSet);//(4) } // Register self to connection group. ConnectionManager.addConnection(namespace, HostNameUtil.getIp()); } } 分析： (1)先从环境变量参数，配置文件属性里，或者启动的类中获取namespace (2)若获取到namespace不为空，则集群配置管理器ClusterServerConfigManager设置为嵌入式 (3)若ClusterServerConfigManager中的namespaceSet命名集合不包含namespace，则新建namespaceSet集合， 新建实例化时添加默认namespace为default (4)调用loadServerNamespaceSet加载步骤(1)的namespace 这个会从Apollo获取该命名空间最新的配置的 ``` "},"micro-service/限流/sentinel/集群流控/sentinel集群流控.html":{"url":"micro-service/限流/sentinel/集群流控/sentinel集群流控.html","title":"sentinel集群流控","keywords":"","body":" "},"micro-service/限流/sentinel/集群流控/sentinel集群流控1-配置说明.html":{"url":"micro-service/限流/sentinel/集群流控/sentinel集群流控1-配置说明.html","title":"sentinel集群流控之配置说明","keywords":"","body":" 集群流量规则限流配置 [ { \"resource\": \"sayHelloResource3\", \"count\": 12, \"clusterMode\": true, \"clusterConfig\": { \"flowId\": \"1\", \"thresholdType\": 0, \"fallbackToLocalWhenFail\": true } }, { \"resource\": \"test3\", \"count\": 60, \"clusterMode\": true, \"clusterConfig\": { \"flowId\": \"2\", \"thresholdType\": 0, \"fallbackToLocalWhenFail\": true } } ] resource //要限流的资源名称,对应@SentinelResource注解里的name count //每秒限流的数目 fallbackToLocalWhenFail // 在 client 连接失败或通信失败时，是否退化到本地的限流模式 flowId // （必需）全局唯一的规则 ID，由集群限流管控端分配. thresholdType // 阈值模式，默认（0）为单机均摊，1 为全局阈值. https://github.com/alibaba/Sentinel/wiki/%E9%9B%86%E7%BE%A4%E6%B5%81%E6%8E%A7#%E9%9B%86%E7%BE%A4%E6%B5%81%E6%8E%A7%E8%A7%84%E5%88%99 集群相关ip和端口配置 [ { \"clientSet\": [ \"10.20.11.237@8721\", \"10.20.11.237@8719\" ], \"ip\": \"10.20.11.237\", \"machineId\": \"10.20.11.237@8719\", \"port\": 17631 } ] ip : 分配token的tokenServer的ip port ： 分配token的tokenServer的端口(注：这个端口应该是给控制台推送规则到tokenServer时使用的，具体看下面的分析。 这个port也用在tokenServer和tokenClient之间通信，) machineId : tokenServer的机器ip加port端口(这端口是tokenServer和tokenClient之间通信的？？？还是干嘛的 是用来区分同一台机器的同个应用的不同启动服务？？？) clientSet ： 客户端集合 上面配置对应类com.fzs.iotcard.sentinel.cluster.core.entity.ClusterGroupEntity @Data @ToString public class ClusterGroupEntity { private String machineId; private String ip; private Integer port; private Set clientSet; } 启动配置参数 -Dserver.port=8090 -Dcsp.sentinel.log.use.pid=true -Dcsp.sentinel.log.use.pid是防止本地启动同一应用的多个服务而导致日志不正常用的 "},"micro-service/限流/sentinel/集群流控/sentinel集群流控2-ServerTransportConfig.html":{"url":"micro-service/限流/sentinel/集群流控/sentinel集群流控2-ServerTransportConfig.html","title":"sentinel集群流控-ServerTransportConfig","keywords":"","body":" ServerTransportConfig\\配置transport.port用途 8719端口配置如下： iotcard.cloud.sentinel.transport.port=8719 对应配置类为com.alibaba.csp.sentinel.cluster.server.config.ServerTransportConfig public class ServerTransportConfig { public static final int DEFAULT_IDLE_SECONDS = 600; private int port; private int idleSeconds; 调试发现当点击控制台的集群流控，就跳到 com.alibaba.csp.sentinel.cluster.server.command.handler.FetchClusterServerInfoCommandHandler#handle public CommandResponse handle(CommandRequest request) { JSONObject info = new JSONObject(); JSONArray connectionGroups = new JSONArray(); Set namespaceSet = ClusterServerConfigManager.getNamespaceSet(); Iterator var5 = namespaceSet.iterator(); while(var5.hasNext()) { String namespace = (String)var5.next(); ConnectionGroup group = ConnectionManager.getOrCreateConnectionGroup(namespace); if (group != null) { connectionGroups.add(group); } } ServerTransportConfig transportConfig = (new ServerTransportConfig()).setPort(ClusterServerConfigManager.getPort()).setIdleSeconds(ClusterServerConfigManager.getIdleSeconds()); ServerFlowConfig flowConfig = (new ServerFlowConfig()).setExceedCount(ClusterServerConfigManager.getExceedCount()).setMaxOccupyRatio(ClusterServerConfigManager.getMaxOccupyRatio()).setIntervalMs(ClusterServerConfigManager.getIntervalMs()).setSampleCount(ClusterServerConfigManager.getSampleCount()).setMaxAllowedQps(ClusterServerConfigManager.getMaxAllowedQps()); JSONArray requestLimitData = this.buildRequestLimitData(namespaceSet); info.fluentPut(\"port\", ClusterServerConfigManager.getPort()).fluentPut(\"connection\", connectionGroups).fluentPut(\"requestLimitData\", requestLimitData).fluentPut(\"transport\", transportConfig).fluentPut(\"flow\", flowConfig).fluentPut(\"namespaceSet\", namespaceSet).fluentPut(\"embedded\", ClusterServerConfigManager.isEmbedded()); info.put(\"appName\", AppNameUtil.getAppName()); return CommandResponse.ofSuccess(info.toJSONString()); } 其中这行设置端口 ServerTransportConfig transportConfig = (new ServerTransportConfig()).setPort(ClusterServerConfigManager.getPort()).setIdleSeconds(ClusterServerConfigManager.getIdleSeconds()); 分析：由于控制台要推送规则到配置中心或者客户端，则必须要连接到客户端，所以客户端必须提供个端口 才能建立连接，所以有默认个18730端口,所以ServerTransportConfig中的port就是这个端口 服务端配置类： 调用链： setPort:45, ServerTransportConfig (com.alibaba.csp.sentinel.cluster.server.config) handle:54, FetchClusterServerInfoCommandHandler (com.alibaba.csp.sentinel.cluster.server.command.handler) run:103, HttpEventTask (com.alibaba.csp.sentinel.transport.command.http) call:511, Executors$RunnableAdapter (java.util.concurrent) run$$$capture:266, FutureTask (java.util.concurrent) run:-1, FutureTask (java.util.concurrent) - Async stack trace :151, FutureTask (java.util.concurrent) newTaskFor:87, AbstractExecutorService (java.util.concurrent) submit:111, AbstractExecutorService (java.util.concurrent) run:191, SimpleHttpCommandCenter$ServerThread (com.alibaba.csp.sentinel.transport.command) call:511, Executors$RunnableAdapter (java.util.concurrent) run$$$capture:266, FutureTask (java.util.concurrent) run:-1, FutureTask (java.util.concurrent) - Async stack trace :151, FutureTask (java.util.concurrent) newTaskFor:87, AbstractExecutorService (java.util.concurrent) submit:111, AbstractExecutorService (java.util.concurrent) submit:678, Executors$DelegatedExecutorService (java.util.concurrent) run:106, SimpleHttpCommandCenter$2 (com.alibaba.csp.sentinel.transport.command) run:745, Thread (java.lang) 分析： 调用ClusterStateManager.registerProperty(clusterModeDs.getProperty());设置服务端状态时， 触发 init:40, CommandCenterInitFunc (com.alibaba.csp.sentinel.transport.init) 继续触发 start:75, SimpleHttpCommandCenter (com.alibaba.csp.sentinel.transport.command) 而在SimpleHttpCommandCenter.start里会新建个serverSocket来监听接收消息 executor.submit(new ServerThread(serverSocket)); 如下： 这里收到消息时会开线程调用执行HttpEventTask这个任务 class ServerThread extends Thread { private ServerSocket serverSocket; ServerThread(ServerSocket s) { this.serverSocket = s; setName(\"sentinel-courier-server-accept-thread\"); } @Override public void run() { while (true) { Socket socket = null; try { socket = this.serverSocket.accept(); setSocketSoTimeout(socket); HttpEventTask eventTask = new HttpEventTask(socket); bizExecutor.submit(eventTask); } catch (Exception e) { CommandCenterLog.info(\"Server error\", e); if (socket != null) { try { socket.close(); } catch (Exception e1) { CommandCenterLog.info(\"Error when closing an opened socket\", e1); } } try { // In case of infinite log. Thread.sleep(10); } catch (InterruptedException e1) { // Indicates the task should stop. break; } } } } } 那什么时候触发这里的接收消息，当在sentinel控制台里点击集群监控，就会触发到这里 如下： 控制台调用cluster/server/info这个http请求获取集群服务器的信息，上面的ServerSocket这个监听 会根据请求路径来解析到FetchClusterServerInfoCommandHandler处理器所以会有下面的HttpEventTask任务跳转到FetchClusterServerInfoCommandHandler处理 handle:54, FetchClusterServerInfoCommandHandler (com.alibaba.csp.sentinel.cluster.server.command.handler) run:103, HttpEventTask (com.alibaba.csp.sentinel.transport.command.http) 问题： 看了sentinel控制台集群流控的源码，好像没有调用http请求，那这个接收到的socket请求来自哪里的？？？ 难度是在新建ServerThread这个serverSocket线程时 new HttpEventTask(socket)这个时执行的，应该是?? 但是为什么点击sentinel控制台的集群监控会触发这个调试呢？？ sentinel控制台调用地方： 直接搜索cluster/server/info点调用即可出来 前端入口： Request URL: http://localhost:9090/cluster/server_state/FlowSyncApplication com.alibaba.csp.sentinel.dashboard.controller.cluster.ClusterConfigController#apiGetClusterServerStateOfApp com.alibaba.csp.sentinel.dashboard.service.ClusterConfigService#getClusterUniversalState(java.lang.String) public CompletableFuture> getClusterUniversalState(String app) { if (StringUtil.isBlank(app)) { return AsyncUtils.newFailedFuture(new IllegalArgumentException(\"app cannot be empty\")); } AppInfo appInfo = appManagement.getDetailApp(app); if (appInfo == null || appInfo.getMachines() == null) { return CompletableFuture.completedFuture(new ArrayList<>()); } List> futures = appInfo.getMachines().stream() .filter(e -> e.isHealthy()) .map(machine -> getClusterUniversalState(app, machine.getIp(), machine.getPort()) .thenApply(e -> new ClusterUniversalStatePairVO(machine.getIp(), machine.getPort(), e))) .collect(Collectors.toList()); return AsyncUtils.sequenceSuccessFuture(futures); } 可以看到是根据machine的ip和port端口(默认8719)来请求客户端的，这个machine来自appManagement，具体是由心跳检测上报在sentinel控制台的 具体又调到getClusterUniversalState方法 public CompletableFuture getClusterUniversalState(String app, String ip, int port) { return sentinelApiClient.fetchClusterMode(ip, port) .thenApply(e -> new ClusterUniversalStateVO().setStateInfo(e)) .thenCompose(vo -> { if (vo.getStateInfo().getClientAvailable()) { return sentinelApiClient.fetchClusterClientInfoAndConfig(ip, port) .thenApply(cc -> vo.setClient(new ClusterClientStateVO().setClientConfig(cc))); } else { return CompletableFuture.completedFuture(vo); } }).thenCompose(vo -> { if (vo.getStateInfo().getServerAvailable()) { return sentinelApiClient.fetchClusterServerBasicInfo(ip, port) .thenApply(vo::setServer); } else { return CompletableFuture.completedFuture(vo); } }); } 又调到sentinelApiClient.fetchClusterServerBasicInfo(ip, port) 下面其中FETCH_CLUSTER_SERVER_BASIC_INFO_PATH就是cluster/server/info public CompletableFuture fetchClusterServerBasicInfo(String ip, int port) { if (StringUtil.isBlank(ip) || port JSON.parseObject(r, ClusterServerStateVO.class)); } catch (Exception ex) { logger.warn(\"Error when fetching cluster sever all config and basic info\", ex); return AsyncUtils.newFailedFuture(ex); } } 看日志Socket[addr=/10.20.11.237,port=13019,localport=8720] 可以看到接收到的端口是8720 另外关于port和localport的: java.net.SocketImpl /** * The port number on the remote host to which this socket is connected. */ protected int port; /** * The local port number to which this socket is connected. */ protected int localport; localport 是本机端口， socket port 应该是 server port 吧，表示对端端口 tcp/ip 中使用 本地ip:port 远程 ip :port 表示一个通信 参考：https://zhidao.baidu.com/question/691871712846751924.html 而FetchClusterServerInfoCommandHandler setPort:45, ServerTransportConfig (com.alibaba.csp.sentinel.cluster.server.config) handle:54, FetchClusterServerInfoCommandHandler (com.alibaba.csp.sentinel.cluster.server.command.handler) "},"micro-service/限流/sentinel/集群流控/sentinel集群流控3-TransportConfig.html":{"url":"micro-service/限流/sentinel/集群流控/sentinel集群流控3-TransportConfig.html","title":"sentinel集群流控之TransportConfig","keywords":"","body":" TransportConfig TransportConfig.runtimePort这个是配置 \"machineId\": \"10.20.11.237@8719\" 用的 public class TransportConfig { public static final String CONSOLE_SERVER = \"csp.sentinel.dashboard.server\"; public static final String SERVER_PORT = \"csp.sentinel.api.port\"; public static final String HEARTBEAT_INTERVAL_MS = \"csp.sentinel.heartbeat.interval.ms\"; public static final String HEARTBEAT_CLIENT_IP = \"csp.sentinel.heartbeat.client.ip\"; public static final String HEARTBEAT_API_PATH = \"csp.sentinel.heartbeat.api.path\"; public static final String HEARTBEAT_DEFAULT_PATH = \"/registry/machine\"; private static int runtimePort = -1; 有三个调用的地方 第一个地方： com.alibaba.csp.sentinel.transport.command.netty.HttpServer#start int retryCount = 0; ChannelFuture channelFuture = null; // loop for an successful binding while (true) { int newPort = getNewPort(port, retryCount); try { channelFuture = b.bind(newPort).sync(); TransportConfig.setRuntimePort(newPort); CommandCenterLog.info(\"[NettyHttpCommandCenter] Begin listening at port \" + newPort); break; } catch (Exception e) { TimeUnit.MILLISECONDS.sleep(30); RecordLog.warn(\"[HttpServer] Netty server bind error, port={}, retry={}\", newPort, retryCount); retryCount ++; } } /** * Increase port number every 3 tries. * * @param basePort base port to start * @param retryCount retry count * @return next calculated port */ private int getNewPort(int basePort, int retryCount) { return basePort + retryCount / 3; } io.netty.bootstrap.AbstractBootstrap#bind(int) public ChannelFuture bind(int inetPort) { return this.bind(new InetSocketAddress(inetPort)); } 分析： 1、先获取端口getNewPort(port, retryCount)2、绑定端口b.bind(newPort).sync(); 3、绑定失败则retryCount ++循环重新获取端口,所以端口会递增 问题： 1、什么时候HttpServer#start方法会调用到??? 第二个地方： com.alibaba.csp.sentinel.transport.command.SimpleHttpCommandCenter#start @Override public void run() { boolean success = false; ServerSocket serverSocket = getServerSocketFromBasePort(port); if (serverSocket != null) { CommandCenterLog.info(\"[CommandCenter] Begin listening at port \" + serverSocket.getLocalPort()); socketReference = serverSocket; executor.submit(new ServerThread(serverSocket)); success = true; port = serverSocket.getLocalPort(); } else { CommandCenterLog.info(\"[CommandCenter] chooses port fail, http command center will not work\"); } if (!success) { port = PORT_UNINITIALIZED; } TransportConfig.setRuntimePort(port); executor.shutdown(); } } private static ServerSocket getServerSocketFromBasePort(int basePort) { int tryCount = 0; while(true) { try { ServerSocket server = new ServerSocket(basePort + tryCount / 3, 100); server.setReuseAddress(true); return server; } catch (IOException var5) { ++tryCount; try { TimeUnit.MILLISECONDS.sleep(30L); } catch (InterruptedException var4) { return null; } } } } 创建的ServerSocket如下： ServerSocket[addr=0.0.0.0/0.0.0.0,localport=8720] 分析： 1、这里也是尝试根据port建立ServerSocket new ServerSocket(basePort + tryCount / 3, 100); 2、然后获取建立的ServerSocket对应真正的端口 this.port = serverSocket.getLocalPort(); 3、将端口重新设置回TransportConfig TransportConfig.setRuntimePort(this.port); 调用链： start:75, SimpleHttpCommandCenter (com.alibaba.csp.sentinel.transport.command) init:40, CommandCenterInitFunc (com.alibaba.csp.sentinel.transport.init) doInit:53, InitExecutor (com.alibaba.csp.sentinel.init) :51, ClusterStateManager (com.alibaba.csp.sentinel.cluster) initStateProperty:323, RedisClusterInitFunc (com.fzs.iotcard.sentinel.cluster.redis) init:155, RedisClusterInitFunc (com.fzs.iotcard.sentinel.cluster.redis) 从下往上看： 触发点是在这： com.fzs.iotcard.sentinel.cluster.redis.RedisClusterInitFunc#initStateProperty{ ClusterStateManager.registerProperty(clusterModeDs.getProperty()); } ClusterStateManager static { InitExecutor.doInit(); stateProperty.addListener(PROPERTY_LISTENER); } @InitOrder(-1) public class CommandCenterInitFunc implements InitFunc { public CommandCenterInitFunc() { } public void init() throws Exception { CommandCenter commandCenter = CommandCenterProvider.getCommandCenter(); if (commandCenter == null) { RecordLog.warn(\"[CommandCenterInitFunc] Cannot resolve CommandCenter\", new Object[0]); } else { commandCenter.beforeStart(); commandCenter.start(); RecordLog.info(\"[CommandCenterInit] Starting command center: \" + commandCenter.getClass().getCanonicalName(), new Object[0]); } } } 而CommandCenterProvider.getCommandCenter()取出的是SimpleHttpCommandCenter com.alibaba.csp.sentinel.transport.command.SimpleHttpCommandCenter#start{ TransportConfig.setRuntimePort(this.port); } 第三个地方 com.alibaba.csp.sentinel.transport.command.SimpleHttpCommandCenter#stop @Override public void stop() throws Exception { if (socketReference != null) { try { socketReference.close(); } catch (IOException e) { CommandCenterLog.warn(\"Error when releasing the server socket\", e); } } bizExecutor.shutdownNow(); executor.shutdownNow(); TransportConfig.setRuntimePort(PORT_UNINITIALIZED); handlerMap.clear(); } 这个地方是http服务关闭后重新设置TransportConfig中端口为-1 TransportConfig.setRuntimePort(PORT_UNINITIALIZED); TransportConfig#getPort获取配置文件配置的端口 com.alibaba.csp.sentinel.transport.config.TransportConfig#getPort public static String getPort() { return runtimePort > 0 ? String.valueOf(runtimePort) : SentinelConfig.getConfig(\"csp.sentinel.api.port\"); } 1、先判断当前TransportConfig的runtimePort是否大于0，小于0则从SentinelConfig.getConfig(\"csp.sentinel.api.port\")取 2、而csp.sentinel.api.port来源于下面 com.fzs.iotcard.sentinel.cluster.core.autoconfigure.ClusterSentinelAutoConfiguration#init if (StringUtils.isEmpty(System.getProperty(TransportConfig.SERVER_PORT)) && StringUtils.hasText(properties.getTransport().getPort())) { System.setProperty(TransportConfig.SERVER_PORT, properties.getTransport().getPort()); } 其中TransportConfig.SERVER_PORT为 public class TransportConfig { public static final String SERVER_PORT = \"csp.sentinel.api.port\"; } "},"micro-service/限流/sentinel/集群流控/sentinel集群流控4-ClusterClientAssignConfig.html":{"url":"micro-service/限流/sentinel/集群流控/sentinel集群流控4-ClusterClientAssignConfig.html","title":"sentinel集群流控-ClusterClientAssignConfig","keywords":"","body":" ClusterClientAssignConfig客户端分配配置 com.alibaba.csp.sentinel.cluster.client.config.ClusterClientAssignConfig public class ClusterClientAssignConfig { private String serverHost; private Integer serverPort; 看下面知道是将ClusterGroupEntity中的ip和port设置到ClusterClientAssignConfig中的， 也就是说这个port也用在tokenServer和tokenClient之间通信，那machineId(例如10.20.11.237@8719) 中@后面的8719又是干嘛用的 protected Optional extractClientAssignment(List groupList) { if (groupList.stream().anyMatch(this::machineEqual)) { return Optional.empty(); } // Build client assign config from the client set of target server group. for (ClusterGroupEntity group : groupList) { if (group.getClientSet().contains(getCurrentMachineId())) { String ip = group.getIp(); Integer port = group.getPort(); return Optional.of(new ClusterClientAssignConfig(ip, port)); } } return Optional.empty(); } 集群流控 "},"micro-service/限流/sentinel/集群流控/sentinel集群流控5-心跳检测.html":{"url":"micro-service/限流/sentinel/集群流控/sentinel集群流控5-心跳检测.html","title":"sentinel集群流控之心跳检测","keywords":"","body":" "},"python/python入门.html":{"url":"python/python入门.html","title":"python入门","keywords":"","body":" Window CMD 中运行python 显示乱码问题解决办法 在CMD窗中输入 chcp 65001 后，直接运行Python文件就不会显示乱码了。 windows下安装python 且 安装pip https://www.cnblogs.com/baiyuer/p/9606773.html 安装pip 下载地址是：https://pypi.org/project/pip/#files 1、下载完成之后，解压到一个文件夹，用CMD控制台进入解压文件的目录 （目录中不要包含汉字。放到比较好找的位置）2、然后，在文件目录下，输入： python setup.py install 3、安装好之后，我们直接在命令行输入pip，同样会显示‘pip’不是内部命令，也不是可运行的程序。因为我们还没有添加环境变量。4、按照之前介绍的添加环境变量的方法，我们在PATH最后添加：（添加变量的时候，g用“;”英文分号的分号隔开） D:\\Program Files\\python27\\Scripts 到现在我们才算完整安装好了pip 注：上面添加pip到环境变量是安装pip命令python setup.py install 时从打印的日志里看的 removing 'build\\bdist.win32\\egg' (and everything under it) Processing pip-20.3.3-py2.7.egg removing 'd:\\program files\\python27\\lib\\site-packages\\pip-20.3.3-py2.7.egg' (and everything under it) creating d:\\program files\\python27\\lib\\site-packages\\pip-20.3.3-py2.7.egg Extracting pip-20.3.3-py2.7.egg to d:\\program files\\python27\\lib\\site-packages pip 20.3.3 is already the active version in easy-install.pth Installing pip-script.py script to D:\\Program Files\\python27\\Scripts Installing pip.exe script to D:\\Program Files\\python27\\Scripts Installing pip.exe.manifest script to D:\\Program Files\\python27\\Scripts Installing pip2.7-script.py script to D:\\Program Files\\python27\\Scripts Installing pip2.7.exe script to D:\\Program Files\\python27\\Scripts Installing pip2.7.exe.manifest script to D:\\Program Files\\python27\\Scripts Installing pip2-script.py script to D:\\Program Files\\python27\\Scripts Installing pip2.exe script to D:\\Program Files\\python27\\Scripts Installing pip2.exe.manifest script to D:\\Program Files\\python27\\Scripts Installed d:\\program files\\python27\\lib\\site-packages\\pip-20.3.3-py2.7.egg Processing dependencies for pip==20.3.3 Finished processing dependencies for pip==20.3.3 hoby@LAPTOP-6VJBADD9 MINGW64 /d/Program Files/pip-20.3.3 如何利用Intellij Idea搭建python编译运行环境 https://blog.csdn.net/qq_38188725/article/details/80623710 无法打开.xlsx文件，xlrd.biffh.XLRDError: Excel xlsx file； not supported https://blog.csdn.net/weixin_44073728/article/details/111054157 ``` "},"python/python小牛试刀-获取微信关注用户信息.html":{"url":"python/python小牛试刀-获取微信关注用户信息.html","title":"python小牛试刀-获取微信关注用户信息","keywords":"","body":" 本文内容介绍：1、背景和需求2、解决思路3、解决语言4、python-requests和python-redis5、获取关注公众号的所有用户的openid6、根据openid获取用户详细的用户信息7、总结 1、背景和需求   现在要统计还有多少用户关注橙医生,导出微信上用户的基本信息和注册信息，但是存在以下问题：1、数据库现在只记录用户关注的记录，没有记录用户取消关注的记录，2、用户基本信息比如所在地区和用户年龄没有记录到数据库中，需要调用微信api去重新获取3、导出关注记录的时候，同时要导出该用户的基本注册信息 2、解决思路 1、从数据库导出现在所有关注过的记录(openid),现在统计到有80多万记录2、调用微信api获取现在所有关注的记录(openid)，统计到有50万条记录3、将步骤2中获取到openid，先调用微信api去获取所有用户具体的基本用户信息4、对比数据库中的openid和步骤3获取到的用户信息中的openid，然后查询数据库查询出该用户的注册信息,导出到excel，完。 3、解决语言 打算用python，因为python是脚本语言，方便对导出数据进行处理，同时还由于调用微信api需要access_token，而这个token在我们服务器由其他java项目生成的，放在redis里面。 4、python-requests和python-redis基础模块知识 python-requests模块 先下载安装 git clone git://github.com/kennethreitz/requests.git python setup.py install 导入Requests模块,发起get请求,响应文本内容用r.text获取,若要变成json，直接 r.json()即可 import requests r = requests.get('https://github.com/timeline.json') d=r.json() python-redis模块 编译安装： wget https://pypi.python.org/packages/source/r/redis/redis-2.9.1.tar.gz tar xvzf redis-2.9.1.tar.gz cd redis-2.9.1 python setup.py install 用法： import redis r=redis.Redis(host='localhost',port=6379,db=0,password='密码') token=r.get('wxtoken:PATIENT_TOKEN') 5、获取关注我们公众号的所有用户的openid 详细代码如下：涉及调用微信api，还有从redis里面获取token等知识 #! /usr/bin/python # encoding=utf-8 import requests import demjson import json import sys reload(sys) sys.setdefaultencoding( \"utf-8\" ) import time import socket import redis import traceback token='your token' baseurl='http://api.weixin.qq.com/cgi-bin/user/get?access_token=' redis_host='your redis_host' redis_password='your redis_password' #调用微信api获取关注的所有openid函数 def getFollowOpenids( baseurl , token ,nextopenid): if nextopenid: geturl=baseurl + token + '&next_openid='+nextopenid else: geturl=baseurl + token print \"geturl=%s\"%(geturl) r=requests.get(geturl,timeout=10) d=r.json() return d #获取redis里面的微信access_token def getToken(): r=redis.Redis(host=redis_host,port=6379,db=0,password=redis_password) token=r.get('wxtoken:PATIENT_TOKEN') while not token: print \"再次取到的token是空的token=%s\"%token time.sleep(30) token=getToken() return token fo=open(\"wx-openid.csv\",\"a+\"); def writeToCsv( d ): for x in d['data']['openid']: fo.write(\"%s\\n\"%x) token=getToken() nextopenid='' d=getFollowOpenids( baseurl , token ,nextopenid ) #将第一次获取到的所有关注记录写入wx-openid.csv文件中 writeToCsv( d ) #获取下一次调用需要开始的nextopenid nextopenid=d['next_openid'] print \"第一次获取到的nextopenid=%s\"%nextopenid #统计需要调用多少次微信api，打印所有的记录数 total_time=d['total']/10000 print \"total_time=%s,total=%d\"%(total_time,d['total']) #循环调用微信api去获取关注的openid while total_time > 0: d=getFollowOpenids( baseurl , token ,nextopenid ) writeToCsv( d ) nextopenid=d['next_openid'] print \"获取到下次next_openid=%s\"%nextopenid total_time=total_time-1 print \"\\n\" fo.close(); 6、根据openid获取用户详细的用户信息 #! /usr/bin/python # encoding=utf-8 import requests import demjson import json import sys reload(sys) sys.setdefaultencoding( \"utf-8\" ) import time import socket import redis import traceback token='your token' baseurl='http://api.weixin.qq.com/cgi-bin/user/info?access_token=' redis_host='your redis_host' redis_password='your redis_password' def getUserInfo( baseurl , token ,openid ): geturl=baseurl + token+'&openid='+openid r=requests.get(geturl,timeout=10) d=r.json() print r.text return d def getToken(): r=redis.Redis(host=redis_host,port=6379,db=0,password=redis_password) token=r.get('wxtoken:PATIENT_TOKEN') while not token: print \"再次取到的token是空的token=%s\"%token time.sleep(30) token=getToken() return token fo=open(\"common-userinfo.csv\",\"wb\"); with open(\"wx-openid.csv\",\"r\") as wxf: for strs in wxf.readlines(): try: d=getUserInfo(baseurl,token,strs.strip()) if 'errcode' in d and d['errcode']==42001: print \"token=%s过期了\"%token token=getToken() print \"新token=%s\"%token d=getUserInfo(baseurl,token,strs.strip()) if d['subscribe']==1: subtime=d['subscribe_time'] timeArray=time.localtime(subtime) otherStyleTime=time.strftime(\"%Y-%m-%d %H:%M-%S\",timeArray) info=d['openid']+\",\"+d['nickname']+\",\"+otherStyleTime+\",\"+d['city']+\",\"+str(d['sex'])+\"\\n\" else: info=strs.strip()+\",,,,\" fo.write(info) except: info=sys.exc_info() print info[0],\":\",info[1] traceback.print_exc(file=sys.stdout) print \"异常json:%s\"%strs #pass fo.close(); 7、总结   上面的python代码都是刚学刚用的，由于时间比较匆忙，需要及时完成需求，所以上面代码还没进行很好封装，后面连接数据库查询注册信息方面的也没写。本文只提供获取微信关注用户信息的例子参考，如有问题，可联系我。可参考的知识链接：1、python连接redishttp://debugo.com/python-redis/2、http请求框架python-requestshttp://docs.python-requests.org/zh_CN/latest/user/quickstart.html "},"中间件/mybatis-plus/mybatis-plus生成器相关问题.html":{"url":"中间件/mybatis-plus/mybatis-plus生成器相关问题.html","title":"mybatis-plus生成器相关问题","keywords":"","body":" 实体名重新命名问题 数据库表名字建得不规范(缩写等),而实体名字和数据库表名字不同 参考： https://github.com/baomidou/mybatis-plus/blob/1ea2629a12344f77dd5aa318e4bbee96740cc8e5/mybatis-plus-generator/src/main/java/com/baomidou/mybatisplus/generator/config/INameConvert.java#L70-L75 https://github.com/baomidou/mybatis-plus/blob/3.0/mybatis-plus-generator/src/main/java/com/baomidou/mybatisplus/generator/config/INameConvert.java 整合oracle 自增序列配置 oracle的id一般自己定义个sequence来自增，而不是数据库默认自增，所以实体id要弄成序列的 看如下代码： @TableName(\"T_USER\") @KeySequence(value = \"SEQ_USER\") public class User extends Model { private static final long serialVersionUID = 1L; /** * 用户ID */ @TableId(value = \"USER_ID\", type = IdType.INPUT) private Integer userId; } 主要是： @KeySequence(value = \"SEQ_USER\") @TableId(value = \"USER_ID\", type = IdType.INPUT)这2行代码,type必须指定为IdType.INPUT 使用时，mybatis-plus 3.0版本的必须配置下面注入注解id的默认生成实现 /** * Sequence主键自增 * https://blog.csdn.net/ancdc/article/details/86517796 * @return 返回oracle自增类 */ @Bean public OracleKeyGenerator oracleKeyGenerator(){ return new OracleKeyGenerator(); } 参考： https://blog.csdn.net/ancdc/article/details/86517796 代码生成器自定义数据库表字段类型转换 mybatis-plus提供的oracle转换类如下： com.baomidou.mybatisplus.generator.config.converts.OracleTypeConvert 其中处理数字类型的如下： /** * 将对应的类型名称转换为对应的 java 类类型 * * String.valueOf(Integer.MAX_VALUE).length() == 10 * Integer 不一定能装下 10 位的数字 * * String.valueOf(Long.MAX_VALUE).length() == 19 * Long 不一定能装下 19 位的数字 * * @param typeName 类型名称 * @return 返回列类型 */ private static IColumnType toNumberType(String typeName) { if (typeName.matches(\"number\\\\([0-9]\\\\)\")) { return DbColumnType.INTEGER; } else if (typeName.matches(\"number\\\\(1[0-8]\\\\)\")) { return DbColumnType.LONG; } return DbColumnType.BIG_DECIMAL; } 在实际的生成代码上发现，若数据库定义NUMBER(15,2) （表示15位，后面有2位小数点）然后上面返回的数据类型都是BigDecimal，而在旧代码里定义的是double然后看了下，发现没有定义返回double类型的，所以只好重写了个方法返回double类型的 private static IColumnType toNumberType(String typeName) { if (typeName.matches(\"number\\\\([0-9]\\\\)\")) { return DbColumnType.INTEGER; } else if (typeName.matches(\"number\\\\(1[0-8]\\\\)\")) { return DbColumnType.LONG; } //TODO add on 20201208 if (typeName.matches(\"number\\\\(1[0-8],[0-9]\\\\)\")) { return DOUBLE; } if (typeName.matches(\"number\\\\(3[0-8],[0-9]\\\\)\")) { return DOUBLE; } return DbColumnType.BIG_processTypeConvertDECIMAL; } 然后在引用上，发现自己重写了OracleTypeConvert中的processTypeConvert方法没有生效， 只好自己写了个类MyOracleTypeConvert，然后再引入 protected DataSourceConfig getOracleDataSourceConfig() { DataSourceConfig d = new DataSourceConfig() .setDbType(DbType.ORACLE)// 数据库类型 /*.setTypeConvert(new OracleTypeConvert() { // 自定义数据库表字段类型转换【可选】 public IColumnType processTypeConvert(String fieldType) { System.out.println(\"转换类型：\" + fieldType); // if ( fieldType.toLowerCase().contains( \"tinyint\" ) ) { // return DbColumnType.BOOLEAN; // } if (fieldType.toLowerCase().contains(\"number\")) { return AbstractMybatisPlusGenerator.toNumberType(fieldType); } return super.processTypeConvert(getGlobalConfig(), fieldType); } })*/ //TODO 上面重写processTypeConvert不生效，所以改为用自己的 .setTypeConvert(new MyOracleTypeConvert() { // 自定义数据库表字段类型转换【可选】 public IColumnType processTypeConvert(String fieldType) { System.out.println(\"转换类型：\" + fieldType); return super.processTypeConvert(getGlobalConfig(), fieldType); } }) .setDriverName(\"oracle.jdbc.driver.OracleDriver\") .setUsername(getDataBaseInfo().getUsername()) .setPassword(getDataBaseInfo().getPassword()) .setUrl(getDataBaseInfo().getUrl()); if (!StringUtils.isEmpty(getDataBaseInfo().getSchemaname())) { //oracle的看使用处ConfigBuilder类中，会默认设置为用户名，也就是username d.setSchemaName(getDataBaseInfo().getSchemaname()); } return d; } 参考： https://blog.csdn.net/kanglong129/article/details/98360631 "},"中间件/redis/redis和redisson自动装配.html":{"url":"中间件/redis/redis和redisson自动装配.html","title":"redis和redisson自动装配","keywords":"","body":" RedisAutoConfiguration spring-boot-autoconfigure包下： package org.springframework.boot.autoconfigure.data.redis; import java.net.UnknownHostException; import org.springframework.boot.autoconfigure.condition.ConditionalOnClass; import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean; import org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Import; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.core.RedisOperations; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.core.StringRedisTemplate; @Configuration( proxyBeanMethods = false ) @ConditionalOnClass({RedisOperations.class}) @EnableConfigurationProperties({RedisProperties.class}) @Import({LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class}) public class RedisAutoConfiguration { public RedisAutoConfiguration() { } @Bean @ConditionalOnMissingBean( name = {\"redisTemplate\"} ) public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { RedisTemplate template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } } 可以看到我们不配置RedisTemplate，只需要在配置文件添加RedisProperties里的属性即可但是他这个保存到redis的时候没有序列化的,在redis里看可能会乱码 RedissonAutoConfiguration 看redisson-spring-boot-starter下的RedissonAutoConfiguration org.redisson.spring.starter.RedissonAutoConfiguration 下面也会创建redissonConnectionFactory、RedisTemplate等，同时RedissonAutoConfiguration用了AutoConfigureBefore，会比RedisAutoConfiguration先装配 @Configuration @ConditionalOnClass({Redisson.class, RedisOperations.class}) @AutoConfigureBefore({RedisAutoConfiguration.class}) @EnableConfigurationProperties({RedissonProperties.class, RedisProperties.class}) public class RedissonAutoConfiguration { @Autowired private RedissonProperties redissonProperties; @Autowired private RedisProperties redisProperties; @Autowired private ApplicationContext ctx; public RedissonAutoConfiguration() { } @Bean @ConditionalOnMissingBean( name = {\"redisTemplate\"} ) public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean({StringRedisTemplate.class}) public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean({RedisConnectionFactory.class}) public RedissonConnectionFactory redissonConnectionFactory(RedissonClient redisson) { return new RedissonConnectionFactory(redisson); } "},"中间件/shardingsphere/sharding-jdbc实现读写分离.html":{"url":"中间件/shardingsphere/sharding-jdbc实现读写分离.html","title":"sharding-jdbc实现读写分离","keywords":"","body":" 1、准备数据库 创建3个数据库，然后在各自数据库里创建一个user表 CREATE DATABASE `ds-master` CHARACTER SET 'utf8' COLLATE 'utf8_general_ci'; CREATE DATABASE `ds-slave0` CHARACTER SET 'utf8' COLLATE 'utf8_general_ci'; CREATE DATABASE `ds-slave1` CHARACTER SET 'utf8' COLLATE 'utf8_general_ci'; CREATE TABLE `user`( id bigint(64) auto_increment not null, city varchar(20) not null, name varchar(20) not null, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 2、引入Maven依赖 4.0.0-RC1 org.apache.shardingsphere sharding-jdbc-spring-boot-starter ${sharding-sphere.version} org.apache.shardingsphere sharding-jdbc-spring-namespace ${sharding-sphere.version} 3、配置数据源和读写分离 spring: shardingsphere: datasource: names: ds-master,ds-slave0,ds-slave1 ds-master: type: com.alibaba.druid.pool.DruidDataSource driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ds-master?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai username: root password: root ds-slave0: type: com.alibaba.druid.pool.DruidDataSource driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ds-slave0?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai username: root password: root ds-slave1: type: com.alibaba.druid.pool.DruidDataSource driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ds-slave1?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai username: root password: root masterslave: name: ds-ms # 名称,合法的字符串即可,但如果涉及到在读写分离的基础上设置分库分表,则名称需要有意义才可以,另外,虽然目前没有强制要求,但主从库配置需要配置在实际关联的主从库上,如果配置的数据源之间主从是断开的状态,那么可能会发生写入的数据对于只读会话无法读取到的问题 masterDataSourceName: ds-master # 主库的DataSource名称 slaveDataSourceNames: # 从库的DataSource列表,至少需要有一个 - ds-slave0 - ds-slave1 loadBalanceAlgorithmClassName: org.apache.shardingsphere.api.algorithm.masterslave # MasterSlaveLoadBalanceAlgorithm接口的实现类,允许自定义实现 默认提供两个,配置路径为org.apache.shardingsphere.api.algorithm.masterslave下的RandomMasterSlaveLoadBalanceAlgorithm(随机Random)与RoundRobinMasterSlaveLoadBalanceAlgorithm(轮询:次数%从库数量) #loadBalanceAlgorithmType: #从库负载均衡算法类型，可选值：ROUND_ROBIN，RANDOM。若loadBalanceAlgorithmClassName存在则忽略该配置,默认为ROUND_ROBIN props: sql.show: true #是否开启SQL显示，默认值: false # acceptor.size: # accept连接的线程数量,默认为cpu核数2倍 # executor.size: #工作线程数量最大，默认值: 无限制 # max.connections.size.per.query: # 每个查询可以打开的最大连接数量,默认为1 # proxy.frontend.flush.threshold: # proxy的服务时候,对于单个大查询,每多少个网络包返回一次 # proxy.transaction.type: # 默认LOCAL,proxy的事务模型 允许LOCAL,XA,BASE三个值 LOCAL无分布式事务,XA则是采用atomikos实现的分布式事务 BASE目前尚未实现 # proxy.opentracing.enabled: # 是否启用opentracing # proxy.backend.use.nio: # 是否采用netty的NIO机制连接后端数据库,默认False ,使用epoll机制 # proxy.backend.max.connections: # 使用NIO而非epoll的话,proxy后台连接每个netty客户端允许的最大连接数量(注意不是数据库连接限制) 默认为8 # proxy.backend.connection.timeout.seconds: #使用nio而非epoll的话,proxy后台连接的超时时间,默认60s # check.table.metadata.enabled: # 是否在启动时候,检查sharing的表的实际元数据是否一致,默认False 4、新建springboot的Application应用启动类 注意排除掉DruidDataSourceAutoConfigure类的自动加载，引入Swagger package com.demo; import com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceAutoConfigure; import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.Banner; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import springfox.documentation.swagger2.annotations.EnableSwagger2; import java.util.HashMap; @SpringBootApplication(exclude = {DruidDataSourceAutoConfigure.class}) @EnableSwagger2 @MapperScan({ \"com.demo.mapper*\", \"com.demo.open.mapper*\" })//这里不定义的话，则要在mapper文件里加上@Mapper注解 public class ShardingJdbcDemoApplication { public static void main(String[] args) { SpringApplication app = new SpringApplication(ShardingJdbcDemoApplication.class); app.setBannerMode(Banner.Mode.OFF); app.run(args); HashMap hashMap=new HashMap(); } } 5、新建实体对象User package com.demo.entity; import lombok.Data; import java.io.Serializable; @Data public class User implements Serializable { private static final long serialVersionUID = -1; private Long id; private String city = \"\"; private String name = \"\"; } 6、新建mapper package com.demo.mapper; import java.util.List; import com.demo.entity.User; import org.apache.ibatis.annotations.Mapper; @Mapper public interface UserMapper { Long addUser(User user); List list(); User findById(Long id); User findByName(String name); } 7、新建UserService以及实现类 package com.demo.service; import com.demo.entity.User; import java.util.List; public interface UserService { List list(); Long add(User user); User findById(Long id); User findByName(String name); } 实现： package com.demo.service.impl; import com.demo.entity.User; import com.demo.mapper.UserMapper; import com.demo.service.UserService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import java.util.List; @Service public class UserServiceImpl implements UserService { @Autowired private UserMapper userMapper; public List list() { return userMapper.list(); } public Long add(User user) { return userMapper.addUser(user); } @Override public User findById(Long id) { return userMapper.findById(id); } @Override public User findByName(String name) { return userMapper.findByName(name); } } 8、新建UserController package com.demo.web; import com.demo.entity.User; import com.demo.service.UserService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; @RestController public class UserController { @Autowired private UserService userService; @GetMapping(\"/users\") public Object list() { return userService.list(); } @GetMapping(\"/add\") public Object add() { for (long i = 0; i 9、swagger测试 访问http://localhost:8081/swagger-ui.html#/ 9.1、增加数据 先调用http://localhost:8081/add方法增加主库ds-master的数据 查看数据库，ds-master已有数据，而ds-slave0,ds-slave1没有数据 9.2、查询 调用http://localhost:8081/users查询，查看后台日志如下： 2019-08-07 11:40:09,920 http-nio-8081-exec-4 INFO org.apache.shardingsphere.core.route.SQLLogger:89 [http-nio-8081-exec-4] Rule Type: master-slave 2019-08-07 11:40:09,920 http-nio-8081-exec-4 INFO org.apache.shardingsphere.core.route.SQLLogger:89 [http-nio-8081-exec-4] SQL: SELECT u.* FROM user u ::: DataSources: ds-slave0 分析日志： 1、Rule Type规则类型为主从master-slave，也就是读写分离2、SQL: SELECT u.* FROM user u ::: DataSources: ds-slave0 这句说明是从从库ds-slave0查询的 参考：https://shardingsphere.apache.org/document/current/cn/manual/sharding-jdbc/usage/read-write-splitting/ "},"中间件/spring/spring-core工具包.html":{"url":"中间件/spring/spring-core工具包.html","title":"spring-core工具包","keywords":"","body":" org.springframework.util.ReflectionUtils#findMethod(java.lang.Class, java.lang.String, java.lang.Class...) 使用举例： org.redisson.spring.starter.RedissonAutoConfiguration Method clusterMethod = ReflectionUtils.findMethod(RedisProperties.class, \"getCluster\"); ``` "},"前端/angular/angular基础/angular-generate命令.html":{"url":"前端/angular/angular基础/angular-generate命令.html","title":"angular-generate命令","keywords":"","body":" "},"前端/jquery基础/jquery按钮用法.html":{"url":"前端/jquery基础/jquery按钮用法.html","title":"jquery按钮用法","keywords":"","body":" 1、 JQuery控制radio选中和不选中方法 2、 3、 ``` "},"前端/json/前端json字符串和js对象转换.html":{"url":"前端/json/前端json字符串和js对象转换.html","title":"前端json字符串和js对象转换","keywords":"","body":" 1、object转化为json字符串 var data = new Object(); var jsonData = JSON.stringify(data); 2、json字符串转为js对象 var jsonObj = eval(jsonStr); var jsonObj = JSON.parse(jsonStr); 参考： https://blog.csdn.net/wangzhibo666/article/details/87718123?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf https://blog.csdn.net/yo746862873/article/details/52468683 3、 ``` "},"前端/node/node学习.html":{"url":"前端/node/node学习.html","title":"node学习","keywords":"","body":" 1、node待学习 commander学习 https://www.cnblogs.com/1wen/p/10142210.html https://www.iteye.com/blog/witcheryne-1196170 https://segmentfault.com/q/1010000000367285 2、 3、 "},"前端/vue/vue待学习.html":{"url":"前端/vue/vue待学习.html","title":"vue待学习","keywords":"","body":" 待学习网址 vue后台模板 https://github.com/dohoby/vue-admin-template/blob/master/README-zh.md https://panjiachen.gitee.io/vue-element-admin-site/zh/guide/#%E5%8A%9F%E8%83%BD 下载项目后用yarn安装，不要用npm install安装（会报错） yarn "},"前端/后台模板/ngx-admin后台模板学习.html":{"url":"前端/后台模板/ngx-admin后台模板学习.html","title":"ngx-admin后台模板学习","keywords":"","body":" ngx-admin是开源的基于angular的后台管理模板 1.用命令或者idea下载 git clone https://github.com/akveo/ngx-admin.git 2.去到ngx-admin目录下，任意用下面1个命令安装 npm i 或命令 npm install 3.启动项目 npm start 4.访问 http://localhost:4200 5.线上模式 npm run build:prod 文档地址 ngx-admin文档地址 "},"前端/弹窗/layer/layer弹窗.html":{"url":"前端/弹窗/layer/layer弹窗.html","title":"layer弹窗","keywords":"","body":" layer弹窗用法 layer弹窗效果 artTemplate模板 1、 2、 3、 ``` "},"博客/gitbook/gitbook教程.html":{"url":"博客/gitbook/gitbook教程.html","title":"gitbook教程","keywords":"","body":" 基本步骤 #1、安装gitbook客户端 npm install gitbook-cli -g # 2、初始化一个仓库，会生成README.md和SUMMARY.md文件 gitbook init # 3、新建book.json，然后执行下面命令会安装里面的插件 gitbook install # 4、启动服务器 gitbook serve gitbook serve -p 8080 生产上去掉热部署，要不首页加载会很慢 gitbook serve --no-live 其他命令 gitbook -V # 生成html gitbook build book.json文件 { \"title\": \"Webpack 中文指南\", \"description\": \"Webpack 是当下最热门的前端资源模块化管理和打包工具，本书大部分内容翻译自 Webpack 官网。\", \"language\": \"zh\", \"plugins\": [ \"disqus\", \"github\", \"editlink\", \"prism\", \"-highlight\", \"baidu\", \"splitter\", \"sitemap\", \"summary\" ], \"pluginsConfig\": { \"disqus\": { \"shortName\": \"webpack-handbook\" }, \"github\": { \"url\": \"https://github.com/zhaoda/webpack-handbook\" }, \"editlink\": { \"base\": \"https://github.com/zhaoda/webpack-handbook/blob/master/content\", \"label\": \"编辑本页\" }, \"baidu\": { \"token\": \"a9787f0ab45d5e237bab522431d0a7ec\" }, \"sitemap\": { \"hostname\": \"http://zhaoda.net/\" } } } 自动生成summary目录 安装插件 npm install -g gitbook-summary book sm -c _posts book sm -c source/_posts -c参数-c，即--catalog，是指全部要显示的目录，表示要生成html的文件夹缺陷：source/_posts表示该目录是需要生成html的目录,貌似这样没用，只能到source目录,不能具体到_posts目录 -i 是参数 --ignores的缩写形式，意思是忽略该参数提供的目录-i 用法像下面那样,有效果,注意是文件夹的名字(注意大小写)， book sm -c source/_posts -i about,tags,friends,categories 在book.json里添加也可以，如下： \"ignores\": [\"friends\",\"tags\",\"categories\",\"about\"], 缺陷：若要忽略的文件夹，存在要生成的文件夹_posts的子文件夹。这个子文件夹也无法生成，这种应该改成指定路径下的文件夹的，例如devops既存在source下，又存在_posts下，我只想忽略source下的devops，它却连_posts下的也忽略了 注意：在哪个目录下执行book命令就生成SUMMARY.md在哪个目录下，测试发现在content目录下(非根目录下)生成的文件开头没法 取到book.json定义的title 参考：https://blog.csdn.net/ds19991999/article/details/81275458 生成pdf文件 gitbook pdf . book.pdf 添加章节编号 在pluginsConfig加上,注意不是在plugin里加 \"theme-default\": { \"showLevel\": true } https://www.crifan.com/gitbook_add_chapter_index_number/ 修改indroduction首页指定为另一个文件 \"structure\": { \"readme\": \"SUMMARY.md\" } 修改根目录，即打包生成html目录 \"root\": \"./content\", 部署到coding 特别注意1、自定义的gitbbook发布时不能在根目录下新建scripts文件夹，否则会影响hexo的生成和发布 2、自定义的deploy-gh-pages.js会改变当前git仓库的分支，特别注意这个 新建gitbook_deploy文件夹，然后新建deploy-gh-pages.js文件，文件内容大概如下注意修改repo为你自己的git仓库,_book是你生成的gitbook的html输出目录 'use strict'; var ghpages = require('gh-pages'); main(); function main() { const defaults = { dest: '.', add: false, git: 'git', depth: 1, dotfiles: false, branch: 'gh-pages', src: '**/*', only: '.', push: true, message: 'Updates', silent: false, repo: '你的git仓库地址' }; ghpages.publish('./_book',defaults, console.error.bind(console)); } 参考：https://github.com/tschaub/gh-pages 自动化 特别注意不能ignore掉content文件夹，否则命令找不到文件的 npm run gautopublish nodejs拷贝文件https://www.cnblogs.com/coding4/p/7495968.html 发布到gitbook http://www.chengweiyang.cn/gitbook/gitbook.com/newbook.html 统计插件 { \"plugins\": [ \"pageview-count\" ] } 个性化配置 http://www.chengweiyang.cn/gitbook/customize/book.json.html 修改样式 https://blog.tedxiong.com/how_to_remove_Published_with_GitBook_in_GitBook.html 其他 插件 https://blog.csdn.net/weixin_37865166/article/details/91899788 https://yanhaijing.com/tool/2015/09/12/my-gitbook-note/ 在book.json中定义，这样README.md就可以用作项目的简介 { \"structure\": { \"readme\": \"SUMMARY.md\" } } 注意： 这个一般和\"root\": \".deploy/content\",这个一起用 还有注意readme这里只能定义文件，比如SUMMARY.md,而不能带目录如.deploy/content/SUMMARY.md, 而root则可以定义成目录如.deploy/content \"root\": \".deploy/content\", { \"structure\": { \"readme\": \"SUMMARY.md\" } } 上面表示根目录在.deploy/content目录下,描述文件为SUMMARY.md， 这时gitbook build编译命令为gitbook build . .deploy/_book --no-live 第一个.表示在项目的根目录下(比如lqx-gitbook-deploy),注意这里必须用. 不要用.deploy/content,否则gitbook build会报README.md找不到的 第二个.deploy/_book表示要生成的html文件输出的目录. https://www.cnblogs.com/luoheng23/p/11197922.html https://baijiahao.baidu.com/s?id=1590626161534963215&wfr=spider&for=pc https://gitbook.zhangjikai.com/structure.html https://www.jianshu.com/p/4e109a1113b2 插件： https://www.jianshu.com/p/427b8bb066e6 热加载： https://blog.csdn.net/weixin_38171180/article/details/89975512 去掉热加载 http://stackmirror.caup.cn/page/s1b4bt53rg3a 生成页内目录(要自己在文章加toc标签) npm i gitbook-plugin-toc2 --save plugins: [\"toc2\"], \"pluginsConfig\": { \"toc\": { \"addClass\": true, \"className\": \"toc\" } } https://www.npmjs.com/package/gitbook-plugin-toc2 https://cnodejs.org/topic/575229332420978970d4a5f0 生成页内目录2(要自己在文章加toc标签) npm i gitbook-plugin-page-toc-button --save { ... \"plugins\": [ \"page-toc-button\", ], \"pluginsConfig\": { \"page-toc-button\": { \"maxTocDepth\": 2, \"minTocSize\": 2 } } ... } https://www.gitdig.com/gitbook/plugin/toc.html https://github.com/jonschlinkert/markdown-toc https://github.com/stuebersystems/gitbook-plugin-simple-page-toc https://github.com/dohoby/gitbook-plugin-page-toc-button 可扩展导航章节(有问题,无法展开) npm i gitbook-plugin-expandable-chapters-small --save https://www.npmjs.com/package/gitbook-plugin-expandable-chapters-small TODO 待研究 1、给html,js等加上版本号，要不每次更改内容时，浏览器还是有缓存 http://xszhao.science/cheatsheet/content/web/gitbook.html 2、toc目录移动到右边 gitbook官方文档 https://github.com/GitbookIO/gitbook/tree/master/docs 源码：C:\\Users\\Administrator.gitbook\\versions\\3.2.3 问题 若遇到下面的提示，很可能是没有权限访问，但是在命令行用ssh又可以拼得通连接git是可以的 at ChildProcess.emit (events.js:191:7) at maybeClose (internal/child_process.js:877:16) at Process.ChildProcess._handle.onexit (internal/child_process.js:226:5) code: 128, message: 'Cloning into \\'node_modules\\\\gh-pages\\\\.cache\\\\git@git.\\'...\\nHost key verification failed.\\r\\nfatal: Could not read from remote repository.\\n\\nPlease make sure you have the correct access rights\\nand the repository exists.\\n', name: 'ProcessError' } 解决办法： 在网上搜索了好久都没找到相应办法，后来在命令行下执行下面的,也就是手动clone下仓库的地址， 看下面的提示The authenticity of host 'git.dev.tencent.com (118.25.166.124)' can't be established. 这个和上面的报错Host key verification failed对应, 命令停止在Are you sure you want to continue connecting (yes/no)? yes输入yes后，再重新执行上面的部署命令即可解决了 λ git clone 你的git仓库的ssh地址 Cloning into 'gitbook'... The authenticity of host 'git.dev.tencent.com (118.25.166.124)' can't be established. RSA key fingerprint is SHA256:xxxxxxxxxx. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added 'git.dev.tencent.com' (RSA) to the list of known hosts. remote: Enumerating objects: 3734, done. remote: Counting objects: 100% (3734/3734), done. remote: Compressing objects: 100% (3464/3464), done. remote: Total 3734 (delta 2449), reused 297 (delta 137) Receiving objects: 100% (3734/3734), 3.09 MiB | 1020.00 KiB/s, done. Resolving deltas: 100% (2449/2449), done. Checking connectivity... done. git 不是内部或外部命令，也不是可运行的程序 注意git安装的要把git的两个路径设置到path环境变量，否则在idea里没法跑git命令 a:找到git安装路径中bin的位置：D:\\Program Files\\Git\\bin b:找到git安装路径中libexec\\git-core的位置，如：D:\\Program Files\\Git\\mingw64\\libexec\\git-core 其中git安装路径为D:\\Program Files\\Git\\ 参考https://blog.csdn.net/qq_27911459/article/details/98967901 "},"博客/hugo/hugo教程.html":{"url":"博客/hugo/hugo教程.html","title":"hugo教程","keywords":"","body":" 1、 https://www.gohugo.org/ 2、 3、 "},"各种问题/http/http400问题.html":{"url":"各种问题/http/http400问题.html","title":"http400问题","keywords":"","body":" 1、后端controller加上@RequestBody就报错400 @ResponseBody @RequestMapping(value = \"/save\", method = RequestMethod.POST) public ResultBean save(HttpServletRequest request,@RequestBody IotInterfaceParamConfigDTO record) { ResultBean resultBean = new ResultBean(); IotUser user = super.getPortalUser(request); if (user == null) { return ResultBean.resultFail(\"0\", \"用户没登录\"); } if (record.getId() != null) { record.setCreator(user.getUserName()); iotInterfaceParamConfigService.update(record); } else { record.setModifier(user.getUserName()); iotInterfaceParamConfigService.add(record); } return resultBean; } 2、前端用ajax或者rest client 请求参数 { \"id\": \"\", \"interfacePlatformId\": \"12\", \"businessCategoryId\": \"11\", \"interfaceCategoryId\": \"11\", \"interfaceNumber\": \"aa\", \"interfaceName\": \"a\", \"serviceAddress\": \"a\", \"businessDesc\": \"a\", \"suitFor\": \"1\", \"enable\": \"1\", \"iotInterfaceParamRules\": [{ \"id\": \"undefined\", \"cardManageMode\": \"4\", \"condition\": \">1 >1\", \"priority\": \"3\", \"remarkDesc\": \"a\" }], \"iotInterfaceParamProperties\": [{ \"id\": \"\", \"attributeName\": \"a\", \"condition\": \"a\", \"remarkDesc\": \"a\" }] } 3、解决： log4j.properties加上debug，改为下面的， log4j.rootLogger=debug,info, CONSOLE, FILE,stdout 开启后查看日志： 2020-10-30 15:04:36.861 pid[] thread[http-nio-8080-exec-4hread] DEBUG hibernate4.support.OpenSessionInViewFilter:187 - Using SessionFactory 'sys_sessionFactory' for OpenSessionInViewFilter 2020-10-30 15:04:36,861 DEBUG [org.springframework.orm.hibernate4.support.OpenSessionInViewFilter] - Using SessionFactory 'sys_sessionFactory' for OpenSessionInViewFilter 2020-10-30 15:04:36.863 pid[] thread[http-nio-8080-exec-4hread] DEBUG factory.support.DefaultListableBeanFactory:243 - Returning cached instance of singleton bean 'sys_sessionFactory' 2020-10-30 15:04:36,863 DEBUG [org.springframework.beans.factory.support.DefaultListableBeanFactory] - Returning cached instance of singleton bean 'sys_sessionFactory' 2020-10-30 15:04:36.863 pid[] thread[http-nio-8080-exec-4hread] DEBUG hibernate4.support.OpenSessionInViewFilter:139 - Opening Hibernate Session in OpenSessionInViewFilter 2020-10-30 15:04:36,863 DEBUG [org.springframework.orm.hibernate4.support.OpenSessionInViewFilter] - Opening Hibernate Session in OpenSessionInViewFilter 2020-10-30 15:04:36.864 pid[] thread[http-nio-8080-exec-4hread] DEBUG hibernate.internal.SessionImpl:302 - Opened session at timestamp: 16040414768 2020-10-30 15:04:36,864 DEBUG [org.hibernate.internal.SessionImpl] - Opened session at timestamp: 16040414768 2020-10-30 15:04:36.864 pid[] thread[http-nio-8080-exec-4hread] DEBUG web.servlet.DispatcherServlet:819 - DispatcherServlet with name 'dispatchServlet' processing POST request for [/fzsiotcard/admin/interfacemanage/iotInterfaceParamConfig/save] 2020-10-30 15:04:36,864 DEBUG [org.springframework.web.servlet.DispatcherServlet] - DispatcherServlet with name 'dispatchServlet' processing POST request for [/fzsiotcard/admin/interfacemanage/iotInterfaceParamConfig/save] 2020-10-30 15:04:36.864 pid[] thread[http-nio-8080-exec-4hread] DEBUG method.annotation.RequestMappingHandlerMapping:229 - Looking up handler method for path /admin/interfacemanage/iotInterfaceParamConfig/save 2020-10-30 15:04:36,864 DEBUG [org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping] - Looking up handler method for path /admin/interfacemanage/iotInterfaceParamConfig/save 2020-10-30 15:04:36.865 pid[] thread[http-nio-8080-exec-4hread] DEBUG method.annotation.RequestMappingHandlerMapping:234 - Returning handler method [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)] 2020-10-30 15:04:36,865 DEBUG [org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping] - Returning handler method [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)] 2020-10-30 15:04:36.865 pid[] thread[http-nio-8080-exec-4hread] DEBUG factory.support.DefaultListableBeanFactory:243 - Returning cached instance of singleton bean 'iotInterfaceParamConfigController' 2020-10-30 15:04:36,865 DEBUG [org.springframework.beans.factory.support.DefaultListableBeanFactory] - Returning cached instance of singleton bean 'iotInterfaceParamConfigController' 2020-10-30 15:04:36.865 pid[] thread[http-nio-8080-exec-4hread] DEBUG component.interceptors.AuthenticationInterceptor:49 - HandlerMethod: /admin/interfacemanage/iotInterfaceParamConfig/save rights authentication. 2020-10-30 15:04:36,865 DEBUG [com.fzs.uniauth.component.interceptors.AuthenticationInterceptor] - HandlerMethod: /admin/interfacemanage/iotInterfaceParamConfig/save rights authentication. 2020-10-30 15:04:36.866 pid[] thread[http-nio-8080-exec-4hread] DEBUG method.annotation.RequestResponseBodyMethodProcessor:140 - Reading [class com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO] as \"application/json;charset=UTF-8\" using [org.springframework.http.converter.json.MappingJackson2HttpMessageConverter@77cc5550] 2020-10-30 15:04:36,866 DEBUG [org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor] - Reading [class com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO] as \"application/json;charset=UTF-8\" using [org.springframework.http.converter.json.MappingJackson2HttpMessageConverter@77cc5550] 2020-10-30 15:04:36.867 pid[] thread[http-nio-8080-exec-4hread] DEBUG method.annotation.ExceptionHandlerExceptionResolver:132 - Resolving exception from handler [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)]: org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]) 2020-10-30 15:04:36,867 DEBUG [org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver] - Resolving exception from handler [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)]: org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]) 2020-10-30 15:04:36.867 pid[] thread[http-nio-8080-exec-4hread] DEBUG mvc.annotation.ResponseStatusExceptionResolver:132 - Resolving exception from handler [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)]: org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]) 2020-10-30 15:04:36,867 DEBUG [org.springframework.web.servlet.mvc.annotation.ResponseStatusExceptionResolver] - Resolving exception from handler [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)]: org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]) 2020-10-30 15:04:36.868 pid[] thread[http-nio-8080-exec-4hread] DEBUG mvc.support.DefaultHandlerExceptionResolver:132 - Resolving exception from handler [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)]: org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]) 2020-10-30 15:04:36,868 DEBUG [org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolver] - Resolving exception from handler [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)]: org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]) 2020-10-30 15:04:36.868 pid[] thread[http-nio-8080-exec-4hread] DEBUG web.servlet.DispatcherServlet:993 - Null ModelAndView returned to DispatcherServlet with name 'dispatchServlet': assuming HandlerAdapter completed request handling 2020-10-30 15:04:36,868 DEBUG [org.springframework.web.servlet.DispatcherServlet] - Null ModelAndView returned to DispatcherServlet with name 'dispatchServlet': assuming HandlerAdapter completed request handling 2020-10-30 15:04:36.869 pid[] thread[http-nio-8080-exec-4hread] DEBUG web.servlet.DispatcherServlet:983 - Successfully completed request 2020-10-30 15:04:36,869 DEBUG [org.springframework.web.servlet.DispatcherServlet] - Successfully completed request 2020-10-30 15:04:36.869 pid[] thread[http-nio-8080-exec-4hread] DEBUG hibernate4.support.OpenSessionInViewFilter:159 - Closing Hibernate Session in OpenSessionInViewFilter 2020-10-30 15:04:36,869 DEBUG [org.springframework.orm.hibernate4.support.OpenSessionInViewFilter] - Closing Hibernate Session in OpenSessionInViewFilter 2020-10-30 15:05:05.847 pid[] thread[Apollo-RemoteConfigLongPollService-1hread] DEBUG apollo.internals.RemoteConfigLongPollService:172 - Long polling response: 304, url: http://dev-apollo-configservice:9012/notifications/v2?cluster=default&appId=fzs-iotcard&ip=10.20.11.161&notifications=%5B%7B%22namespaceName%22%3A%22application%22%2C%22notificationId%22%3A2154%7D%5D 2020-10-30 15:05:05,847 DEBUG [com.ctrip.framework.apollo.internals.RemoteConfigLongPollService] - Long polling response: 304, url: http://dev-apollo-configservice:9012/notifications/v2?cluster=default&appId=fzs-iotcard&ip=10.20.11.161&notifications=%5B%7B%22namespaceName%22%3A%22application%22%2C%22notificationId%22%3A2154%7D%5D 2020-10-30 15:05:05.849 pid[] thread[Apollo-RemoteConfigLongPollService-1hread] DEBUG apollo.internals.RemoteConfigLongPollService:163 - Long polling from http://dev-apollo-configservice:9012/notifications/v2?cluster=default&appId=fzs-iotcard&ip=10.20.11.161&notifications=%5B%7B%22namespaceName%22%3A%22application%22%2C%22notificationId%22%3A2154%7D%5D 2020-10-30 15:05:05,849 DEBUG [com.ctrip.framework.apollo.internals.RemoteConfigLongPollService] - Long polling from http://dev-apollo-configservice:9012/notifications/v2?cluster=default&appId=fzs-iotcard&ip=10.20.11.161&notifications=%5B%7B%22namespaceName%22%3A%22application%22%2C%22notificationId%22%3A2154%7D%5D 仔细观察发现是这行日志的问题： IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value 也就是IotInterfaceParamRule对应的字段id设值为undefined了， 再仔细观察请求json参数，果然发现有个undefined \"iotInterfaceParamRules\": [{ \"id\": \"undefined\", \"cardManageMode\": \"4\", \"condition\": \">1 >1\", \"priority\": \"3\", \"remarkDesc\": \"a\" }] 干掉undefined再请求即可正常了 正确json如下： { \"id\": \"\", \"interfacePlatformId\": \"12\", \"businessCategoryId\": \"7\", \"interfaceCategoryId\": \"11\", \"interfaceNumber\": \"1\", \"interfaceName\": \"1\", \"serviceAddress\": \"1\", \"businessDesc\": \"1\", \"suitFor\": \"2\", \"enable\": \"1\", \"iotInterfaceParamRules\": [{ \"id\": \"\", \"cardManageMode\": \"1\", \"condition\": \" ajax请求： //获取rule数据 var ruleData = getRuleTableData(); var propertyData = getPropertyData(); var formdata = form.serialize();//序列化表单 var arr = formdata.split(\"&\");//转换成字符数组 var newData = new Object();//用来存储转换后的数组 for (var i = 0; i 别人的400(和我上面的不一样) 400问题 ajax错误返回： 参考： https://www.cnblogs.com/xinzhisoft/p/10648946.html 上面我自己打印的错误js日志： abort: ƒ (t) always: ƒ () complete: ƒ () done: ƒ () error: ƒ () fail: ƒ () getAllResponseHeaders: ƒ () getResponseHeader: ƒ (t) overrideMimeType: ƒ (t) pipe: ƒ () progress: ƒ () promise: ƒ (t) readyState: 4 responseText: \"HTTP状态 500 - 内部服务器错误body {font-family:Tahoma,Arial,sans-serif;} h1, h2, h3, b {color:white;background-color:#525D76;} h1 {font-size:22px;} h2 {font-size:16px;} h3 {font-size:14px;} p {font-size:12px;} a {color:black;} .line {height:1px;background-color:#525D76;border:none;}HTTP状态 500 - 内部服务器错误类型 异常报告消息 Request processing failed; nested exception is org.springframework.dao.DataIntegrityViolationException: 描述 服务器遇到一个意外的情况，阻止它完成请求。例外情况org.springframework.web.util.NestedServletException: Request processing failed; nested exception is org.springframework.dao.DataIntegrityViolationException: ↵### Error updating database. Cause: java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵ ↵### The error may exist in file [D:\\idea-workspace4\\FZS_IOT_CARD\\target\\project-practice\\WEB-INF\\classes\\mapper\\interfacemanage\\IotInterfaceParamRuleMapper.xml] ↵### The error may involve com.web.supplier.interfacemanage.mapper.IotInterfaceParamRuleMapper.insertSelective-Inline ↵### The error occurred while setting parameters ↵### SQL: insert into T_IOT_INTERFACE_PARAM_RULE ( ID, CARD_MANAGE_MODE, CONDITION, PRIORITY, REMARK_DESC, STATUS, CREATE_TIME, DELETED ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) ↵### Cause: java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵↵; SQL []; ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵; nested exception is java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵ ↵ org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:965) ↵ org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:855) ↵ javax.servlet.http.HttpServlet.service(HttpServlet.java:652) ↵ org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:829) ↵ javax.servlet.http.HttpServlet.service(HttpServlet.java:733) ↵ org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ↵ org.springframework.orm.hibernate4.support.OpenSessionInViewFilter.doFilterInternal(OpenSessionInViewFilter.java:151) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:88) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) ↵根本原因。org.springframework.dao.DataIntegrityViolationException: ↵### Error updating database. Cause: java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵ ↵### The error may exist in file [D:\\idea-workspace4\\FZS_IOT_CARD\\target\\project-practice\\WEB-INF\\classes\\mapper\\interfacemanage\\IotInterfaceParamRuleMapper.xml] ↵### The error may involve com.web.supplier.interfacemanage.mapper.IotInterfaceParamRuleMapper.insertSelective-Inline ↵### The error occurred while setting parameters ↵### SQL: insert into T_IOT_INTERFACE_PARAM_RULE ( ID, CARD_MANAGE_MODE, CONDITION, PRIORITY, REMARK_DESC, STATUS, CREATE_TIME, DELETED ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) ↵### Cause: java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵↵; SQL []; ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵; nested exception is java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵ ↵ org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:249) ↵ org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72) ↵ org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:71) ↵ org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:365) ↵ com.sun.proxy.$Proxy26.insert(Unknown Source) ↵ org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:237) ↵ org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:79) ↵ org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:40) ↵ com.sun.proxy.$Proxy167.insertSelective(Unknown Source) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamRuleServiceImpl.insert(IotInterfaceParamRuleServiceImpl.java:59) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl.lambda$saveIotInterfaceParamProperties$1(IotInterfaceParamConfigServiceImpl.java:173) ↵ java.util.ArrayList.forEach(ArrayList.java:1249) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl.saveIotInterfaceParamProperties(IotInterfaceParamConfigServiceImpl.java:167) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl.add(IotInterfaceParamConfigServiceImpl.java:124) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl$$FastClassBySpringCGLIB$$b816365b.invoke(&lt;generated&gt;) ↵ org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ↵ org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:629) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl$$EnhancerBySpringCGLIB$$47ae7cb1.add(&lt;generated&gt;) ↵ com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(IotInterfaceParamConfigController.java:88) ↵ com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController$$FastClassBySpringCGLIB$$17aa7ed9.invoke(&lt;generated&gt;) ↵ org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ↵ org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:700) ↵ org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150) ↵ org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:91) ↵ org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) ↵ org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:633) ↵ com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController$$EnhancerBySpringCGLIB$$f44c91c5.save(&lt;generated&gt;) ↵ sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ↵ sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ↵ sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ↵ java.lang.reflect.Method.invoke(Method.java:498) ↵ org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215) ↵ org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132) ↵ org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104) ↵ org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:745) ↵ org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:685) ↵ org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:80) ↵ org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:919) ↵ org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:851) ↵ org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:953) ↵ org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:855) ↵ javax.servlet.http.HttpServlet.service(HttpServlet.java:652) ↵ org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:829) ↵ javax.servlet.http.HttpServlet.service(HttpServlet.java:733) ↵ org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ↵ org.springframework.orm.hibernate4.support.OpenSessionInViewFilter.doFilterInternal(OpenSessionInViewFilter.java:151) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:88) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) ↵根本原因。java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵ ↵ oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:439) ↵ oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:395) ↵ oracle.jdbc.driver.T4C8Oall.processError(T4C8Oall.java:802) ↵ oracle.jdbc.driver.T4CTTIfun.receive(T4CTTIfun.java:436) ↵ oracle.jdbc.driver.T4CTTIfun.doRPC(T4CTTIfun.java:186) ↵ oracle.jdbc.driver.T4C8Oall.doOALL(T4C8Oall.java:521) ↵ oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:205) ↵ oracle.jdbc.driver.T4CPreparedStatement.executeForRows(T4CPreparedStatement.java:1008) ↵ oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1307) ↵ oracle.jdbc.driver.OraclePreparedStatement.executeInternal(OraclePreparedStatement.java:3449) ↵ oracle.jdbc.driver.OraclePreparedStatement.execute(OraclePreparedStatement.java:3550) ↵ oracle.jdbc.driver.OraclePreparedStatementWrapper.execute(OraclePreparedStatementWrapper.java:1374) ↵ com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:2931) ↵ com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_execute(FilterEventAdapter.java:440) ↵ com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:2929) ↵ com.alibaba.druid.wall.WallFilter.preparedStatement_execute(WallFilter.java:601) ↵ com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:2929) ↵ com.alibaba.druid.proxy.jdbc.PreparedStatementProxyImpl.execute(PreparedStatementProxyImpl.java:131) ↵ com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493) ↵ sun.reflect.GeneratedMethodAccessor95.invoke(Unknown Source) ↵ sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ↵ java.lang.reflect.Method.invoke(Method.java:498) ↵ org.apache.ibatis.logging.jdbc.PreparedStatementLogger.invoke(PreparedStatementLogger.java:58) ↵ com.sun.proxy.$Proxy124.execute(Unknown Source) ↵ org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:41) ↵ org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:66) ↵ org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:45) ↵ org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:108) ↵ org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:75) ↵ org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:145) ↵ org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:134) ↵ sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ↵ sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ↵ sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ↵ java.lang.reflect.Method.invoke(Method.java:498) ↵ org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:355) ↵ com.sun.proxy.$Proxy26.insert(Unknown Source) ↵ org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:237) ↵ org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:79) ↵ org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:40) ↵ com.sun.proxy.$Proxy167.insertSelective(Unknown Source) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamRuleServiceImpl.insert(IotInterfaceParamRuleServiceImpl.java:59) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl.lambda$saveIotInterfaceParamProperties$1(IotInterfaceParamConfigServiceImpl.java:173) ↵ java.util.ArrayList.forEach(ArrayList.java:1249) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl.saveIotInterfaceParamProperties(IotInterfaceParamConfigServiceImpl.java:167) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl.add(IotInterfaceParamConfigServiceImpl.java:124) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl$$FastClassBySpringCGLIB$$b816365b.invoke(&lt;generated&gt;) ↵ org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ↵ org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:629) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl$$EnhancerBySpringCGLIB$$47ae7cb1.add(&lt;generated&gt;) ↵ com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(IotInterfaceParamConfigController.java:88) ↵ com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController$$FastClassBySpringCGLIB$$17aa7ed9.invoke(&lt;generated&gt;) ↵ org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ↵ org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:700) ↵ org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150) ↵ org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:91) ↵ org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) ↵ org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:633) ↵ com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController$$EnhancerBySpringCGLIB$$f44c91c5.save(&lt;generated&gt;) ↵ sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ↵ sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ↵ sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ↵ java.lang.reflect.Method.invoke(Method.java:498) ↵ org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215) ↵ org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132) ↵ org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104) ↵ org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:745) ↵ org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:685) ↵ org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:80) ↵ org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:919) ↵ org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:851) ↵ org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:953) ↵ org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:855) ↵ javax.servlet.http.HttpServlet.service(HttpServlet.java:652) ↵ org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:829) ↵ javax.servlet.http.HttpServlet.service(HttpServlet.java:733) ↵ org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ↵ org.springframework.orm.hibernate4.support.OpenSessionInViewFilter.doFilterInternal(OpenSessionInViewFilter.java:151) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:88) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) ↵):注意 主要问题的全部 stack 信息可以在 server logs 里查看Apache Tomcat/8.5.57\" setRequestHeader: ƒ (t,e) state: ƒ () status: 500 statusCode: ƒ (t) statusText: \"error\" success: ƒ () then: ƒ () __proto__: Object "},"各种问题/http/http415问题.html":{"url":"各种问题/http/http415问题.html","title":"http415问题","keywords":"","body":" 1、请求参数 General Reqquest URL: http://localhost:8080/fzsiotcard/api/interfacemanage/iotInterfaceDictReview/add?_=1602662669347 Request Method: POST Status Code: 415 Remote Address: [::1]:8080 Referrer Policy: strict-origin-when-cross-origin Response Headers Connection: keep-alive Content-Language: zh-CN Content-Length: 675 Content-Type: text/html;charset=utf-8 Date: Wed, 14 Oct 2020 08:04:29 GMT Keep-Alive: timeout=20 Request Headers Accept: application/json, text/javascript, */*; q=0.01 Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9 Connection: keep-alive Content-Length: 54 Content-Type: application/x-www-form-urlencoded; charset=UTF-8 Cookie: JSESSIONID=F15DD56D87E5EA271E84A5F7F78BF302; login=P_-DAwEBDkNvb2tpZVJlbWVtYmVyAf-EAAEDAQhNZW1iZXJJZAEEAAEHQWNjb3VudAEMAAEEVGltZQH_hgAAABD_hQUBAQRUaW1lAf-GAAAAHf-EAQIBBWFkbWluAQ8BAAAADtbw0KQ6weScAeAA|1600051620985785500|8b02a18f03f527ff1ba9d83799970afc65e34045 Host: localhost:8080 Origin: http://localhost:8080 Referer: http://localhost:8080/fzsiotcard/api/interfacemanage/iotInterfaceDictContent/init?interfaceDictId=2&categoryName=%E5%B9%B3%E5%8F%B0%E7%B1%BB%E5%88%AB Sec-Fetch-Dest: empty Sec-Fetch-Mode: cors Sec-Fetch-Site: same-origin User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36 X-Requested-With: XMLHttpRequest Query String Parameters _: 1602662669347 Form data dictContentId: interfaceDictId: 2 name: - LiangQingXiang 2、响应结果 HTTP状态 415 - 不支持的媒体类型 类型 状态报告 描述 源服务器拒绝服务请求，因为有效负载的格式在目标资源上此方法不支持。 Apache Tomcat/8.5.57 3、后端 @ResponseBody @RequestMapping(value = \"/add\")//, method = RequestMethod.POST) public ResultBean insert(HttpServletRequest request, HttpServletResponse response, @RequestBody IotInterfaceDictReview record) { ResultBean resultBean = new ResultBean(); iotInterfaceDictReviewService.insert(record); return resultBean; } 4、解决 是后端controller请求参数里里多了个@RequestBody导致的，这个可能是前端以json才需要用这个吧 ``` "},"各种问题/java/指针引用问题和List删除元素.html":{"url":"各种问题/java/指针引用问题和List删除元素.html","title":"指针引用问题和List删除元素","keywords":"","body":" 1、引用对象发生变化导致的问题 如下图：分析此代码有啥问题 分析：看下面的红框处，该方法看起来是没什么大问题，proList传递进来的是个引用， 问题出在第二个红框(该方法是根据proList生成xml文件)处，该同事在第二个红框的代码里拦截掉一部分proList列表里的值， 但是该同事没有对拦截掉的部分进行删除，导致proList这个还是原来的， 而第三个红框该同事又对proList所有对象进行调用api后的返回结果进行设置，注意这里更改的proList包含了 刚才第二个框框里拦截的部分对象，这样就导致有问题,所以第二个框框拦截的时候，也要对proList里拦截的对象进行删除 2、常见删除List里元素的方法 1、使用iterator List list = new ArrayList<>(); list.add(\"aa\"); list.add(\"bb\"); list.add(\"cc\"); Iterator it = list.iterator(); while(it.hasNext()){ String str = (String)it.next(); if(\"aa\".equals(str)){ it.remove(); } } System.out.println(list.size()); 2、倒序(不能正序，否则有数组溢出) List list = new ArrayList<>(); list.add(\"aa\"); list.add(\"bb\"); list.add(\"cc\"); for (int i = list.size() - 1; i >= 0; i--) { String str = list.get(i); if (\"aa\".equals(str)) { list.remove(str); } } System.out.println(list.size()); 3、使用CopyOnWriteArrayList List list = new ArrayList<>(); list.add(\"aa\"); list.add(\"bb\"); list.add(\"cc\"); CopyOnWriteArrayList cowList = new CopyOnWriteArrayList(list); for (String str : cowList) { if (\"aa\".equals(str)) { cowList.remove(str); } } System.out.println(cowList.size()); "},"各种问题/springboot/springboot排除数据源自动装配失效问题.html":{"url":"各种问题/springboot/springboot排除数据源自动装配失效问题.html","title":"springboot排除数据源自动装配失效问题","keywords":"","body":" 1、问题描述 当springboot项目不需要连接数据库，当properties或yml文件没有配spring.datasource.url等数据库连接信息时，由于springboot会自动装配，将数据源自动加载进来， 所以得把数据源自动装配的去掉，否则会报错 2020-09-10 19:35:47.810 INFO 11356 --- [ main] com.fzs.iotcard.FzsIotCardApplication : Starting FzsIotCardApplication on LAPTOP-6VJBADD9 with PID 11356 (D:\\idea-workspace3\\lqx-project-demo-github\\fzs_iot_card2\\target\\classes started by hoby in D:\\idea-workspace3\\lqx-project-demo-github) 2020-09-10 19:35:47.815 INFO 11356 --- [ main] com.fzs.iotcard.FzsIotCardApplication : The following profiles are active: local 2020-09-10 19:35:56.373 WARN 11356 --- [ main] o.m.s.mapper.ClassPathMapperScanner : No MyBatis mapper was found in '[com.fzs.iotcard]' package. Please check your configuration. 2020-09-10 19:35:56.484 INFO 11356 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode! 2020-09-10 19:35:56.486 INFO 11356 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode. 2020-09-10 19:35:56.536 INFO 11356 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 19ms. Found 0 repository interfaces. 2020-09-10 19:35:57.018 INFO 11356 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$dfe19409] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-09-10 19:35:57.615 INFO 11356 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 2020-09-10 19:35:57.658 INFO 11356 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2020-09-10 19:35:57.658 INFO 11356 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.21] 2020-09-10 19:35:57.874 INFO 11356 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 2020-09-10 19:35:57.874 INFO 11356 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 6290 ms 2020-09-10 19:35:58.394 INFO 11356 --- [ main] pertySourcedRequestMappingHandlerMapping : Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)] 2020-09-10 19:35:58.554 INFO 11356 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor' 2020-09-10 19:35:58.735 INFO 11356 --- [ main] c.a.d.s.b.a.DruidDataSourceAutoConfigure : Init DruidDataSource 2020-09-10 19:35:58.820 WARN 11356 --- [ main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/alibaba/druid/spring/boot/autoconfigure/DruidDataSourceAutoConfigure.class]: Invocation of init method failed; nested exception is org.springframework.boot.autoconfigure.jdbc.DataSourceProperties$DataSourceBeanCreationException: Failed to determine a suitable driver class 2020-09-10 19:35:58.821 INFO 11356 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Shutting down ExecutorService 'applicationTaskExecutor' 2020-09-10 19:35:58.824 INFO 11356 --- [ main] o.apache.catalina.core.StandardService : Stopping service [Tomcat] 2020-09-10 19:35:58.919 INFO 11356 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2020-09-10 19:35:58.923 ERROR 11356 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter : *************************** APPLICATION FAILED TO START *************************** Description: Failed to configure a DataSource: 'url' attribute is not specified and no embedded datasource could be configured. Reason: Failed to determine a suitable driver class Action: Consider the following: If you want an embedded database (H2, HSQL or Derby), please put it on the classpath. If you have database settings to be loaded from a particular profile you may need to activate it (no profiles are currently active). Process finished with exit code 1 2、问题分析 参考了网上把下面DataSourceAutoConfiguration.class, HibernateJpaAutoConfiguration.class进行了排除 @SpringBootApplication(exclude = {DataSourceAutoConfiguration.class, HibernateJpaAutoConfiguration.class) 但是排除掉后还是报相同的错，网上搜索了都不行然后自己仔细看打印的日志，发现有行 2020-09-10 19:35:58.735 INFO 11356 --- [ main] c.a.d.s.b.a.DruidDataSourceAutoConfigure : Init DruidDataSource 然后网上一搜DruidDataSourceAutoConfigure发现springboot也会默认装置druid的数据源，所以得把这个也排除掉 DruidDataSourceAutoConfigure源码如下: @Configuration @ConditionalOnClass(DruidDataSource.class) @AutoConfigureBefore(DataSourceAutoConfiguration.class) @EnableConfigurationProperties({DruidStatProperties.class, DataSourceProperties.class}) @Import({DruidSpringAopConfiguration.class, DruidStatViewServletConfiguration.class, DruidWebStatFilterConfiguration.class, DruidFilterConfiguration.class}) public class DruidDataSourceAutoConfigure { private static final Logger LOGGER = LoggerFactory.getLogger(DruidDataSourceAutoConfigure.class); @Bean(initMethod = \"init\") @ConditionalOnMissingBean public DataSource dataSource() { LOGGER.info(\"Init DruidDataSource\"); return new DruidDataSourceWrapper(); } } 当代码中缺失不配置DataSource就会默认创建一个DataSource，具体又是创建DruidDataSourceWrapper，而DruidDataSourceWrapper定义如下： @ConfigurationProperties(\"spring.datasource.druid\") class DruidDataSourceWrapper extends DruidDataSource implements InitializingBean { 看到这里是依赖了spring.datasource.druid相关的druid配置，所以得把DruidDataSourceAutoConfigure也排除掉 3、问题解决 同时把DataSourceAutoConfiguration.class, HibernateJpaAutoConfiguration.class, DruidDataSourceAutoConfigure.class 这3个排除掉即可 @SpringBootApplication(exclude = {DataSourceAutoConfiguration.class, HibernateJpaAutoConfiguration.class, DruidDataSourceAutoConfigure.class}) @EnableSwagger2 public class FzsIotCardApplication { public static void main(String[] args) { SpringApplication app = new SpringApplication(FzsIotCardApplication.class); app.setBannerMode(Banner.Mode.OFF); app.run(args); } } 或者把pom中的druid-spring-boot-starter去掉，DruidDataSourceAutoConfigure是存在这个包里的 com.alibaba druid-spring-boot-starter ${druid.starter.version} 参考： https://blog.csdn.net/superyu1992/article/details/80336928 "},"各种问题/springboot/springboot日志问题.html":{"url":"各种问题/springboot/springboot日志问题.html","title":"springboot日志问题","keywords":"","body":" 1、springboot启动报日志错误问题 \"D:\\Program Files\\Java8\\jdk1.8.0_77\\bin\\java.exe\" -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:58693,suspend=y,server=n -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -javaagent:C:\\Users\\Administrator\\.IntelliJIdea2019.2\\system\\captureAgent\\debugger-agent.jar -Dfile.encoding=UTF-8 -classpath \"D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\charsets.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\deploy.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\access-bridge-64.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\cldrdata.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\dnsns.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\jaccess.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\jfxrt.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\localedata.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\nashorn.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\sunec.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\sunjce_provider.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\sunmscapi.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\sunpkcs11.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\zipfs.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\javaws.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\jce.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\jfr.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\jfxswt.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\jsse.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\management-agent.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\plugin.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\resources.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\rt.jar;D:\\2\\lqx-project-demo\\basic-server\\target\\classes;D:\\2\\lqx-project-demo\\demo\\search\\elasticsearch-starter\\target\\classes;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-autoconfigure\\2.1.6.RELEASE\\spring-boot-autoconfigure-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-configuration-processor\\2.1.6.RELEASE\\spring-boot-configuration-processor-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-json\\2.1.6.RELEASE\\spring-boot-starter-json-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-web\\5.1.8.RELEASE\\spring-web-5.1.8.RELEASE.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\datatype\\jackson-datatype-jdk8\\2.9.9\\jackson-datatype-jdk8-2.9.9.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\datatype\\jackson-datatype-jsr310\\2.9.9\\jackson-datatype-jsr310-2.9.9.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\module\\jackson-module-parameter-names\\2.9.9\\jackson-module-parameter-names-2.9.9.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-data-jpa\\2.1.6.RELEASE\\spring-boot-starter-data-jpa-2.1.6.RELEASE.jar;D:\\maven\\repository\\javax\\transaction\\javax.transaction-api\\1.3\\javax.transaction-api-1.3.jar;D:\\maven\\repository\\javax\\xml\\bind\\jaxb-api\\2.3.1\\jaxb-api-2.3.1.jar;D:\\maven\\repository\\javax\\activation\\javax.activation-api\\1.2.0\\javax.activation-api-1.2.0.jar;D:\\maven\\repository\\org\\hibernate\\hibernate-core\\5.3.10.Final\\hibernate-core-5.3.10.Final.jar;D:\\maven\\repository\\org\\jboss\\logging\\jboss-logging\\3.3.2.Final\\jboss-logging-3.3.2.Final.jar;D:\\maven\\repository\\antlr\\antlr\\2.7.7\\antlr-2.7.7.jar;D:\\maven\\repository\\org\\jboss\\jandex\\2.0.5.Final\\jandex-2.0.5.Final.jar;D:\\maven\\repository\\org\\dom4j\\dom4j\\2.1.1\\dom4j-2.1.1.jar;D:\\maven\\repository\\org\\hibernate\\common\\hibernate-commons-annotations\\5.0.4.Final\\hibernate-commons-annotations-5.0.4.Final.jar;D:\\maven\\repository\\org\\springframework\\data\\spring-data-jpa\\2.1.9.RELEASE\\spring-data-jpa-2.1.9.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\data\\spring-data-commons\\2.1.9.RELEASE\\spring-data-commons-2.1.9.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-orm\\5.1.8.RELEASE\\spring-orm-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-aspects\\5.1.8.RELEASE\\spring-aspects-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-web\\2.1.6.RELEASE\\spring-boot-starter-web-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-tomcat\\2.1.6.RELEASE\\spring-boot-starter-tomcat-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\apache\\tomcat\\embed\\tomcat-embed-core\\9.0.21\\tomcat-embed-core-9.0.21.jar;D:\\maven\\repository\\org\\apache\\tomcat\\embed\\tomcat-embed-el\\9.0.21\\tomcat-embed-el-9.0.21.jar;D:\\maven\\repository\\org\\apache\\tomcat\\embed\\tomcat-embed-websocket\\9.0.21\\tomcat-embed-websocket-9.0.21.jar;D:\\maven\\repository\\org\\hibernate\\validator\\hibernate-validator\\6.0.17.Final\\hibernate-validator-6.0.17.Final.jar;D:\\maven\\repository\\javax\\validation\\validation-api\\2.0.1.Final\\validation-api-2.0.1.Final.jar;D:\\maven\\repository\\org\\springframework\\spring-webmvc\\5.1.8.RELEASE\\spring-webmvc-5.1.8.RELEASE.jar;D:\\maven\\repository\\commons-codec\\commons-codec\\1.12\\commons-codec-1.12.jar;D:\\maven\\repository\\io\\springfox\\springfox-swagger2\\2.7.0\\springfox-swagger2-2.7.0.jar;D:\\maven\\repository\\io\\swagger\\swagger-annotations\\1.5.13\\swagger-annotations-1.5.13.jar;D:\\maven\\repository\\io\\swagger\\swagger-models\\1.5.13\\swagger-models-1.5.13.jar;D:\\maven\\repository\\io\\springfox\\springfox-spi\\2.7.0\\springfox-spi-2.7.0.jar;D:\\maven\\repository\\io\\springfox\\springfox-core\\2.7.0\\springfox-core-2.7.0.jar;D:\\maven\\repository\\io\\springfox\\springfox-schema\\2.7.0\\springfox-schema-2.7.0.jar;D:\\maven\\repository\\io\\springfox\\springfox-swagger-common\\2.7.0\\springfox-swagger-common-2.7.0.jar;D:\\maven\\repository\\io\\springfox\\springfox-spring-web\\2.7.0\\springfox-spring-web-2.7.0.jar;D:\\maven\\repository\\org\\reflections\\reflections\\0.9.11\\reflections-0.9.11.jar;D:\\maven\\repository\\com\\google\\guava\\guava\\18.0\\guava-18.0.jar;D:\\maven\\repository\\com\\fasterxml\\classmate\\1.4.0\\classmate-1.4.0.jar;D:\\maven\\repository\\org\\springframework\\plugin\\spring-plugin-core\\1.2.0.RELEASE\\spring-plugin-core-1.2.0.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\plugin\\spring-plugin-metadata\\1.2.0.RELEASE\\spring-plugin-metadata-1.2.0.RELEASE.jar;D:\\maven\\repository\\org\\mapstruct\\mapstruct\\1.1.0.Final\\mapstruct-1.1.0.Final.jar;D:\\maven\\repository\\io\\springfox\\springfox-swagger-ui\\2.7.0\\springfox-swagger-ui-2.7.0.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-log4j\\1.3.5.RELEASE\\spring-boot-starter-log4j-1.3.5.RELEASE.jar;D:\\maven\\repository\\org\\slf4j\\slf4j-log4j12\\1.7.26\\slf4j-log4j12-1.7.26.jar;D:\\maven\\repository\\log4j\\log4j\\1.2.17\\log4j-1.2.17.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-data-redis\\2.1.6.RELEASE\\spring-boot-starter-data-redis-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\data\\spring-data-redis\\2.1.9.RELEASE\\spring-data-redis-2.1.9.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\data\\spring-data-keyvalue\\2.1.9.RELEASE\\spring-data-keyvalue-2.1.9.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-oxm\\5.1.8.RELEASE\\spring-oxm-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-context-support\\5.1.8.RELEASE\\spring-context-support-5.1.8.RELEASE.jar;D:\\maven\\repository\\io\\lettuce\\lettuce-core\\5.1.7.RELEASE\\lettuce-core-5.1.7.RELEASE.jar;D:\\maven\\repository\\com\\alibaba\\fastjson\\1.2.44\\fastjson-1.2.44.jar;D:\\maven\\repository\\org\\apache\\httpcomponents\\httpclient\\4.4.1\\httpclient-4.4.1.jar;D:\\maven\\repository\\org\\apache\\httpcomponents\\httpcore\\4.4.11\\httpcore-4.4.11.jar;D:\\maven\\repository\\com\\google\\code\\gson\\gson\\2.8.5\\gson-2.8.5.jar;D:\\maven\\repository\\org\\elasticsearch\\elasticsearch\\6.4.3\\elasticsearch-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\elasticsearch-core\\6.4.3\\elasticsearch-core-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\elasticsearch-secure-sm\\6.4.3\\elasticsearch-secure-sm-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\elasticsearch-x-content\\6.4.3\\elasticsearch-x-content-6.4.3.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\dataformat\\jackson-dataformat-smile\\2.9.9\\jackson-dataformat-smile-2.9.9.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\dataformat\\jackson-dataformat-cbor\\2.9.9\\jackson-dataformat-cbor-2.9.9.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-core\\7.4.0\\lucene-core-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-analyzers-common\\7.4.0\\lucene-analyzers-common-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-backward-codecs\\7.4.0\\lucene-backward-codecs-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-grouping\\7.4.0\\lucene-grouping-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-highlighter\\7.4.0\\lucene-highlighter-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-join\\7.4.0\\lucene-join-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-memory\\7.4.0\\lucene-memory-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-misc\\7.4.0\\lucene-misc-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-queries\\7.4.0\\lucene-queries-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-queryparser\\7.4.0\\lucene-queryparser-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-sandbox\\7.4.0\\lucene-sandbox-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-spatial\\7.4.0\\lucene-spatial-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-spatial-extras\\7.4.0\\lucene-spatial-extras-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-spatial3d\\7.4.0\\lucene-spatial3d-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-suggest\\7.4.0\\lucene-suggest-7.4.0.jar;D:\\maven\\repository\\org\\elasticsearch\\elasticsearch-cli\\6.4.3\\elasticsearch-cli-6.4.3.jar;D:\\maven\\repository\\net\\sf\\jopt-simple\\jopt-simple\\5.0.2\\jopt-simple-5.0.2.jar;D:\\maven\\repository\\com\\carrotsearch\\hppc\\0.7.1\\hppc-0.7.1.jar;D:\\maven\\repository\\joda-time\\joda-time\\2.10.2\\joda-time-2.10.2.jar;D:\\maven\\repository\\com\\tdunning\\t-digest\\3.2\\t-digest-3.2.jar;D:\\maven\\repository\\org\\hdrhistogram\\HdrHistogram\\2.1.9\\HdrHistogram-2.1.9.jar;D:\\maven\\repository\\org\\apache\\logging\\log4j\\log4j-api\\2.11.2\\log4j-api-2.11.2.jar;D:\\maven\\repository\\org\\elasticsearch\\jna\\4.5.1\\jna-4.5.1.jar;D:\\maven\\repository\\org\\elasticsearch\\client\\rest\\6.0.0-alpha1\\rest-6.0.0-alpha1.jar;D:\\maven\\repository\\org\\apache\\httpcomponents\\httpasyncclient\\4.1.4\\httpasyncclient-4.1.4.jar;D:\\maven\\repository\\org\\apache\\httpcomponents\\httpcore-nio\\4.4.11\\httpcore-nio-4.4.11.jar;D:\\maven\\repository\\org\\elasticsearch\\client\\elasticsearch-rest-high-level-client\\6.4.3\\elasticsearch-rest-high-level-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\client\\elasticsearch-rest-client\\6.4.3\\elasticsearch-rest-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\parent-join-client\\6.4.3\\parent-join-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\aggs-matrix-stats-client\\6.4.3\\aggs-matrix-stats-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\rank-eval-client\\6.4.3\\rank-eval-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\lang-mustache-client\\6.4.3\\lang-mustache-client-6.4.3.jar;D:\\maven\\repository\\com\\github\\spullara\\mustache\\java\\compiler\\0.9.3\\compiler-0.9.3.jar;D:\\maven\\repository\\org\\elasticsearch\\client\\transport\\6.4.3\\transport-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\reindex-client\\6.4.3\\reindex-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\percolator-client\\6.4.3\\percolator-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\transport-netty4-client\\6.4.3\\transport-netty4-client-6.4.3.jar;D:\\maven\\repository\\io\\netty\\netty-codec-http\\4.1.36.Final\\netty-codec-http-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-resolver\\4.1.36.Final\\netty-resolver-4.1.36.Final.jar;D:\\maven\\repository\\org\\ansj\\ansj_seg\\5.1.1\\ansj_seg-5.1.1.jar;D:\\maven\\repository\\org\\nlpcn\\nlp-lang\\1.7.2\\nlp-lang-1.7.2.jar;D:\\maven\\repository\\org\\apache\\httpcomponents\\httpmime\\4.5.6\\httpmime-4.5.6.jar;D:\\maven\\repository\\org\\jsoup\\jsoup\\1.11.2\\jsoup-1.11.2.jar;D:\\maven\\repository\\javax\\servlet\\javax.servlet-api\\4.0.1\\javax.servlet-api-4.0.1.jar;D:\\maven\\repository\\javax\\persistence\\javax.persistence-api\\2.2\\javax.persistence-api-2.2.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-core\\1.4.0\\shiro-core-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-lang\\1.4.0\\shiro-lang-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-cache\\1.4.0\\shiro-cache-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-crypto-hash\\1.4.0\\shiro-crypto-hash-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-crypto-core\\1.4.0\\shiro-crypto-core-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-crypto-cipher\\1.4.0\\shiro-crypto-cipher-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-config-core\\1.4.0\\shiro-config-core-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-config-ogdl\\1.4.0\\shiro-config-ogdl-1.4.0.jar;D:\\maven\\repository\\commons-beanutils\\commons-beanutils\\1.9.3\\commons-beanutils-1.9.3.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-event\\1.4.0\\shiro-event-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-web\\1.4.0\\shiro-web-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-spring\\1.4.0\\shiro-spring-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-ehcache\\1.4.0\\shiro-ehcache-1.4.0.jar;D:\\maven\\repository\\net\\sf\\ehcache\\ehcache-core\\2.6.11\\ehcache-core-2.6.11.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-amqp\\2.1.6.RELEASE\\spring-boot-starter-amqp-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-messaging\\5.1.8.RELEASE\\spring-messaging-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-beans\\5.1.8.RELEASE\\spring-beans-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\amqp\\spring-rabbit\\2.1.7.RELEASE\\spring-rabbit-2.1.7.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\amqp\\spring-amqp\\2.1.7.RELEASE\\spring-amqp-2.1.7.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\retry\\spring-retry\\1.2.4.RELEASE\\spring-retry-1.2.4.RELEASE.jar;D:\\maven\\repository\\com\\rabbitmq\\amqp-client\\5.4.3\\amqp-client-5.4.3.jar;D:\\maven\\repository\\org\\springframework\\spring-tx\\5.1.8.RELEASE\\spring-tx-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\projectlombok\\lombok\\1.16.10\\lombok-1.16.10.jar;D:\\maven\\repository\\org\\redisson\\redisson\\3.11.2\\redisson-3.11.2.jar;D:\\maven\\repository\\io\\netty\\netty-common\\4.1.36.Final\\netty-common-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-codec\\4.1.36.Final\\netty-codec-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-buffer\\4.1.36.Final\\netty-buffer-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-transport\\4.1.36.Final\\netty-transport-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-resolver-dns\\4.1.36.Final\\netty-resolver-dns-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-codec-dns\\4.1.36.Final\\netty-codec-dns-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-handler\\4.1.36.Final\\netty-handler-4.1.36.Final.jar;D:\\maven\\repository\\javax\\cache\\cache-api\\1.1.1\\cache-api-1.1.1.jar;D:\\maven\\repository\\io\\projectreactor\\reactor-core\\3.2.10.RELEASE\\reactor-core-3.2.10.RELEASE.jar;D:\\maven\\repository\\org\\reactivestreams\\reactive-streams\\1.0.2\\reactive-streams-1.0.2.jar;D:\\maven\\repository\\io\\reactivex\\rxjava2\\rxjava\\2.2.9\\rxjava-2.2.9.jar;D:\\maven\\repository\\de\\ruedigermoeller\\fst\\2.57\\fst-2.57.jar;D:\\maven\\repository\\org\\javassist\\javassist\\3.21.0-GA\\javassist-3.21.0-GA.jar;D:\\maven\\repository\\org\\objenesis\\objenesis\\2.5.1\\objenesis-2.5.1.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\dataformat\\jackson-dataformat-yaml\\2.9.9\\jackson-dataformat-yaml-2.9.9.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\core\\jackson-core\\2.9.9\\jackson-core-2.9.9.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\core\\jackson-databind\\2.9.9\\jackson-databind-2.9.9.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\core\\jackson-annotations\\2.9.0\\jackson-annotations-2.9.0.jar;D:\\maven\\repository\\net\\bytebuddy\\byte-buddy\\1.9.13\\byte-buddy-1.9.13.jar;D:\\maven\\repository\\org\\jodd\\jodd-bean\\5.0.10\\jodd-bean-5.0.10.jar;D:\\maven\\repository\\org\\jodd\\jodd-core\\5.0.10\\jodd-core-5.0.10.jar;D:\\maven\\repository\\org\\redisson\\redisson-spring-boot-starter\\3.11.2\\redisson-spring-boot-starter-3.11.2.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-actuator\\2.1.6.RELEASE\\spring-boot-starter-actuator-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-actuator-autoconfigure\\2.1.6.RELEASE\\spring-boot-actuator-autoconfigure-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-actuator\\2.1.6.RELEASE\\spring-boot-actuator-2.1.6.RELEASE.jar;D:\\maven\\repository\\io\\micrometer\\micrometer-core\\1.1.5\\micrometer-core-1.1.5.jar;D:\\maven\\repository\\org\\latencyutils\\LatencyUtils\\2.0.3\\LatencyUtils-2.0.3.jar;D:\\maven\\repository\\org\\redisson\\redisson-spring-data-21\\3.11.2\\redisson-spring-data-21-3.11.2.jar;D:\\maven\\repository\\org\\apache\\poi\\poi\\4.0.0\\poi-4.0.0.jar;D:\\maven\\repository\\org\\apache\\poi\\poi-ooxml\\4.0.0\\poi-ooxml-4.0.0.jar;D:\\maven\\repository\\org\\apache\\poi\\poi-ooxml-schemas\\4.0.0\\poi-ooxml-schemas-4.0.0.jar;D:\\maven\\repository\\org\\apache\\xmlbeans\\xmlbeans\\3.0.1\\xmlbeans-3.0.1.jar;D:\\maven\\repository\\org\\apache\\commons\\commons-compress\\1.18\\commons-compress-1.18.jar;D:\\maven\\repository\\com\\github\\virtuald\\curvesapi\\1.04\\curvesapi-1.04.jar;D:\\maven\\repository\\com\\xuxueli\\xxl-job-core\\1.8.2\\xxl-job-core-1.8.2.jar;D:\\maven\\repository\\javax\\servlet\\jsp\\jsp-api\\2.2\\jsp-api-2.2.jar;D:\\maven\\repository\\org\\eclipse\\jetty\\jetty-server\\9.4.19.v20190610\\jetty-server-9.4.19.v20190610.jar;D:\\maven\\repository\\org\\eclipse\\jetty\\jetty-http\\9.4.19.v20190610\\jetty-http-9.4.19.v20190610.jar;D:\\maven\\repository\\org\\eclipse\\jetty\\jetty-util\\9.4.19.v20190610\\jetty-util-9.4.19.v20190610.jar;D:\\maven\\repository\\org\\eclipse\\jetty\\jetty-io\\9.4.19.v20190610\\jetty-io-9.4.19.v20190610.jar;D:\\maven\\repository\\com\\caucho\\hessian\\4.0.38\\hessian-4.0.38.jar;D:\\maven\\repository\\org\\codehaus\\jackson\\jackson-mapper-asl\\1.9.13\\jackson-mapper-asl-1.9.13.jar;D:\\maven\\repository\\org\\codehaus\\jackson\\jackson-core-asl\\1.9.13\\jackson-core-asl-1.9.13.jar;D:\\maven\\repository\\org\\springframework\\spring-context\\5.1.8.RELEASE\\spring-context-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-aop\\5.1.8.RELEASE\\spring-aop-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-expression\\5.1.8.RELEASE\\spring-expression-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\codehaus\\groovy\\groovy-all\\2.4.5\\groovy-all-2.4.5.jar;D:\\maven\\repository\\org\\apache\\commons\\commons-exec\\1.3\\commons-exec-1.3.jar;D:\\maven\\repository\\com\\belerweb\\pinyin4j\\2.5.0\\pinyin4j-2.5.0.jar;D:\\maven\\repository\\org\\slf4j\\slf4j-api\\1.7.26\\slf4j-api-1.7.26.jar;D:\\maven\\repository\\org\\slf4j\\jcl-over-slf4j\\1.7.26\\jcl-over-slf4j-1.7.26.jar;D:\\maven\\repository\\org\\slf4j\\jul-to-slf4j\\1.7.26\\jul-to-slf4j-1.7.26.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter\\2.1.6.RELEASE\\spring-boot-starter-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot\\2.1.6.RELEASE\\spring-boot-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-logging\\2.1.6.RELEASE\\spring-boot-starter-logging-2.1.6.RELEASE.jar;D:\\maven\\repository\\ch\\qos\\logback\\logback-classic\\1.2.3\\logback-classic-1.2.3.jar;D:\\maven\\repository\\ch\\qos\\logback\\logback-core\\1.2.3\\logback-core-1.2.3.jar;D:\\maven\\repository\\org\\apache\\logging\\log4j\\log4j-to-slf4j\\2.11.2\\log4j-to-slf4j-2.11.2.jar;D:\\maven\\repository\\javax\\annotation\\javax.annotation-api\\1.3.2\\javax.annotation-api-1.3.2.jar;D:\\maven\\repository\\org\\springframework\\spring-core\\5.1.8.RELEASE\\spring-core-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-jcl\\5.1.8.RELEASE\\spring-jcl-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\yaml\\snakeyaml\\1.23\\snakeyaml-1.23.jar;D:\\maven\\repository\\redis\\clients\\jedis\\3.0.1\\jedis-3.0.1.jar;D:\\maven\\repository\\org\\apache\\commons\\commons-pool2\\2.6.2\\commons-pool2-2.6.2.jar;D:\\maven\\repository\\com\\baomidou\\mybatis-plus-boot-starter\\3.1.2\\mybatis-plus-boot-starter-3.1.2.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-jdbc\\2.1.6.RELEASE\\spring-boot-starter-jdbc-2.1.6.RELEASE.jar;D:\\maven\\repository\\com\\zaxxer\\HikariCP\\3.2.0\\HikariCP-3.2.0.jar;D:\\maven\\repository\\org\\springframework\\spring-jdbc\\5.1.8.RELEASE\\spring-jdbc-5.1.8.RELEASE.jar;D:\\maven\\repository\\com\\baomidou\\mybatis-plus\\3.1.2\\mybatis-plus-3.1.2.jar;D:\\maven\\repository\\com\\baomidou\\mybatis-plus-generator\\3.1.2\\mybatis-plus-generator-3.1.2.jar;D:\\maven\\repository\\com\\alibaba\\druid\\1.1.18\\druid-1.1.18.jar;D:\\maven\\repository\\com\\alibaba\\druid-spring-boot-starter\\1.1.18\\druid-spring-boot-starter-1.1.18.jar;D:\\maven\\repository\\org\\json\\json\\20180130\\json-20180130.jar;D:\\maven\\repository\\org\\apache\\oltu\\oauth2\\org.apache.oltu.oauth2.client\\0.31\\org.apache.oltu.oauth2.client-0.31.jar;D:\\maven\\repository\\org\\apache\\oltu\\oauth2\\org.apache.oltu.oauth2.common\\0.31\\org.apache.oltu.oauth2.common-0.31.jar;D:\\maven\\repository\\org\\codehaus\\jettison\\jettison\\1.2\\jettison-1.2.jar;D:\\maven\\repository\\com\\squareup\\okhttp3\\okhttp\\3.8.1\\okhttp-3.8.1.jar;D:\\maven\\repository\\com\\squareup\\okio\\okio\\1.13.0\\okio-1.13.0.jar;D:\\maven\\repository\\org\\apache\\commons\\commons-collections4\\4.4\\commons-collections4-4.4.jar;D:\\maven\\repository\\org\\apache\\commons\\commons-vfs2\\2.1\\commons-vfs2-2.1.jar;D:\\maven\\repository\\commons-logging\\commons-logging\\1.2\\commons-logging-1.2.jar;D:\\maven\\repository\\org\\apache\\commons\\commons-lang3\\3.4\\commons-lang3-3.4.jar;D:\\maven\\repository\\commons-collections\\commons-collections\\3.1\\commons-collections-3.1.jar;D:\\maven\\repository\\commons-fileupload\\commons-fileupload\\1.3.1\\commons-fileupload-1.3.1.jar;D:\\maven\\repository\\commons-io\\commons-io\\2.2\\commons-io-2.2.jar;D:\\maven\\repository\\com\\baomidou\\mybatis-plus-extension\\3.1.2\\mybatis-plus-extension-3.1.2.jar;D:\\maven\\repository\\com\\baomidou\\mybatis-plus-core\\3.1.2\\mybatis-plus-core-3.1.2.jar;D:\\maven\\repository\\com\\baomidou\\mybatis-plus-annotation\\3.1.2\\mybatis-plus-annotation-3.1.2.jar;D:\\maven\\repository\\com\\github\\jsqlparser\\jsqlparser\\1.2\\jsqlparser-1.2.jar;D:\\maven\\repository\\org\\mybatis\\mybatis\\3.5.1\\mybatis-3.5.1.jar;D:\\maven\\repository\\org\\mybatis\\mybatis-spring\\2.0.1\\mybatis-spring-2.0.1.jar;D:\\maven\\repository\\com\\baomidou\\dynamic-datasource-spring-boot-starter\\2.5.5\\dynamic-datasource-spring-boot-starter-2.5.5.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-aop\\2.1.6.RELEASE\\spring-boot-starter-aop-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\aspectj\\aspectjweaver\\1.9.4\\aspectjweaver-1.9.4.jar;D:\\IntelliJ IDEA 2019.2.1\\lib\\idea_rt.jar\" com.basic.BasicServerApplication Connected to the target VM, address: '127.0.0.1:58693', transport: 'socket' SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/D:/maven/repository/org/slf4j/slf4j-log4j12/1.7.26/slf4j-log4j12-1.7.26.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/D:/maven/repository/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory] Exception in thread \"main\" java.lang.IllegalArgumentException: LoggerFactory is not a Logback LoggerContext but Logback is on the classpath. Either remove Logback or the competing implementation (class org.slf4j.impl.Log4jLoggerFactory loaded from file:/D:/maven/repository/org/slf4j/slf4j-log4j12/1.7.26/slf4j-log4j12-1.7.26.jar). If you are using WebLogic you will need to add 'org.slf4j' to prefer-application-packages in WEB-INF/weblogic.xml: org.slf4j.impl.Log4jLoggerFactory at org.springframework.util.Assert.instanceCheckFailed(Assert.java:655) at org.springframework.util.Assert.isInstanceOf(Assert.java:555) at org.springframework.boot.logging.logback.LogbackLoggingSystem.getLoggerContext(LogbackLoggingSystem.java:279) at org.springframework.boot.logging.logback.LogbackLoggingSystem.beforeInitialize(LogbackLoggingSystem.java:103) at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationStartingEvent(LoggingApplicationListener.java:212) at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:193) at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:127) at org.springframework.boot.context.event.EventPublishingRunListener.starting(EventPublishingRunListener.java:69) at org.springframework.boot.SpringApplicationRunListeners.starting(SpringApplicationRunListeners.java:47) at org.springframework.boot.SpringApplication.run(SpringApplication.java:301) at com.basic.BasicServerApplication.main(BasicServerApplication.java:30) Disconnected from the target VM, address: '127.0.0.1:58693', transport: 'socket' Process finished with exit code 1 2、代码分析 通过点击报错日志里面的具体报错类，查找到对应LogbackLoggingSystem.java下面的代码 private LoggerContext getLoggerContext() { ILoggerFactory factory = StaticLoggerBinder.getSingleton().getLoggerFactory(); Assert.isInstanceOf(LoggerContext.class, factory, String.format( \"LoggerFactory is not a Logback LoggerContext but Logback is on \" + \"the classpath. Either remove Logback or the competing \" + \"implementation (%s loaded from %s). If you are using \" + \"WebLogic you will need to add 'org.slf4j' to \" + \"prefer-application-packages in WEB-INF/weblogic.xml\", factory.getClass(), getLocation(factory))); return (LoggerContext) factory; } private Object getLocation(ILoggerFactory factory) { try { ProtectionDomain protectionDomain = factory.getClass().getProtectionDomain(); CodeSource codeSource = protectionDomain.getCodeSource(); if (codeSource != null) { return codeSource.getLocation(); } } catch (SecurityException ex) { // Unable to determine location } return \"unknown location\"; } public static void isInstanceOf(Class type, @Nullable Object obj, String message) { notNull(type, \"Type to check against must not be null\"); if (!type.isInstance(obj)) { instanceCheckFailed(type, obj, message); } } 代码分析如下： LoggerContext这个通过import导入的包发现是logback的，就是logback-classic:jar:1.2.3.jar下的 factory通过getLocation获取到的结果是file:/D:/maven/repository/org/slf4j/slf4j-log4j12/1.7.26/slf4j-log4j12-1.7.26.jar路径下的 通过Assert.isInstanceOf(LoggerContext.class, factory比较发现这2者不是对应的关系 所以报String.format( \"LoggerFactory is not a Logback LoggerContext but Logback is on \" + \"the classpath. Either remove Logback or the competing \" + \"implementation (%s loaded from %s). If you are using \" + \"WebLogic you will need to add 'org.slf4j' to \" + \"prefer-application-packages in WEB-INF/weblogic.xml\", factory.getClass(), getLocation(factory))) 这段错误，也就是日志打印出来的错误 看maven仓库也会发现也存在slf4j-log4j12对应的包 3、解决 去到对应项目下，执行mvn dependency:tree,结果如下 搜索log4j或搜索slf4j-log4j12，看到存在slf4j-log4j12-1.7.26.jar这个jar包,看到他是在elasitcsearch-starter这个项目下的[INFO] +- com.basic.search:elasitcsearch-starter:jar:1.0.0:compile [INFO] | +- org.springframework.boot:spring-boot-starter-log4j:jar:1.3.5.RELEASE:compile [INFO] | | +- org.slf4j:slf4j-log4j12:jar:1.7.26:compile 查看elasitcsearch-starter这个项目的pom.xml，看到引入了spring-boot-starter-log4j，问题就在这里了，这里会依赖slf4j-log4j12 org.springframework.boot spring-boot-starter-log4j ${spring-log4j.version} 解决办法：引用elasitcsearch-starter时排除掉slf4j-log4j12即可 com.basic.search elasitcsearch-starter 1.0.0 org.slf4j slf4j-log4j12 附注：未解决之前项目依赖如下： λ mvn dependency:tree [INFO] Scanning for projects... [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building basic-server 2.0.2 [INFO] ------------------------------------------------------------------------ [INFO] [INFO] --- maven-dependency-plugin:3.1.1:tree (default-cli) @ basic-server --- [INFO] com.basic:basic-server:jar:2.0.2 [INFO] +- com.basic.search:elasitcsearch-starter:jar:1.0.0:compile [INFO] | +- org.springframework.boot:spring-boot-autoconfigure:jar:2.1.6.RELEASE:compile [INFO] | +- org.springframework.boot:spring-boot-configuration-processor:jar:2.1.6.RELEASE:compile [INFO] | +- org.springframework.boot:spring-boot-starter-json:jar:2.1.6.RELEASE:compile [INFO] | | +- org.springframework:spring-web:jar:5.1.8.RELEASE:compile [INFO] | | +- com.fasterxml.jackson.datatype:jackson-datatype-jdk8:jar:2.9.9:compile [INFO] | | +- com.fasterxml.jackson.datatype:jackson-datatype-jsr310:jar:2.9.9:compile [INFO] | | \\- com.fasterxml.jackson.module:jackson-module-parameter-names:jar:2.9.9:compile [INFO] | +- org.springframework.boot:spring-boot-starter-data-jpa:jar:2.1.6.RELEASE:compile [INFO] | | +- javax.transaction:javax.transaction-api:jar:1.3:compile [INFO] | | +- javax.xml.bind:jaxb-api:jar:2.3.1:compile [INFO] | | | \\- javax.activation:javax.activation-api:jar:1.2.0:compile [INFO] | | +- org.hibernate:hibernate-core:jar:5.3.10.Final:compile [INFO] | | | +- org.jboss.logging:jboss-logging:jar:3.3.2.Final:compile [INFO] | | | +- antlr:antlr:jar:2.7.7:compile [INFO] | | | +- org.jboss:jandex:jar:2.0.5.Final:compile [INFO] | | | +- org.dom4j:dom4j:jar:2.1.1:compile [INFO] | | | \\- org.hibernate.common:hibernate-commons-annotations:jar:5.0.4.Final:compile [INFO] | | +- org.springframework.data:spring-data-jpa:jar:2.1.9.RELEASE:compile [INFO] | | | +- org.springframework.data:spring-data-commons:jar:2.1.9.RELEASE:compile [INFO] | | | \\- org.springframework:spring-orm:jar:5.1.8.RELEASE:compile [INFO] | | \\- org.springframework:spring-aspects:jar:5.1.8.RELEASE:compile [INFO] | +- org.springframework.boot:spring-boot-starter-web:jar:2.1.6.RELEASE:compile [INFO] | | +- org.springframework.boot:spring-boot-starter-tomcat:jar:2.1.6.RELEASE:compile [INFO] | | | +- org.apache.tomcat.embed:tomcat-embed-core:jar:9.0.21:compile [INFO] | | | +- org.apache.tomcat.embed:tomcat-embed-el:jar:9.0.21:compile [INFO] | | | \\- org.apache.tomcat.embed:tomcat-embed-websocket:jar:9.0.21:compile [INFO] | | +- org.hibernate.validator:hibernate-validator:jar:6.0.17.Final:compile [INFO] | | | \\- javax.validation:validation-api:jar:2.0.1.Final:compile [INFO] | | \\- org.springframework:spring-webmvc:jar:5.1.8.RELEASE:compile [INFO] | +- commons-codec:commons-codec:jar:1.12:compile [INFO] | +- io.springfox:springfox-swagger2:jar:2.7.0:compile [INFO] | | +- io.swagger:swagger-annotations:jar:1.5.13:compile [INFO] | | +- io.swagger:swagger-models:jar:1.5.13:compile [INFO] | | +- io.springfox:springfox-spi:jar:2.7.0:compile [INFO] | | | \\- io.springfox:springfox-core:jar:2.7.0:compile [INFO] | | +- io.springfox:springfox-schema:jar:2.7.0:compile [INFO] | | +- io.springfox:springfox-swagger-common:jar:2.7.0:compile [INFO] | | +- io.springfox:springfox-spring-web:jar:2.7.0:compile [INFO] | | | \\- org.reflections:reflections:jar:0.9.11:compile [INFO] | | +- com.google.guava:guava:jar:18.0:compile [INFO] | | +- com.fasterxml:classmate:jar:1.4.0:compile [INFO] | | +- org.springframework.plugin:spring-plugin-core:jar:1.2.0.RELEASE:compile [INFO] | | +- org.springframework.plugin:spring-plugin-metadata:jar:1.2.0.RELEASE:compile [INFO] | | \\- org.mapstruct:mapstruct:jar:1.1.0.Final:compile [INFO] | +- io.springfox:springfox-swagger-ui:jar:2.7.0:compile [INFO] | +- org.springframework.boot:spring-boot-starter-log4j:jar:1.3.5.RELEASE:compile [INFO] | | +- org.slf4j:slf4j-log4j12:jar:1.7.26:compile [INFO] | | \\- log4j:log4j:jar:1.2.17:compile [INFO] | +- org.springframework.boot:spring-boot-starter-data-redis:jar:2.1.6.RELEASE:compile [INFO] | | +- org.springframework.data:spring-data-redis:jar:2.1.9.RELEASE:compile [INFO] | | | +- org.springframework.data:spring-data-keyvalue:jar:2.1.9.RELEASE:compile [INFO] | | | +- org.springframework:spring-oxm:jar:5.1.8.RELEASE:compile [INFO] | | | \\- org.springframework:spring-context-support:jar:5.1.8.RELEASE:compile [INFO] | | \\- io.lettuce:lettuce-core:jar:5.1.7.RELEASE:compile [INFO] | +- com.alibaba:fastjson:jar:1.2.44:compile [INFO] | +- org.apache.httpcomponents:httpclient:jar:4.4.1:compile [INFO] | | \\- org.apache.httpcomponents:httpcore:jar:4.4.11:compile [INFO] | +- com.google.code.gson:gson:jar:2.8.5:compile [INFO] | +- org.elasticsearch:elasticsearch:jar:6.4.3:compile [INFO] | | +- org.elasticsearch:elasticsearch-core:jar:6.4.3:compile [INFO] | | +- org.elasticsearch:elasticsearch-secure-sm:jar:6.4.3:compile [INFO] | | +- org.elasticsearch:elasticsearch-x-content:jar:6.4.3:compile [INFO] | | | +- com.fasterxml.jackson.dataformat:jackson-dataformat-smile:jar:2.9.9:compile [INFO] | | | \\- com.fasterxml.jackson.dataformat:jackson-dataformat-cbor:jar:2.9.9:compile [INFO] | | +- org.apache.lucene:lucene-core:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-analyzers-common:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-backward-codecs:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-grouping:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-highlighter:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-join:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-memory:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-misc:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-queries:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-queryparser:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-sandbox:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-spatial:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-spatial-extras:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-spatial3d:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-suggest:jar:7.4.0:compile [INFO] | | +- org.elasticsearch:elasticsearch-cli:jar:6.4.3:compile [INFO] | | | \\- net.sf.jopt-simple:jopt-simple:jar:5.0.2:compile [INFO] | | +- com.carrotsearch:hppc:jar:0.7.1:compile [INFO] | | +- joda-time:joda-time:jar:2.10.2:compile [INFO] | | +- com.tdunning:t-digest:jar:3.2:compile [INFO] | | +- org.hdrhistogram:HdrHistogram:jar:2.1.9:compile [INFO] | | +- org.apache.logging.log4j:log4j-api:jar:2.11.2:compile [INFO] | | \\- org.elasticsearch:jna:jar:4.5.1:compile [INFO] | +- org.elasticsearch.client:rest:jar:6.0.0-alpha1:compile [INFO] | | +- org.apache.httpcomponents:httpasyncclient:jar:4.1.4:compile [INFO] | | \\- org.apache.httpcomponents:httpcore-nio:jar:4.4.11:compile [INFO] | +- org.elasticsearch.client:elasticsearch-rest-high-level-client:jar:6.4.3:compile [INFO] | | +- org.elasticsearch.client:elasticsearch-rest-client:jar:6.4.3:compile [INFO] | | +- org.elasticsearch.plugin:parent-join-client:jar:6.4.3:compile [INFO] | | +- org.elasticsearch.plugin:aggs-matrix-stats-client:jar:6.4.3:compile [INFO] | | +- org.elasticsearch.plugin:rank-eval-client:jar:6.4.3:compile [INFO] | | \\- org.elasticsearch.plugin:lang-mustache-client:jar:6.4.3:compile [INFO] | | \\- com.github.spullara.mustache.java:compiler:jar:0.9.3:compile [INFO] | +- org.elasticsearch.client:transport:jar:6.4.3:compile [INFO] | | +- org.elasticsearch.plugin:reindex-client:jar:6.4.3:compile [INFO] | | \\- org.elasticsearch.plugin:percolator-client:jar:6.4.3:compile [INFO] | +- org.elasticsearch.plugin:transport-netty4-client:jar:6.4.3:compile [INFO] | | +- io.netty:netty-codec-http:jar:4.1.36.Final:compile [INFO] | | \\- io.netty:netty-resolver:jar:4.1.36.Final:compile [INFO] | +- org.ansj:ansj_seg:jar:5.1.1:compile [INFO] | | \\- org.nlpcn:nlp-lang:jar:1.7.2:compile [INFO] | +- org.apache.httpcomponents:httpmime:jar:4.5.6:compile [INFO] | +- org.jsoup:jsoup:jar:1.11.2:compile [INFO] | +- javax.servlet:javax.servlet-api:jar:4.0.1:compile [INFO] | \\- javax.persistence:javax.persistence-api:jar:2.2:compile [INFO] +- org.postgresql:postgresql:jar:42.2.2:compile [INFO] +- org.apache.shiro:shiro-core:jar:1.4.0:compile [INFO] | +- org.apache.shiro:shiro-lang:jar:1.4.0:compile [INFO] | +- org.apache.shiro:shiro-cache:jar:1.4.0:compile [INFO] | +- org.apache.shiro:shiro-crypto-hash:jar:1.4.0:compile [INFO] | | \\- org.apache.shiro:shiro-crypto-core:jar:1.4.0:compile [INFO] | +- org.apache.shiro:shiro-crypto-cipher:jar:1.4.0:compile [INFO] | +- org.apache.shiro:shiro-config-core:jar:1.4.0:compile [INFO] | +- org.apache.shiro:shiro-config-ogdl:jar:1.4.0:compile [INFO] | | \\- commons-beanutils:commons-beanutils:jar:1.9.3:compile [INFO] | \\- org.apache.shiro:shiro-event:jar:1.4.0:compile [INFO] +- org.apache.shiro:shiro-web:jar:1.4.0:compile [INFO] +- org.apache.shiro:shiro-spring:jar:1.4.0:compile [INFO] +- org.apache.shiro:shiro-ehcache:jar:1.4.0:compile [INFO] | \\- net.sf.ehcache:ehcache-core:jar:2.6.11:compile [INFO] +- org.springframework.boot:spring-boot-starter-amqp:jar:2.1.6.RELEASE:compile [INFO] | +- org.springframework:spring-messaging:jar:5.1.8.RELEASE:compile [INFO] | | \\- org.springframework:spring-beans:jar:5.1.8.RELEASE:compile [INFO] | \\- org.springframework.amqp:spring-rabbit:jar:2.1.7.RELEASE:compile [INFO] | +- org.springframework.amqp:spring-amqp:jar:2.1.7.RELEASE:compile [INFO] | | \\- org.springframework.retry:spring-retry:jar:1.2.4.RELEASE:compile [INFO] | +- com.rabbitmq:amqp-client:jar:5.4.3:compile [INFO] | \\- org.springframework:spring-tx:jar:5.1.8.RELEASE:compile [INFO] +- org.projectlombok:lombok:jar:1.16.10:compile [INFO] +- org.redisson:redisson:jar:3.11.2:compile [INFO] | +- io.netty:netty-common:jar:4.1.36.Final:compile [INFO] | +- io.netty:netty-codec:jar:4.1.36.Final:compile [INFO] | +- io.netty:netty-buffer:jar:4.1.36.Final:compile [INFO] | +- io.netty:netty-transport:jar:4.1.36.Final:compile [INFO] | +- io.netty:netty-resolver-dns:jar:4.1.36.Final:compile [INFO] | | \\- io.netty:netty-codec-dns:jar:4.1.36.Final:compile [INFO] | +- io.netty:netty-handler:jar:4.1.36.Final:compile [INFO] | +- javax.cache:cache-api:jar:1.1.1:compile [INFO] | +- io.projectreactor:reactor-core:jar:3.2.10.RELEASE:compile [INFO] | | \\- org.reactivestreams:reactive-streams:jar:1.0.2:compile [INFO] | +- io.reactivex.rxjava2:rxjava:jar:2.2.9:compile [INFO] | +- de.ruedigermoeller:fst:jar:2.57:compile [INFO] | | +- org.javassist:javassist:jar:3.21.0-GA:compile [INFO] | | \\- org.objenesis:objenesis:jar:2.5.1:compile [INFO] | +- com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.9.9:compile [INFO] | +- com.fasterxml.jackson.core:jackson-core:jar:2.9.9:compile [INFO] | +- com.fasterxml.jackson.core:jackson-databind:jar:2.9.9:compile [INFO] | | \\- com.fasterxml.jackson.core:jackson-annotations:jar:2.9.0:compile [INFO] | +- net.bytebuddy:byte-buddy:jar:1.9.13:compile [INFO] | \\- org.jodd:jodd-bean:jar:5.0.10:compile [INFO] | \\- org.jodd:jodd-core:jar:5.0.10:compile [INFO] +- org.redisson:redisson-spring-boot-starter:jar:3.11.2:compile [INFO] | +- org.springframework.boot:spring-boot-starter-actuator:jar:2.1.6.RELEASE:compile [INFO] | | +- org.springframework.boot:spring-boot-actuator-autoconfigure:jar:2.1.6.RELEASE:compile [INFO] | | | \\- org.springframework.boot:spring-boot-actuator:jar:2.1.6.RELEASE:compile [INFO] | | \\- io.micrometer:micrometer-core:jar:1.1.5:compile [INFO] | | \\- org.latencyutils:LatencyUtils:jar:2.0.3:compile [INFO] | \\- org.redisson:redisson-spring-data-21:jar:3.11.2:compile [INFO] +- org.apache.poi:poi:jar:4.0.0:compile [INFO] +- org.apache.poi:poi-ooxml:jar:4.0.0:compile [INFO] | +- org.apache.poi:poi-ooxml-schemas:jar:4.0.0:compile [INFO] | | \\- org.apache.xmlbeans:xmlbeans:jar:3.0.1:compile [INFO] | +- org.apache.commons:commons-compress:jar:1.18:compile [INFO] | \\- com.github.virtuald:curvesapi:jar:1.04:compile [INFO] +- com.xuxueli:xxl-job-core:jar:1.8.2:compile [INFO] | +- javax.servlet.jsp:jsp-api:jar:2.2:compile [INFO] | +- org.eclipse.jetty:jetty-server:jar:9.4.19.v20190610:compile [INFO] | | +- org.eclipse.jetty:jetty-http:jar:9.4.19.v20190610:compile [INFO] | | | \\- org.eclipse.jetty:jetty-util:jar:9.4.19.v20190610:compile [INFO] | | \\- org.eclipse.jetty:jetty-io:jar:9.4.19.v20190610:compile [INFO] | +- com.caucho:hessian:jar:4.0.38:compile [INFO] | +- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile [INFO] | | \\- org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile [INFO] | +- org.springframework:spring-context:jar:5.1.8.RELEASE:compile [INFO] | | +- org.springframework:spring-aop:jar:5.1.8.RELEASE:compile [INFO] | | \\- org.springframework:spring-expression:jar:5.1.8.RELEASE:compile [INFO] | +- org.codehaus.groovy:groovy-all:jar:2.4.5:compile [INFO] | \\- org.apache.commons:commons-exec:jar:1.3:compile [INFO] +- com.belerweb:pinyin4j:jar:2.5.0:compile [INFO] +- junit:junit:jar:4.12:test [INFO] | \\- org.hamcrest:hamcrest-core:jar:1.3:test [INFO] +- org.slf4j:slf4j-api:jar:1.7.26:compile [INFO] +- org.slf4j:jcl-over-slf4j:jar:1.7.26:compile [INFO] +- org.slf4j:jul-to-slf4j:jar:1.7.26:compile [INFO] +- org.springframework.boot:spring-boot-starter:jar:2.1.6.RELEASE:compile [INFO] | +- org.springframework.boot:spring-boot:jar:2.1.6.RELEASE:compile [INFO] | +- org.springframework.boot:spring-boot-starter-logging:jar:2.1.6.RELEASE:compile [INFO] | | +- ch.qos.logback:logback-classic:jar:1.2.3:compile [INFO] | | | \\- ch.qos.logback:logback-core:jar:1.2.3:compile [INFO] | | \\- org.apache.logging.log4j:log4j-to-slf4j:jar:2.11.2:compile [INFO] | +- javax.annotation:javax.annotation-api:jar:1.3.2:compile [INFO] | +- org.springframework:spring-core:jar:5.1.8.RELEASE:compile [INFO] | | \\- org.springframework:spring-jcl:jar:5.1.8.RELEASE:compile [INFO] | \\- org.yaml:snakeyaml:jar:1.23:compile [INFO] +- redis.clients:jedis:jar:3.0.1:compile [INFO] | \\- org.apache.commons:commons-pool2:jar:2.6.2:compile [INFO] +- com.baomidou:mybatis-plus-boot-starter:jar:3.1.2:compile [INFO] | \\- org.springframework.boot:spring-boot-starter-jdbc:jar:2.1.6.RELEASE:compile [INFO] | +- com.zaxxer:HikariCP:jar:3.2.0:compile [INFO] | \\- org.springframework:spring-jdbc:jar:5.1.8.RELEASE:compile [INFO] +- com.baomidou:mybatis-plus:jar:3.1.2:compile [INFO] +- com.baomidou:mybatis-plus-generator:jar:3.1.2:compile (optional) [INFO] +- com.alibaba:druid:jar:1.1.18:compile [INFO] +- com.alibaba:druid-spring-boot-starter:jar:1.1.18:compile [INFO] +- org.json:json:jar:20180130:compile [INFO] +- org.apache.oltu.oauth2:org.apache.oltu.oauth2.client:jar:0.31:compile [INFO] | +- org.apache.oltu.oauth2:org.apache.oltu.oauth2.common:jar:0.31:compile [INFO] | \\- org.codehaus.jettison:jettison:jar:1.2:compile [INFO] +- com.squareup.okhttp3:okhttp:jar:3.8.1:compile [INFO] | \\- com.squareup.okio:okio:jar:1.13.0:compile [INFO] +- org.apache.commons:commons-collections4:jar:4.4:compile [INFO] +- org.apache.commons:commons-vfs2:jar:2.1:compile [INFO] | \\- commons-logging:commons-logging:jar:1.2:compile [INFO] +- org.apache.commons:commons-lang3:jar:3.4:compile [INFO] +- commons-collections:commons-collections:jar:3.1:compile [INFO] +- commons-fileupload:commons-fileupload:jar:1.3.1:compile [INFO] | \\- commons-io:commons-io:jar:2.2:compile [INFO] +- com.baomidou:mybatis-plus-extension:jar:3.1.2:compile [INFO] | +- com.baomidou:mybatis-plus-core:jar:3.1.2:compile [INFO] | | +- com.baomidou:mybatis-plus-annotation:jar:3.1.2:compile [INFO] | | +- com.github.jsqlparser:jsqlparser:jar:1.2:compile [INFO] | | \\- org.mybatis:mybatis:jar:3.5.1:compile [INFO] | \\- org.mybatis:mybatis-spring:jar:2.0.1:compile [INFO] +- com.baomidou:dynamic-datasource-spring-boot-starter:jar:2.5.5:compile [INFO] | \\- org.springframework.boot:spring-boot-starter-aop:jar:2.1.6.RELEASE:compile [INFO] | \\- org.aspectj:aspectjweaver:jar:1.9.4:compile [INFO] \\- org.springframework.boot:spring-boot-starter-test:jar:2.1.6.RELEASE:test [INFO] +- org.springframework.boot:spring-boot-test:jar:2.1.6.RELEASE:test [INFO] +- org.springframework.boot:spring-boot-test-autoconfigure:jar:2.1.6.RELEASE:test [INFO] +- com.jayway.jsonpath:json-path:jar:2.4.0:test [INFO] | \\- net.minidev:json-smart:jar:2.3:test [INFO] | \\- net.minidev:accessors-smart:jar:1.2:test [INFO] | \\- org.ow2.asm:asm:jar:5.0.4:test [INFO] +- org.assertj:assertj-core:jar:3.11.1:test [INFO] +- org.mockito:mockito-core:jar:2.23.4:test [INFO] | \\- net.bytebuddy:byte-buddy-agent:jar:1.9.13:test [INFO] +- org.hamcrest:hamcrest-library:jar:1.3:test [INFO] +- org.skyscreamer:jsonassert:jar:1.5.0:test [INFO] | \\- com.vaadin.external.google:android-json:jar:0.0.20131108.vaadin1:test [INFO] +- org.springframework:spring-test:jar:5.1.8.RELEASE:test [INFO] \\- org.xmlunit:xmlunit-core:jar:2.6.2:test [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 3.200 s [INFO] Finished at: 2019-10-11T16:00:25+08:00 [INFO] Final Memory: 43M/449M [INFO] ------------------------------------------------------------------------ D:\\2\\lqx-project-demo\\basic-server (v2.0.3) λ "},"各种问题/springboot/springboot配置属性DataSource问题.html":{"url":"各种问题/springboot/springboot配置属性DataSource问题.html","title":"springboot配置属性DataSource问题","keywords":"","body":" 今天发现服务器内存彪升，如下： 查找日志发现报错： Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is com.alibaba.druid.pool.GetConnectionTimeoutException: wait millis 7217, active 8, maxActive 8, creating 0, runningSqlCount 2 分析日志应该是线程数不够，默认是8，重新设置为30，如下： spring.datasource.max-active=30 另外常见DataSource配置如下： spring.dao.exceptiontranslation.enabled是否开启PersistenceExceptionTranslationPostProcessor，默认为true spring.datasource.abandon-when-percentage-full设定超时被废弃的连接占到多少比例时要被关闭或上报 spring.datasource.allow-pool-suspension使用Hikari pool时，是否允许连接池暂停，默认为: false spring.datasource.alternate-username-allowed是否允许替代的用户名. spring.datasource.auto-commit指定updates是否自动提交. spring.datasource.catalog指定默认的catalog. spring.datasource.commit-on-return设置当连接被归还时，是否要提交所有还未完成的事务 spring.datasource.connection-init-sql指定连接被创建，再被添加到连接池之前执行的sql. spring.datasource.connection-init-sqls使用DBCP connection pool时，指定初始化时要执行的sql spring.datasource.connection-properties.[key]在使用DBCP connection pool时指定要配置的属性 spring.datasource.connection-test-query指定校验连接合法性执行的sql语句 spring.datasource.connection-timeout指定连接的超时时间，毫秒单位. spring.datasource.continue-on-error在初始化数据库时，遇到错误是否继续，默认false spring.datasource.data指定Data (DML)脚本 spring.datasource.data-source-class-name指定数据源的全限定名. spring.datasource.data-source-jndi指定jndi的地址 spring.datasource.data-source-properties.[key]使用Hikari connection pool时，指定要设置的属性 spring.datasource.db-properties使用Tomcat connection pool，指定要设置的属性 spring.datasource.default-auto-commit是否自动提交. spring.datasource.default-catalog指定连接默认的catalog. spring.datasource.default-read-only是否设置默认连接只读. spring.datasource.default-transaction-isolation指定连接的事务的默认隔离级别. spring.datasource.driver-class-name指定driver的类名，默认从jdbc url中自动探测. spring.datasource.fair-queue是否采用FIFO返回连接. spring.datasource.health-check-properties.[key]使用Hikari connection pool时，在心跳检查时传递的属性 spring.datasource.idle-timeout指定连接多久没被使用时，被设置为空闲，默认为10ms spring.datasource.ignore-exception-on-pre-load当初始化连接池时，是否忽略异常. spring.datasource.init-sql当连接创建时，执行的sql spring.datasource.initial-size指定启动连接池时，初始建立的连接数量 spring.datasource.initialization-fail-fast当创建连接池时，没法创建指定最小连接数量是否抛异常 spring.datasource.initialize指定初始化数据源，是否用data.sql来初始化，默认: true spring.datasource.isolate-internal-queries指定内部查询是否要被隔离，默认为false spring.datasource.jdbc-interceptors使用Tomcat connection pool时，指定jdbc拦截器，分号分隔 spring.datasource.jdbc-url指定JDBC URL. spring.datasource.jmx-enabled是否开启JMX，默认为: false spring.datasource.jndi-name指定jndi的名称. spring.datasource.leak-detection-threshold使用Hikari connection pool时，多少毫秒检测一次连接泄露. spring.datasource.log-abandoned使用DBCP connection pool，是否追踪废弃statement或连接，默认为: false spring.datasource.log-validation-errors当使用Tomcat connection pool是否打印校验错误. spring.datasource.login-timeout指定连接数据库的超时时间. spring.datasource.max-active指定连接池中最大的活跃连接数. spring.datasource.max-age指定连接池中连接的最大年龄 spring.datasource.max-idle指定连接池最大的空闲连接数量. spring.datasource.max-lifetime指定连接池中连接的最大生存时间，毫秒单位. spring.datasource.max-open-prepared-statements指定最大的打开的prepared statements数量. spring.datasource.max-wait指定连接池等待连接返回的最大等待时间，毫秒单位. spring.datasource.maximum-pool-size指定连接池最大的连接数，包括使用中的和空闲的连接. spring.datasource.min-evictable-idle-time-millis指定一个空闲连接最少空闲多久后可被清除. spring.datasource.min-idle指定必须保持连接的最小值(For DBCP and Tomcat connection pools) spring.datasource.minimum-idle指定连接维护的最小空闲连接数，当使用HikariCP时指定. spring.datasource.name指定数据源名. spring.datasource.num-tests-per-eviction-run指定运行每个idle object evictor线程时的对象数量 spring.datasource.password指定数据库密码. spring.datasource.platform指定schema要使用的Platform(schema-${platform}.sql)，默认为: all spring.datasource.pool-name指定连接池名字. spring.datasource.pool-prepared-statements指定是否池化statements. spring.datasource.propagate-interrupt-state在等待连接时，如果线程被中断，是否传播中断状态. spring.datasource.read-only当使用Hikari connection pool时，是否标记数据源只读 spring.datasource.register-mbeans指定Hikari connection pool是否注册JMX MBeans. spring.datasource.remove-abandoned指定当连接超过废弃超时时间时，是否立刻删除该连接. spring.datasource.remove-abandoned-timeout指定连接应该被废弃的时间. spring.datasource.rollback-on-return在归还连接时，是否回滚等待中的事务. spring.datasource.schema指定Schema (DDL)脚本. spring.datasource.separator指定初始化脚本的语句分隔符，默认: ; spring.datasource.sql-script-encoding指定SQL scripts编码. spring.datasource.suspect-timeout指定打印废弃连接前的超时时间. spring.datasource.test-on-borrow当从连接池借用连接时，是否测试该连接. spring.datasource.test-on-connect创建时，是否测试连接 spring.datasource.test-on-return在连接归还到连接池时是否测试该连接. spring.datasource.test-while-idle当连接空闲时，是否执行连接测试. spring.datasource.time-between-eviction-runs-millis指定空闲连接检查、废弃连接清理、空闲连接池大小调整之间的操作时间间隔 spring.datasource.transaction-isolation指定事务隔离级别，使用Hikari connection pool时指定 spring.datasource.url指定JDBC URL. spring.datasource.use-disposable-connection-facade是否对连接进行包装，防止连接关闭之后被使用. spring.datasource.use-equals比较方法名时是否使用String.equals()替换==. spring.datasource.use-lock是否对连接操作加锁 spring.datasource.username指定数据库名. spring.datasource.validation-interval指定多少ms执行一次连接校验. spring.datasource.validation-query指定获取连接时连接校验的sql查询语句. spring.datasource.validation-query-timeout指定连接校验查询的超时时间. spring.datasource.validation-timeout设定连接校验的超时时间，当使用Hikari connection pool时指定 spring.datasource.validator-class-name用来测试查询的validator全限定名. spring.datasource.xa.data-source-class-name指定数据源的全限定名. spring.datasource.xa.properties指定传递给XA data source的属性 "},"各种问题/前端/form表单序列化后中文乱码问题.html":{"url":"各种问题/前端/form表单序列化后中文乱码问题.html","title":"form表单序列化后中文乱码问题","keywords":"","body":" 1、jquery form表单序列化后中文乱码问题解决代码实现 前台： var params =$('#addForm').serialize(); params = encodeURI(encodeURI(decodeURIComponent(params,true))); $.ajax({ type: \"post\", url: \"sptSUPPSupplierBankController.cmd?method=persisit\", data: params, success: function(data) { if(data=='1'){ alert(\"保存成功\"); }else{ alert(\"保存失败！\"); } } }); jquery form表单.serialize()序列化后中文乱码问题原因及解决 原因： .serialize()自动调用了encodeURIComponent方法将数据编码了 解决方法：调用decodeURIComponent(XXX,true);将数据解码 例如： var params = $(\"#formId\").serialize(); params = decodeURIComponent(params,true); 在进行编码 params = encodeURI(encodeURI(params)); 后台 params = java.net.URLDecoder.decode(params , \"UTF-8\"); 问题解决。 参考： https://blog.csdn.net/fzy629442466/article/details/84786049?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf https://blog.csdn.net/w1014074794/article/details/43987689 2、 3、 ``` "},"各种问题/单元测试/单元测试获取不到数据库连接问题.html":{"url":"各种问题/单元测试/单元测试获取不到数据库连接问题.html","title":"单元测试获取不到数据库连接问题","keywords":"","body":" 问题 在单元测试时，运行的单元测试里有发送mq消息的，然后有个监听器类接收消息的， 然后在测试接收消息时，跑着跑着发现报下面的错，是获取不到连接的问题，后来看了好久，想应该是发送消息的那个 主程序关闭了导致的 ### Error querying database. Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is java.sql.SQLException: HikariDataSource HikariDataSource (HikariPool-1) has been closed. ### The error may exist in file [D:\\idea-workspace4\\iotcard\\flow-sync-service\\target\\classes\\mapper\\FlowSyncCardMonitorHistoryMapper.xml] ### The error may involve com.fzs.iotcard.flowsync.mapper.FlowSyncCardMonitorHistoryMapper.queryYesterdayUpdated ### The error occurred while executing a query ### Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is java.sql.SQLException: HikariDataSource HikariDataSource (HikariPool-1) has been closed. 解决 在运行的单元测试里加上休眠，不要让发送消息的线程太快结束即可 //这里加上休眠，防止mq哪里消费入库还没跑完，这里主线程结束了，导致获取不到数据库连接 Thread.sleep(120000); "},"各种问题/定时任务/xxl-job打印日志问题.html":{"url":"各种问题/定时任务/xxl-job打印日志问题.html","title":"xxl-job打印日志问题","keywords":"","body":" 注意不能像下面那样写,不能有{}或者,这些或者，应该直接用+拼起来， XxlJobLogger.log(\"shopid:{},skus:{}\", shopid, skus); 否则会报类似下面的错： ----------- JobThread Exception:java.lang.IllegalArgumentException: can't parse argument number: at java.text.MessageFormat.makeFormat(MessageFormat.java:1429) at java.text.MessageFormat.applyPattern(MessageFormat.java:479) at java.text.MessageFormat.(MessageFormat.java:362) at java.text.MessageFormat.format(MessageFormat.java:840) at com.xxl.job.core.log.XxlJobLogger.log(XxlJobLogger.java:58) at com.tobe.sp.AmazonTask.xxljob.AmazonOrderDisposeSyncHandler.execute(AmazonOrderDisposeSyncHandler.java:40) at com.xxl.job.core.thread.JobThread.run(JobThread.java:119) Caused by: java.lang.NumberFormatException: For input string: \"\" at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) at java.lang.Integer.parseInt(Integer.java:592) at java.lang.Integer.parseInt(Integer.java:615) at java.text.MessageFormat.makeFormat(MessageFormat.java:1427) ... 6 more ----------- xxl-job job execute end(error) ----------- 正确写法： XxlJobLogger.log(\"arg0：\" + arg0); "},"各种问题/配置/redisTemplate配置问题.html":{"url":"各种问题/配置/redisTemplate配置问题.html","title":"redisTemplate配置问题","keywords":"","body":"title: redisTemplate配置问题 tags: [] date: 2020-12-23 21:48:59 categories: 问题：配置RedisTemplate,启动报错 看下面自定义配置的RedisTemplate，用了LettuceConnectionFactory(是RedisConnectionFactory的子类) /** * redisTemplate 默认序列化使用的 jdkSerializeable, 存储二进制字节码, 所以一般需要自定义序列化类 * https://www.cnblogs.com/puzhiwei/p/12519304.html * @return */ @Bean public RedisTemplate redisTemplateSerializer(LettuceConnectionFactory lettuceConnectionFactory) { // 设置序列化 Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper objectMapper = new ObjectMapper(); // 指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和public objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer等会跑出异常 objectMapper.activateDefaultTyping(LaissezFaireSubTypeValidator.instance, ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); RedisSerializer stringSerializer = new StringRedisSerializer(); // 配置redisTemplate RedisTemplate redisTemplate = new RedisTemplate(); redisTemplate.setConnectionFactory(lettuceConnectionFactory); // key序列化 redisTemplate.setKeySerializer(stringSerializer); // value序列化 redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); // Hash key序列化 redisTemplate.setHashKeySerializer(stringSerializer); // Hash value序列化 redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; } 报错日志： Parameter 0 of method redisTemplateSerializer in com.basic.config.RedisTemplateConfig required a bean of type 'org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory' that could not be found. The following candidates were found but could not be injected: - Bean method 'redisConnectionFactory' in 'LettuceConnectionConfiguration' not loaded because @ConditionalOnMissingBean (types: org.springframework.data.redis.connection.RedisConnectionFactory; SearchStrategy: all) found beans of type 'org.springframework.data.redis.connection.RedisConnectionFactory' redissonConnectionFactory Action: Consider revisiting the entries above or defining a bean of type 'org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory' in your configuration. 原因分析： 看spring-boot-autoconfigure包下的RedisAutoConfiguration org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration 其中用Import注解引入了LettuceConnectionConfiguration @Configuration( proxyBeanMethods = false ) @ConditionalOnClass({RedisOperations.class}) @EnableConfigurationProperties({RedisProperties.class}) @Import({LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class}) public class RedisAutoConfiguration { public RedisAutoConfiguration() { } @Bean @ConditionalOnMissingBean( name = {\"redisTemplate\"} ) public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { RedisTemplate template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } } 继续看LettuceConnectionConfiguration类 可以看到当缺失RedisConnectionFactory时，就会默认创建一个名称为redisConnectionFactory的bean，类型为LettuceConnectionFactory也就是这里会创建一个redisConnectionFactory @Bean @ConditionalOnMissingBean({RedisConnectionFactory.class}) LettuceConnectionFactory redisConnectionFactory(ObjectProvider builderCustomizers, ClientResources clientResources) throws UnknownHostException { LettuceClientConfiguration clientConfig = this.getLettuceClientConfiguration(builderCustomizers, clientResources, this.getProperties().getLettuce().getPool()); return this.createLettuceConnectionFactory(clientConfig); } 而上面配置用RedisTemplate时注入LettuceConnectionFactory类报错是因为同时使用了redisson,而redisson的自动装配也创建了redisConnectionFactory 看redisson-spring-boot-starter下的RedissonAutoConfiguration org.redisson.spring.starter.RedissonAutoConfiguration 下面也会创建redissonConnectionFactory、RedisTemplate等，同时RedissonAutoConfiguration用了AutoConfigureBefore，会比RedisAutoConfiguration先装配 @Configuration @ConditionalOnClass({Redisson.class, RedisOperations.class}) @AutoConfigureBefore({RedisAutoConfiguration.class}) @EnableConfigurationProperties({RedissonProperties.class, RedisProperties.class}) public class RedissonAutoConfiguration { @Autowired private RedissonProperties redissonProperties; @Autowired private RedisProperties redisProperties; @Autowired private ApplicationContext ctx; public RedissonAutoConfiguration() { } @Bean @ConditionalOnMissingBean( name = {\"redisTemplate\"} ) public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean({StringRedisTemplate.class}) public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean({RedisConnectionFactory.class}) public RedissonConnectionFactory redissonConnectionFactory(RedissonClient redisson) { return new RedissonConnectionFactory(redisson); } 解决 配置RedisTemplate，不要用LettuceConnectionFactory注入，直接用RedisConnectionFactory就可以 public RedisTemplate redisTemplateSerializer(RedisConnectionFactory redisConnectionFactory) { "},"开发工具/excel/excel拼接字符串.html":{"url":"开发工具/excel/excel拼接字符串.html","title":"excel拼接字符串","keywords":"","body":" 1.前言 开发过程难免与数据打交道，业务人员有时会以excel表格提供数据给开发人员，所以掌握excel一些基本的技巧也很重要很有帮助 2.需求 如下图,将excel表格里的数据插入或者更新数据库，方法有很多 将excel转换为csv文件，然后用awk\\cat基本命令处理 利用excel直接拼接 3.实战 1.定义拼接的字符串函数如下： =\"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'\"&A3&\"','\"&B3&\"','\"&C3&\"','\"&D3&\"','\"&E3&\"','\"&F3&\"','\"&G3&\"','\"&H3&\"','\"&J3&\"','\"&K3&\"','\"&L3&\"');\" 2.点击excel的M3单元格，将上面内容复制到工具栏的fx函数处，如下： 3.然后焦点回到M3单元格，点击回车，即可拼接了字符串 4.再次点击M3单元格，鼠标移动到该单元格右下角，鼠标变成十字后,按住ctrl键,往下拉,松手即可 5.然后复制M列出来即可，内容如下，把前后的双引号去掉即可 \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'MOROCCO','MA','wonderful_sea-MA','0.2','1','0.1','0','0.05','10','DHS','2');\" \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'EGYPT','EG','wonderful_sea-EG','0.25','1','0.1','0','0.05','19','EGP','0');\" \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'KENYA','KE','wonderful_sea-KE','0.2','1','0.1','0','0.05','105','KSH','0');\" \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'KENYA','KE','SMARTEST-KE','0.2','1','0.1','0','0.05','105','KSH','0');\" \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'KENYA','KE','NICEST store-KE','0.2','1','0.1','0','0.05','105','KSH','0');\" \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'NIGERIA','NG','Celmia official store-NG','0.2','1','0.1','0','0.05','370','NGN','0');\" \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'NIGERIA','NG','INCERUN official store-NG','0.2','1','0.1','0','0.05','370','NGN','0');\" 4.函数分析 结果是需要下面的，对比开始的那个函数，也就是'\"&A3&\"'这地方不同的地方是单引号里面的东西\"&A3&\"，所以用这个替换单引号里的值，再前后加上双引号即可 INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'NIGERIA','NG','INCERUN official store-NG','0.2','1','0.1','0','0.05','370','NGN','0'); 另外更新的可以如下： =\"UPDATE sp_common.shop SET access_token='\"&D2&\"',site_url='\"&C2&\"',shop_mail='\"&A2&\"',site_id='CM',site_name='CAMEROO' WHERE shop_name='\"&B2&\"';\" "},"开发工具/git/git打tag.html":{"url":"开发工具/git/git打tag.html","title":"git打tag","keywords":"","body":" 1、 2、 3、 ``` "},"开发工具/git/git提交注释规范.html":{"url":"开发工具/git/git提交注释规范.html","title":"git提交注释规范","keywords":"","body":" 1、git commit 时报错 remote: commit message: 增加gitnore文件和启动项目要配置的说明 remote: 你提交的commit注释格式有问题，请按格式提交. remote: (): remote: Example: remote: docs(phoneapi.java): 新添加phone接口 remote: or Merge/merge 提交 type 用于说明 commit 的类别，只允许使用下面7个标识。 2、 3、 ``` "},"开发工具/git/git新建项目常见操作.html":{"url":"开发工具/git/git新建项目常见操作.html","title":"git新建项目常见操作","keywords":"","body":" 1、新建项目流程 初始化 git init 添加文件 git add . 提交 git commit -am 'init' 关联远程git git remote add origin git@github.com:xxx.git 关联远程分支 git branch --set-upstream-to=origin/master master 拉取代码（若远程有代码了） git pull 拉取代码(有历史记录，拉取不了则用下面的) git pull origin master --allow-unrelated-histories 推送 git push 推送到远程 git push -u origin master 2、打标签和发release版本 、 3、 ``` "},"开发工具/idea/idea-git操作.html":{"url":"开发工具/idea/idea-git操作.html","title":"idea-git操作","keywords":"","body":" 1、idea中对git版本回滚 1、项目或文件夹右键-> git-> show history-> Copy Revision Number（复制想要的版本号） 2、项目或文件夹右键-> git-> Repository -> Reset HEAD 参考： https://blog.csdn.net/weixin_40836179/article/details/87006285 2、 3、 "},"开发工具/idea/idea中文乱码.html":{"url":"开发工具/idea/idea中文乱码.html","title":"idea中文乱码","keywords":"","body":" https://blog.csdn.net/weixin_43912972/article/details/104098821 1、 2、 3、 "},"开发工具/idea/idea快捷键.html":{"url":"开发工具/idea/idea快捷键.html","title":"idea快捷键","keywords":"","body":" 常见快捷键 文件 重名文件名(重命名变量)： shift+F6 新建文件: alt+insert （注意要先选择文件夹） 搜索 搜索类: ctrl+n 搜索文件: ctrl+shift+n 全局搜索: ctrl+shift+f （注意在搜狗输入法下才行，在其他输入法可能有影响） 调试 debug调试： shift+F9 停止调试: ctrl+F2 修改js或jsp后更新: ctrl+F10 打开窗口 打开services日志窗口： alt+8 打开terminal窗口： alt+F12 打开左边窗口： alt+1 代码窗口 重新方法(或实现): ctrl+o 生成get/set/构造方法:　alt+insert 跳到实现: ctrl+b 关掉编辑窗口： ctrl+F4 设置 打开idea设置：ctrl+alt+s 打开项目设置：ctrl+shift+alt+s 关掉idea: alt+F4 git提交 commit提交: ctrl+k push提交: ctrl+alt+k 类图 生成类图，显示Diagrams： CTRL+ALT+SHIFT+U 或 ctrl+alt+u IDEA编写快捷生成代码 idea 快速打出for循环 "},"开发工具/idea/idea插件.html":{"url":"开发工具/idea/idea插件.html","title":"idea插件","keywords":"","body":" 快速通过mapper跳转到xml文件 free-idea-mybatis 官网：https://github.com/wuzhizhan/free-idea-mybatis 点击快速查看调用处和被调用处，快速切换 mybatis-lite 注意： 此功能默认打开(可能会与Mybatis Plugin / free mybatis plugin等插件冲突)，需要关闭的同学，请在IDEA->File菜单->Setting菜单->Other Setting菜单->Mybatis菜单->导航开关 关闭 使用方法：如下图，按住ctrl健，点击方法名，会显示跳转到xml文件还是impl实训类，自己选择 官网：https://github.com/mustfun/mybatis-lite 常用插件 Grep console 自定义日志颜色，idea控制台可以彩色显示各种级别的log，安装完成后，在console中右键就能打开。 settings->other setting MyBatis Log Plugin 直接将Mybatis执行的sql脚本显示出来，无需处理，可以直接复制出来执行的 Tools -- > Mybatis Log Plugin 打开其日志框，注意其转换的SQL不是输出到IDE的控制台!!! String Manipulation 强大的字符串转换工具。使用快捷键，Alt+m。 或者点击右键 CodeGlance CodeGlance是一款代码编辑区缩略图插件，可以快速定位代码，使用起来比拖动滚动条方便多了 Maven Helper 分析依赖冲突插件 打开项目中的pom文件，在底部会显示一个“Dependency Analyzer”, Rainbow Brackets 彩虹颜色的括号 在黑色主题下看的比较清楚舒服，白色主题下看的很不明显，看自己选择了，除了看着舒服，也有助于 帮助区分前后括号对应关系。 GenerateAllSetter 一键调用一个对象的所有set方法并且赋予默认值 在对象字段多的时候非常方便，在做项目时，每层都有各自的实体对象需要相互转换，但是考虑BeanUtil.copyProperties()等这些工具的弊端，有些地方就需要手动的赋值时，有这个插件就会很方便，创建完对象后在变量名上面按Alt+Enter就会出来 generate all setter选项。 https://github.com/gejun123456/intellij-generateAllSetMethod https://blog.csdn.net/qq_38225558/article/details/88388841 注意：若alter+enter没出现菜单，则看看对象里面有没set方法，必须有set方法才能出现菜单 看：https://github.com/gejun123456/intellij-generateAllSetMethod/issues/32 Lombok 代码注解插件 Key promoter X 快捷键提示工具 https://github.com/halirutan/IntelliJ-Key-Promoter-X GsonFormat jsonFormat JSON转领域对象工具 Restfultookit 一套 RESTful 服务开发辅助工具集。 1.根据 URL 直接跳转到对应的方法定义 ( or Ctrl Alt N ); 2.提供了一个 Services tree 的显示窗口; 3.一个简单的 http 请求工具; 4.在请求方法上添加了有用功能: 复制生成 URL;,复制方法参数... 5.其他功能: java 类上添加 Convert to JSON 功能，格式化 json 数据 ( Windows: Ctrl + Enter; Mac: Command + Enter )。 CamelCase 将不是驼峰格式的名称，快速转成驼峰格式，安装好后，选中要修改的名称，按快捷键shift+alt+u。 Mybatis plugin 可以在mapper接口中和mapper的xml文件中来回跳转，就想接口跳到实现类那样简单。 Translation 中英文翻译工具 CodeMaker 代码生成工具 https://github.com/x-hansong/CodeMaker Iedis Redis可视化 Alibaba Java Coding Guidelines K8s工具：Kubernetes SonarLint FindBugs-IDEA CheckStyle-IDEA mybatis-generator https://gitee.com/rohou/mybatis-generator 阿里java规范 https://github.com/alibaba/p3c/blob/master/idea-plugin/README_cn.md "},"开发工具/idea/ieda快捷生成代码.html":{"url":"开发工具/idea/ieda快捷生成代码.html","title":"ieda快捷生成代码","keywords":"","body":" 1. psvm //生成main方法: public static void main(String[] args) {} 2. sout //生成打印输出: System.out.println(); 3. \"abc\".sout //生成打印字符串: System.out.println(\"adc\"); 4. \"abc\".format //生成字符串格式化: String.format(\"abc\", ) //如List或者Array: List list = new ArrayList<>(); 5. itli //生成for循环 for (int i = 0; i 6. itco // 生成Collection迭代器 for (Iterator iterator = list.iterator(); iterator.hasNext(); ) { String next = iterator.next(); } 7. iter ///生成增强for循环 for (String s : list) { } 8.iten ///生成 enumeration遍历 while (enumeration.hasMoreElements()) { Object nextElement = enumeration.nextElement(); } 9. itar ///生成数组for循环 int[] array = {1,2,3,4,5}; for (int i = 0; i 10. itit ///生成迭代器 iterator Iterator iterator = list.iterator(); while (iterator.hasNext()) { Object next = iterator.next(); } 11. ittok //ittok 生成String token遍历 for (StringTokenizer stringTokenizer = new StringTokenizer(APP_NAME); stringTokenizer.hasMoreTokens(); ) { String s = stringTokenizer.nextToken(); } 12. itws //生成Axis2 web service调用 try { MyServiceLocator locator = new MyServiceLocator(); Activator service = locator.get(); // If authorization is required //((MyService_Soap_BindingStub)service).setUsername(\"user3\"); //((MyService_Soap_BindingStub)service).setPassword(\"pass3\"); // invoke business method service.businessMethod(); } catch (javax.xml.rpc.ServiceException ex) { ex.printStackTrace(); } catch (java.rmi.RemoteException ex) { ex.printStackTrace(); } 13 .try 如:\"abc\".try //生成try.....catch try { \"abc\" } catch (Exception e) { e.printStackTrace(); } 14. ifn //生成判断是否为空 if (list == null) { } 15. inn ///生成判断是否不为空 if (list != null) { } 16. fori //生成简单for循环 for (int i = 0; i 17. inst //生成是否是该对象引用 if (list instanceof Object) { Object o = (Object) list; } 18.psf ///生成 共有 静态最终的 public static final 19. psfi ///生成 共有 静态最终的 int public static final int 20.psfs ///生成 共有 静态最终的 String public static final String "},"开发工具/模板引擎/freemarker模板语法.html":{"url":"开发工具/模板引擎/freemarker模板语法.html","title":"freemarker模板语法","keywords":"","body":" 列表 import ${pkg}; 条件if import io.swagger.annotations.ApiModel; import io.swagger.annotations.ApiModelProperty; 判断不为空K 加上??两个问号 ``` "},"开发工具/常见工具.html":{"url":"开发工具/常见工具.html","title":"常见工具","keywords":"","body":" 1、json在线格式化 http://jsoneditoronline.org/ 2、xml和json格式化 http://www.bejson.com/ 3、各种编码和格式化工具 https://1024tools.com/hmac 4、将propertyies转yml https://www.toyaml.com/index.html 5、google浏览器手势插件访问地址 chrome-extension://jlgkpaicikihijadgifklkbpdajbkhjo/options.html 6、jemeter jemter字体优化 7、xml在线格式化 xml在线格式化 "},"数据库/mysql/mysql版本升级.html":{"url":"数据库/mysql/mysql版本升级.html","title":"mysql版本升级","keywords":"","body":" 将mysql版本从5.6升级到5.7 window下mysql版本从5.6升级5.7 1、下载 下载地址：https://dev.mysql.com/downloads/mysql/ 最新的mysql5.7的压缩包解压开你会发现，没有data目录和my.ini文件，跟之前的版本不一样 我下载的是mysql-5.7.31-winx64.zip 2、查看原来运行的mysql5.6 控制面板-管理工具-服务 搜索mysql，并且点击属性，查看可执行文件路径，看到如下 ```shell script \"D:\\Program Files\\MySQL\\MySQL Server 5.6\\bin\\mysqld\" --defaults-file=\"D:\\Program Files\\myqldata\\my.ini\" MySQL56 可以看到启动的mysql进程为myqld，这个在任务管理器哪里也可以看到，可以在任务管理器或者服务里关掉mysql进程 同时可以看到使用的配置文件是D:\\Program Files\\myqldata\\my.ini，这个就是之前安装mysql5.6时指定的配置文件 打开这个文件对应的目录D:\\Program Files\\myqldata就看到有个data，这个就是存放数据的的目录 #### 3、关闭mysql 服务-右键停止启动mysql56 使用cmd窗口，进入到mysql目录下面，将mysql服务移除（注意用管理员身份运行） ```shell script D:\\Program Files\\MySQL\\MySQL Server 5.6\\bin λ mysqld.exe --remove mysql56 Service successfully removed. 再次搜索服务，发现没有mysql56这个服务了 4、修改my.ini文件 主要是修改basedir改为上面下载的mysql5.7解压的目录，如下： ```shell script basedir=\"D:\\Program Files\\mysql-5.7.31-winx64\\\" #### 5、将mysql5.7的服务添加到win的服务队列中，并且启动mysql服务。 cd 到D:\\Program Files\\mysql-5.7.31-winx64\\bin，执行下面的，如下： ```shell script mysqld.exe --install MySQL57 --defaults-file=\"D:\\Program Files\\myqldata\\my.ini\" Service successfully installed. 其中MySQL57是指安装的服务，--defaults-file指向my.ini配置文件再次看服务，刷新就看到mysql57的服务 6、启动mysql服务 ```shell script net start mysql57 (1)然后报下面的错 ```shell script D:\\Program Files\\mysql-5.7.31-winx64\\bin λ net start mysql57 MySQL57 服务正在启动 .. MySQL57 服务无法启动。 服务没有报告任何错误。 请键入 NET HELPMSG 3534 以获得更多的帮助。 将mysql5.7安装目录添加到path环境变量也不行 (2)解决办法： 直接干掉my.ini文件里的内容，将下面的内容复制进去 ```shell script [mysqld] 设置mysql的安装目录[根据本地情况进行修改] basedir=\"D:\\Program Files\\mysql-5.7.31-winx64\" 设置mysql数据库的数据的存放目录[根据本地情况进行修改] datadir=\"D:\\Program Files\\myqldata\\data\" 设置3306端口 port = 3306 允许最大连接数 max_connections=200 服务端使用的字符集默认为8比特编码的latin1字符集 character-set-server=utf8 创建新表时将使用的默认存储引擎 default-storage-engine=INNODB sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES [mysql] 设置mysql客户端默认字符集 default-character-set=utf8 原因：mysql5.7的my.ini和mysql5.6的有些不一样 (3)cd 到D:\\Program Files\\mysql-5.7.31-winx64目录下 若有data文件夹，则删掉，然后执行下面的 ```shell script mysqld.exe　--initialize 不行就执行下面的的 ```shell script mysqld.exe --initialize-insecure 这个命令会在安装目录下产生data文件夹，对个人在D:\\Program Files\\myqldata目录下建的data文件夹(my.ini指定的datadir)没影响的 (4)重新执行net start mysql57命令 经过上面步骤，这个就可以启动了 #### 7、升级mysql：mysql_upgrade -uroot -p ```shell script mysql_upgrade -uroot -proot 升级速度具体看data目录的大小情况而定。 必须升级，要不原来mysql5.6中的数据库，在navicate中连接报错 8、升级成功后，再次重启mysql5.7服务 ```shell script D:\\Program Files\\mysql-5.7.31-winx64\\bin λ net stop mysql57 MySQL57 服务正在停止. MySQL57 服务已成功停止。 D:\\Program Files\\mysql-5.7.31-winx64\\bin λ net start mysql57 MySQL57 服务正在启动 . MySQL57 服务已经启动成功。 启动完就可以了 #### 9、查看mysql版本 登录 ```shell script mysql -uroot -proot 输入select version(); ```shell script mysql> select version(); +-----------+ | version() | +-----------+ | 5.7.31 | +-----------+ 1 row in set (0.00 sec) 或者status ```shell script mysql> status -------------- mysql Ver 14.14 Distrib 5.7.31, for Win64 (x86_64) Connection id: 5 Current database: Current user: root@localhost SSL: Cipher in use is ECDHE-RSA-AES128-GCM-SHA256 Using delimiter: ; Server version: 5.7.31 MySQL Community Server (GPL) Protocol version: 10 Connection: localhost via TCP/IP Server characterset: utf8 Db characterset: utf8 Client characterset: gbk Conn. characterset: gbk TCP port: 3306 Uptime: 4 min 5 sec Threads: 3 Questions: 40 Slow queries: 0 Opens: 124 Flush tables: 1 Open tables: 117 Queries per second avg: 0.163 -------------- 参考： https://www.cnblogs.com/java-123/p/10624600.html 扩展知识 修改mysql用户密码 ```shell script mysqld -nt --skip-grant-tables 以管理员身份运行这段命令，相当于在my.ini中[mysqld]下加入skip-grant-tables，就可以跳过登录校验 ，此时命令窗口不会动啦， 重开一个窗口 ，直接接登录： ```shell script mysql -uroot -proot use mysql update mysql.user set authentication_string=password('root') where user='root' and Host = 'localhost'; flush privileges; 查看注册表 win10左下角搜索框输入 regedit 然后依次打开 计算机\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\MySQL57 "},"数据库/oracle/oracle常见查询语句.html":{"url":"数据库/oracle/oracle常见查询语句.html","title":"oracle常见查询语句","keywords":"","body":" 1、常见查询 //当前用户拥有的表 select table_name from user_tables; //当前表字段 select * from user_tab_columns where Table_Name='T_IOT_CARD' ORDER BY COLUMN_name asc; //获取表注释： select * from user_tab_comments //获取字段注释： select * from user_col_comments where table_name='T_IOT_CARD' //查看序列 select * from user_sequences; //查看某个特定的序列 select * from user_sequences where sequence_name like '%SEQ_IOT_INTERFACE_DICT%' 参考：https://blog.51cto.com/meiling/2068902 2、oracle中如何查找表在哪个模式下？ select * from dba_tables where table_name like '%PROCESS_TEMPLATE%' demo: select * from dba_tables where table_name ='T_IOT_CARD' 3、 oracle 查看当前用户名 show user select user from dual oracle 查看所有用户名 select * from all_users https://www.cnblogs.com/tdskee/p/5848334.html plsql选择 command window ,不是sql window , 然后输入命令 start D:\\aa.sql Oracle trunc()函数的用法 https://www.cnblogs.com/zhangxiaoxia/p/10270840.html "},"数据库/postgres/postgres创建序列.html":{"url":"数据库/postgres/postgres创建序列.html","title":"postgres创建序列","keywords":"","body":" postgres创建序列并设置到某个主键上 CREATE SEQUENCE jumia_brand_seq START WITH 1 INCREMENT BY 1 NO MINVALUE NO MAXVALUE CACHE 1; alter table jumia_brand alter column id set default nextval('jumia_brand_seq'); "},"数据库/导数据/导出数百万级别数据.html":{"url":"数据库/导数据/导出数百万级别数据.html","title":"导出数百万级别数据","keywords":"","body":" 问题 表数据非常大，有几百万数据，用Navicat直接查询出来会崩掉，怎么样导出？ postgres数据库的解决方案 利用row_number进行排序查询，再一段段查询出来，如下： SELECT *,row_number() OVER(ORDER BY now()) as seq from t1 where seq BETWEEN 2000001 and 3000000 "}}