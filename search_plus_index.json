{"./":{"url":"./","title":"Introduction","keywords":"","body":"Java实用笔记 博客 Gitbook gitbook教程 Hugo hugo教程 各种问题 单元测试 单元测试获取不到数据库连接问题 定时任务 xxl-job打印日志问题 计算 bigdecimal相除问题 内存溢出 easyexcel内存溢出问题 配置 redisTemplate配置问题 前端 form表单序列化后中文乱码问题 Github github连接问题 Http http400问题 http415问题 Java 指针引用问题和List删除元素 hashmap删除问题 java处理重复请求 java指针引用问题 Mybatis Plus mybatis-plus无法更新空值问题 Springboot springboot排除数据源自动装配失效问题 springboot配置属性DataSource问题 springboot启动问题 springboot日志问题 springboot自动装配问题 开发工具 模板引擎 freemarker模板语法 Excel excel拼接字符串 Git git打tag git提交注释规范 git新建项目常见操作 Idea idea-git操作 idea插件 idea快捷键 idea中文乱码 ieda快捷生成代码 Postman postman调上传文件接口 Ppt markdown制作ppt Typora typora画图教程 Window jna问题 window端口占用查询 window开机启动 常见工具 开源项目 阿里开源项目 前端 弹窗 Layer layer弹窗 后台模板 ngx-admin后台模板学习 Angular angular基础 angular-generate命令 jquery基础 jquery按钮用法 Json 前端json字符串和js对象转换 Node node学习 Vue vue待学习 日常开发 常见时间操作 数据库 导数据 导出数百万级别数据 Mysql mysql版本升级 Oracle oracle常见查询语句 oracle常见更新操作 oracle的mergeinto更新用法 oracle分批插入更新 oracle约束 oracle注意问题 Postgres postgres创建序列 sql优化 存在一个表不存在另外一个表 微信支付 微信支付相关 中间件 Mybatis Plus mybatis-plus生成器相关问题 Redis redis发布订阅-消息接收 redis和redisson自动装配 Shardingsphere sharding-jdbc实现读写分离 Spring spring-core工具包 自动化 文档自动化生成 Devops Docker docker安装 docker实战1 docker实战3-运行和查看 docker实战4-挂载目录 docker实战5-曲线拉取国外镜像 Jenkins Jenkins全局工具配置 Kettle kettle数据同步技术攻克 Maven maven插件 maven打包 maven更改版本号 maven命令行推送jar包 maven私服配置并且推送jar包 maven引入lib文件夹下jar包并且打包 maven用法 maven单继承问题 Redis redis在windows下安装 Uml 建模工具plantuml介绍 Elasticsearch es实战 es实战1-常见命令 es实战2-查询命令 es实战3-综合查询案例 es实战4-java常见查询实例 es实战5-聚合分组查询案例 es实战6-springboot2.0集成elasticsearch6 es实战7-elasticsearch实现springboot自动配置 es知识点 和Elasticsearch交互 Elasticsearch学习 Java 缓存 Guava guava缓存简单使用三部曲 数据源 动态数据源 Java 8 java8新特性 Spi spi机制 Spring 动态创建bean spring事件 Swagger 更改swagger上下文 Util 日志 logback日志文件配置 Http RestTemplate用法 Json json序列化和反序列化工具 Xxl Job xxl-job定时任务教程 xxl-job执行shell脚本问题分析 Micro Service 安全 xss攻击 架构 项目目录架构设计 配置中心 Appollo apollo客户端配置使用.md apollo手动监听接收变更的配置 Nacos nacos-spring-cloud学习 nacos安装和入门学习 日志 log4j日志配置例子 文档管理 japidoc文档管理 pandoc教程 限流 限流算法 Sentinel 基础 sentinel通过spi方式注册数据源 sentinel学习 集群流控 sentinel集群流控 sentinel集群流控1-配置说明 sentinel集群流控2-ServerTransportConfig sentinel集群流控3-TransportConfig sentinel集群流控4-ClusterClientAssignConfig sentinel集群流控5-心跳检测 控制台 sentinel控制台部署和应用接入 sentinel控制台改造 源码分析 SentinelResource注解源码分析 sentinel命名空间namespace分析 sentinel问题汇总 Rabbitmq rabbitmq相关问题 rabbitmq-channel-shutdown问题 rabbitmq学习 rabbitmq延迟队列 Redis 批量删除redis Springboot springboot多环境配置 springBoot接口防抖防重复提交 springboot整合hikari数据源 springboot整合log4j打印mybatis的sql日志 springboot整合redisTemplate Python python入门 python小牛试刀-获取微信关注用户信息 "},"博客/gitbook/gitbook教程.html":{"url":"博客/gitbook/gitbook教程.html","title":"gitbook教程","keywords":"","body":" 基本步骤 #1、安装gitbook客户端 npm install gitbook-cli -g # 2、初始化一个仓库，会生成README.md和SUMMARY.md文件 gitbook init # 3、新建book.json，然后执行下面命令会安装里面的插件 gitbook install # 4、启动服务器 gitbook serve gitbook serve -p 8080 生产上去掉热部署，要不首页加载会很慢 gitbook serve --no-live 其他命令 gitbook -V # 生成html gitbook build book.json文件 { \"title\": \"Webpack 中文指南\", \"description\": \"Webpack 是当下最热门的前端资源模块化管理和打包工具，本书大部分内容翻译自 Webpack 官网。\", \"language\": \"zh\", \"plugins\": [ \"disqus\", \"github\", \"editlink\", \"prism\", \"-highlight\", \"baidu\", \"splitter\", \"sitemap\", \"summary\" ], \"pluginsConfig\": { \"disqus\": { \"shortName\": \"webpack-handbook\" }, \"github\": { \"url\": \"https://github.com/zhaoda/webpack-handbook\" }, \"editlink\": { \"base\": \"https://github.com/zhaoda/webpack-handbook/blob/master/content\", \"label\": \"编辑本页\" }, \"baidu\": { \"token\": \"a9787f0ab45d5e237bab522431d0a7ec\" }, \"sitemap\": { \"hostname\": \"http://zhaoda.net/\" } } } 自动生成summary目录 安装插件 npm install -g gitbook-summary book sm -c _posts book sm -c source/_posts -c参数-c，即--catalog，是指全部要显示的目录，表示要生成html的文件夹缺陷：source/_posts表示该目录是需要生成html的目录,貌似这样没用，只能到source目录,不能具体到_posts目录 -i 是参数 --ignores的缩写形式，意思是忽略该参数提供的目录-i 用法像下面那样,有效果,注意是文件夹的名字(注意大小写)， book sm -c source/_posts -i about,tags,friends,categories 在book.json里添加也可以，如下： \"ignores\": [\"friends\",\"tags\",\"categories\",\"about\"], 缺陷：若要忽略的文件夹，存在要生成的文件夹_posts的子文件夹。这个子文件夹也无法生成，这种应该改成指定路径下的文件夹的，例如devops既存在source下，又存在_posts下，我只想忽略source下的devops，它却连_posts下的也忽略了 注意：在哪个目录下执行book命令就生成SUMMARY.md在哪个目录下，测试发现在content目录下(非根目录下)生成的文件开头没法 取到book.json定义的title 参考：https://blog.csdn.net/ds19991999/article/details/81275458 生成pdf文件 gitbook pdf . book.pdf 添加章节编号 在pluginsConfig加上,注意不是在plugin里加 \"theme-default\": { \"showLevel\": true } https://www.crifan.com/gitbook_add_chapter_index_number/ 修改indroduction首页指定为另一个文件 \"structure\": { \"readme\": \"SUMMARY.md\" } 修改根目录，即打包生成html目录 \"root\": \"./content\", 部署到coding 特别注意1、自定义的gitbbook发布时不能在根目录下新建scripts文件夹，否则会影响hexo的生成和发布 2、自定义的deploy-gh-pages.js会改变当前git仓库的分支，特别注意这个 新建gitbook_deploy文件夹，然后新建deploy-gh-pages.js文件，文件内容大概如下注意修改repo为你自己的git仓库,_book是你生成的gitbook的html输出目录 'use strict'; var ghpages = require('gh-pages'); main(); function main() { const defaults = { dest: '.', add: false, git: 'git', depth: 1, dotfiles: false, branch: 'gh-pages', src: '**/*', only: '.', push: true, message: 'Updates', silent: false, repo: '你的git仓库地址' }; ghpages.publish('./_book',defaults, console.error.bind(console)); } 参考：https://github.com/tschaub/gh-pages 自动化 特别注意不能ignore掉content文件夹，否则命令找不到文件的 npm run gautopublish nodejs拷贝文件https://www.cnblogs.com/coding4/p/7495968.html 发布到gitbook http://www.chengweiyang.cn/gitbook/gitbook.com/newbook.html 统计插件 { \"plugins\": [ \"pageview-count\" ] } 个性化配置 http://www.chengweiyang.cn/gitbook/customize/book.json.html 修改样式 https://blog.tedxiong.com/how_to_remove_Published_with_GitBook_in_GitBook.html 其他 插件 https://blog.csdn.net/weixin_37865166/article/details/91899788 https://yanhaijing.com/tool/2015/09/12/my-gitbook-note/ 在book.json中定义，这样README.md就可以用作项目的简介 { \"structure\": { \"readme\": \"SUMMARY.md\" } } 注意： 这个一般和\"root\": \".deploy/content\",这个一起用 还有注意readme这里只能定义文件，比如SUMMARY.md,而不能带目录如.deploy/content/SUMMARY.md, 而root则可以定义成目录如.deploy/content \"root\": \".deploy/content\", { \"structure\": { \"readme\": \"SUMMARY.md\" } } 上面表示根目录在.deploy/content目录下,描述文件为SUMMARY.md， 这时gitbook build编译命令为gitbook build . .deploy/_book --no-live 第一个.表示在项目的根目录下(比如lqx-gitbook-deploy),注意这里必须用. 不要用.deploy/content,否则gitbook build会报README.md找不到的 第二个.deploy/_book表示要生成的html文件输出的目录. https://www.cnblogs.com/luoheng23/p/11197922.html https://baijiahao.baidu.com/s?id=1590626161534963215&wfr=spider&for=pc https://gitbook.zhangjikai.com/structure.html https://www.jianshu.com/p/4e109a1113b2 插件： https://www.jianshu.com/p/427b8bb066e6 热加载： https://blog.csdn.net/weixin_38171180/article/details/89975512 去掉热加载 http://stackmirror.caup.cn/page/s1b4bt53rg3a 生成页内目录(要自己在文章加toc标签) npm i gitbook-plugin-toc2 --save plugins: [\"toc2\"], \"pluginsConfig\": { \"toc\": { \"addClass\": true, \"className\": \"toc\" } } https://www.npmjs.com/package/gitbook-plugin-toc2 https://cnodejs.org/topic/575229332420978970d4a5f0 生成页内目录2(要自己在文章加toc标签) npm i gitbook-plugin-page-toc-button --save { ... \"plugins\": [ \"page-toc-button\", ], \"pluginsConfig\": { \"page-toc-button\": { \"maxTocDepth\": 2, \"minTocSize\": 2 } } ... } https://www.gitdig.com/gitbook/plugin/toc.html https://github.com/jonschlinkert/markdown-toc https://github.com/stuebersystems/gitbook-plugin-simple-page-toc https://github.com/dohoby/gitbook-plugin-page-toc-button 可扩展导航章节(有问题,无法展开) npm i gitbook-plugin-expandable-chapters-small --save https://www.npmjs.com/package/gitbook-plugin-expandable-chapters-small TODO 待研究 1、给html,js等加上版本号，要不每次更改内容时，浏览器还是有缓存 http://xszhao.science/cheatsheet/content/web/gitbook.html 2、toc目录移动到右边 gitbook官方文档 https://github.com/GitbookIO/gitbook/tree/master/docs 源码：C:\\Users\\Administrator.gitbook\\versions\\3.2.3 问题 若遇到下面的提示，很可能是没有权限访问，但是在命令行用ssh又可以拼得通连接git是可以的 at ChildProcess.emit (events.js:191:7) at maybeClose (internal/child_process.js:877:16) at Process.ChildProcess._handle.onexit (internal/child_process.js:226:5) code: 128, message: 'Cloning into \\'node_modules\\\\gh-pages\\\\.cache\\\\git@git.\\'...\\nHost key verification failed.\\r\\nfatal: Could not read from remote repository.\\n\\nPlease make sure you have the correct access rights\\nand the repository exists.\\n', name: 'ProcessError' } 解决办法： 在网上搜索了好久都没找到相应办法，后来在命令行下执行下面的,也就是手动clone下仓库的地址， 看下面的提示The authenticity of host 'git.dev.tencent.com (118.25.166.124)' can't be established. 这个和上面的报错Host key verification failed对应, 命令停止在Are you sure you want to continue connecting (yes/no)? yes输入yes后，再重新执行上面的部署命令即可解决了 λ git clone 你的git仓库的ssh地址 Cloning into 'gitbook'... The authenticity of host 'git.dev.tencent.com (118.25.166.124)' can't be established. RSA key fingerprint is SHA256:xxxxxxxxxx. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added 'git.dev.tencent.com' (RSA) to the list of known hosts. remote: Enumerating objects: 3734, done. remote: Counting objects: 100% (3734/3734), done. remote: Compressing objects: 100% (3464/3464), done. remote: Total 3734 (delta 2449), reused 297 (delta 137) Receiving objects: 100% (3734/3734), 3.09 MiB | 1020.00 KiB/s, done. Resolving deltas: 100% (2449/2449), done. Checking connectivity... done. git 不是内部或外部命令，也不是可运行的程序 注意git安装的要把git的两个路径设置到path环境变量，否则在idea里没法跑git命令 a:找到git安装路径中bin的位置：D:\\Program Files\\Git\\bin b:找到git安装路径中libexec\\git-core的位置，如：D:\\Program Files\\Git\\mingw64\\libexec\\git-core 其中git安装路径为D:\\Program Files\\Git\\ 参考https://blog.csdn.net/qq_27911459/article/details/98967901 "},"博客/hugo/hugo教程.html":{"url":"博客/hugo/hugo教程.html","title":"hugo教程","keywords":"","body":" 1、 https://www.gohugo.org/ 2、 3、 "},"各种问题/单元测试/单元测试获取不到数据库连接问题.html":{"url":"各种问题/单元测试/单元测试获取不到数据库连接问题.html","title":"单元测试获取不到数据库连接问题","keywords":"","body":" 问题 在单元测试时，运行的单元测试里有发送mq消息的，然后有个监听器类接收消息的， 然后在测试接收消息时，跑着跑着发现报下面的错，是获取不到连接的问题，后来看了好久，想应该是发送消息的那个 主程序关闭了导致的 ### Error querying database. Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is java.sql.SQLException: HikariDataSource HikariDataSource (HikariPool-1) has been closed. ### The error may exist in file [D:\\idea-workspace4\\iotcard\\flow-sync-service\\target\\classes\\mapper\\FlowSyncCardMonitorHistoryMapper.xml] ### The error may involve com.fzs.iotcard.flowsync.mapper.FlowSyncCardMonitorHistoryMapper.queryYesterdayUpdated ### The error occurred while executing a query ### Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is java.sql.SQLException: HikariDataSource HikariDataSource (HikariPool-1) has been closed. 解决 在运行的单元测试里加上休眠，不要让发送消息的线程太快结束即可 //这里加上休眠，防止mq哪里消费入库还没跑完，这里主线程结束了，导致获取不到数据库连接 Thread.sleep(120000); "},"各种问题/定时任务/xxl-job打印日志问题.html":{"url":"各种问题/定时任务/xxl-job打印日志问题.html","title":"xxl-job打印日志问题","keywords":"","body":" 注意不能像下面那样写,不能有{}或者,这些或者，应该直接用+拼起来， XxlJobLogger.log(\"shopid:{},skus:{}\", shopid, skus); 否则会报类似下面的错： ----------- JobThread Exception:java.lang.IllegalArgumentException: can't parse argument number: at java.text.MessageFormat.makeFormat(MessageFormat.java:1429) at java.text.MessageFormat.applyPattern(MessageFormat.java:479) at java.text.MessageFormat.(MessageFormat.java:362) at java.text.MessageFormat.format(MessageFormat.java:840) at com.xxl.job.core.log.XxlJobLogger.log(XxlJobLogger.java:58) at com.tobe.sp.AmazonTask.xxljob.AmazonOrderDisposeSyncHandler.execute(AmazonOrderDisposeSyncHandler.java:40) at com.xxl.job.core.thread.JobThread.run(JobThread.java:119) Caused by: java.lang.NumberFormatException: For input string: \"\" at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) at java.lang.Integer.parseInt(Integer.java:592) at java.lang.Integer.parseInt(Integer.java:615) at java.text.MessageFormat.makeFormat(MessageFormat.java:1427) ... 6 more ----------- xxl-job job execute end(error) ----------- 正确写法： XxlJobLogger.log(\"arg0：\" + arg0); "},"各种问题/计算/bigdecimal相除问题.html":{"url":"各种问题/计算/bigdecimal相除问题.html","title":"bigdecimal相除问题","keywords":"","body":" 问题代码 问题代码如下： BigDecimal salePrice=new BigDecimal(\"2.5000000\"); BigDecimal saleDiscount=new BigDecimal(\"8.3333\"); BigDecimal standardRate = salePrice .divide(saleDiscount) .multiply(BigDecimal.valueOf(100)) .setScale(7, RoundingMode.HALF_UP); System.out.println(standardRate); 然后报错： Exception in thread \"main\" java.lang.ArithmeticException: Non-terminating decimal expansion; no exact representable decimal result. at java.math.BigDecimal.divide(BigDecimal.java:1693) at com.redis.Test2Case.main(Test2Case.java:25) 分析： 报错是指：java.lang.AthmeticException：非终止小数展开；没有可精确表示的十进制结果。 其实就是无限循环，小数点后3333这些除不尽 BigDecimal salePrice=new BigDecimal(\"2.5000000\"); BigDecimal saleDiscount=new BigDecimal(\"8.3333\"); BigDecimal standardRate = salePrice .divide(saleDiscount,7,RoundingMode.HALF_UP) .multiply(BigDecimal.valueOf(100)) .setScale(7, RoundingMode.HALF_UP); System.out.println(standardRate); 结果：30.0120000 Non-terminating decimal expansion；no exact representable decimal result https://mp.weixin.qq.com/s/lirmZlwdCIPIzsObsOiyDA ``` "},"各种问题/内存溢出/easyexcel内存溢出问题.html":{"url":"各种问题/内存溢出/easyexcel内存溢出问题.html","title":"easyexcel内存溢出问题","keywords":"","body":" 问题 如图：生产环境上只要点导出数据，数据量大概60万，在某个机器下，内存飙升到5g， 然后就自动重启服务了， 排查 利用jdk下的工具jvisualvm.exe， 具体路径D:\\Program Files\\Java80331\\jdk1.8.0_331\\bin\\jvisualvm.exe 然后jvm设定为2g,即为-Xmx2048m，如下图用jvisualvm看 看图黄色的是申请的，蓝色的是使用的堆内存,但是始终没有超出2g 接着jvm改为5g，即为 -Xmx5120m，如下图用jvisualvm看 看图，看到随着内存加大，黄色申请的内存量也往上增，蓝色的也增长，但是始终还是没有超过2g 经上面分析本地暂时没有排查到具体的问题 观察和搜索 经过本地的排查重现不了，只能继续看问题图，发现问题图应该是黄色的申请资源内存的曲线图， 而不是回收的图，如果是回收的至少是v图，即为一下一上的图，像本地测试那样才是正常， 而再看问题图发现几次点击是先平缓网上增内存，然后在某一个点突然间直线上升， 像申请的内存资源翻倍似的，于是在网上搜索“easyexcel内存溢出”，一搜马上看到 记录一次EasyExcel2.2.6版本内存泄漏问题 再看项目中引用的easyexcel版本，刚好是这个版本，所以问题根本在于内存溢出 解决 ``` "},"各种问题/配置/redisTemplate配置问题.html":{"url":"各种问题/配置/redisTemplate配置问题.html","title":"redisTemplate配置问题","keywords":"","body":"title: redisTemplate配置问题 tags: [] date: 2020-12-23 21:48:59 categories: 问题：配置RedisTemplate,启动报错 看下面自定义配置的RedisTemplate，用了LettuceConnectionFactory(是RedisConnectionFactory的子类) /** * redisTemplate 默认序列化使用的 jdkSerializeable, 存储二进制字节码, 所以一般需要自定义序列化类 * https://www.cnblogs.com/puzhiwei/p/12519304.html * @return */ @Bean public RedisTemplate redisTemplateSerializer(LettuceConnectionFactory lettuceConnectionFactory) { // 设置序列化 Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper objectMapper = new ObjectMapper(); // 指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和public objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer等会跑出异常 objectMapper.activateDefaultTyping(LaissezFaireSubTypeValidator.instance, ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); RedisSerializer stringSerializer = new StringRedisSerializer(); // 配置redisTemplate RedisTemplate redisTemplate = new RedisTemplate(); redisTemplate.setConnectionFactory(lettuceConnectionFactory); // key序列化 redisTemplate.setKeySerializer(stringSerializer); // value序列化 redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); // Hash key序列化 redisTemplate.setHashKeySerializer(stringSerializer); // Hash value序列化 redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; } 报错日志： Parameter 0 of method redisTemplateSerializer in com.basic.config.RedisTemplateConfig required a bean of type 'org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory' that could not be found. The following candidates were found but could not be injected: - Bean method 'redisConnectionFactory' in 'LettuceConnectionConfiguration' not loaded because @ConditionalOnMissingBean (types: org.springframework.data.redis.connection.RedisConnectionFactory; SearchStrategy: all) found beans of type 'org.springframework.data.redis.connection.RedisConnectionFactory' redissonConnectionFactory Action: Consider revisiting the entries above or defining a bean of type 'org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory' in your configuration. 原因分析： 看spring-boot-autoconfigure包下的RedisAutoConfiguration org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration 其中用Import注解引入了LettuceConnectionConfiguration @Configuration( proxyBeanMethods = false ) @ConditionalOnClass({RedisOperations.class}) @EnableConfigurationProperties({RedisProperties.class}) @Import({LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class}) public class RedisAutoConfiguration { public RedisAutoConfiguration() { } @Bean @ConditionalOnMissingBean( name = {\"redisTemplate\"} ) public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { RedisTemplate template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } } 继续看LettuceConnectionConfiguration类 可以看到当缺失RedisConnectionFactory时，就会默认创建一个名称为redisConnectionFactory的bean，类型为LettuceConnectionFactory也就是这里会创建一个redisConnectionFactory @Bean @ConditionalOnMissingBean({RedisConnectionFactory.class}) LettuceConnectionFactory redisConnectionFactory(ObjectProvider builderCustomizers, ClientResources clientResources) throws UnknownHostException { LettuceClientConfiguration clientConfig = this.getLettuceClientConfiguration(builderCustomizers, clientResources, this.getProperties().getLettuce().getPool()); return this.createLettuceConnectionFactory(clientConfig); } 而上面配置用RedisTemplate时注入LettuceConnectionFactory类报错是因为同时使用了redisson,而redisson的自动装配也创建了redisConnectionFactory 看redisson-spring-boot-starter下的RedissonAutoConfiguration org.redisson.spring.starter.RedissonAutoConfiguration 下面也会创建redissonConnectionFactory、RedisTemplate等，同时RedissonAutoConfiguration用了AutoConfigureBefore，会比RedisAutoConfiguration先装配 @Configuration @ConditionalOnClass({Redisson.class, RedisOperations.class}) @AutoConfigureBefore({RedisAutoConfiguration.class}) @EnableConfigurationProperties({RedissonProperties.class, RedisProperties.class}) public class RedissonAutoConfiguration { @Autowired private RedissonProperties redissonProperties; @Autowired private RedisProperties redisProperties; @Autowired private ApplicationContext ctx; public RedissonAutoConfiguration() { } @Bean @ConditionalOnMissingBean( name = {\"redisTemplate\"} ) public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean({StringRedisTemplate.class}) public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean({RedisConnectionFactory.class}) public RedissonConnectionFactory redissonConnectionFactory(RedissonClient redisson) { return new RedissonConnectionFactory(redisson); } 解决 配置RedisTemplate，不要用LettuceConnectionFactory注入，直接用RedisConnectionFactory就可以 public RedisTemplate redisTemplateSerializer(RedisConnectionFactory redisConnectionFactory) { "},"各种问题/前端/form表单序列化后中文乱码问题.html":{"url":"各种问题/前端/form表单序列化后中文乱码问题.html","title":"form表单序列化后中文乱码问题","keywords":"","body":" 1、jquery form表单序列化后中文乱码问题解决代码实现 前台： var params =$('#addForm').serialize(); params = encodeURI(encodeURI(decodeURIComponent(params,true))); $.ajax({ type: \"post\", url: \"sptSUPPSupplierBankController.cmd?method=persisit\", data: params, success: function(data) { if(data=='1'){ alert(\"保存成功\"); }else{ alert(\"保存失败！\"); } } }); jquery form表单.serialize()序列化后中文乱码问题原因及解决 原因： .serialize()自动调用了encodeURIComponent方法将数据编码了 解决方法：调用decodeURIComponent(XXX,true);将数据解码 例如： var params = $(\"#formId\").serialize(); params = decodeURIComponent(params,true); 在进行编码 params = encodeURI(encodeURI(params)); 后台 params = java.net.URLDecoder.decode(params , \"UTF-8\"); 问题解决。 参考： https://blog.csdn.net/fzy629442466/article/details/84786049?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf https://blog.csdn.net/w1014074794/article/details/43987689 2、 3、 ``` "},"各种问题/github/github连接问题.html":{"url":"各种问题/github/github连接问题.html","title":"github连接问题","keywords":"","body":" 问题：git-ssh: connect to host github.com port 22: Connection timed out 修改项目对应的git的url 找到项目下git对应的config文件，比如 我的路径D:\\idea-workspace-blog\\lqx-node-reptile.git下的config，修改url部分 url = git@ssh.github.com:xx/xxx.git 本来是git@github.com的，现在改成git@ssh.github.com 测试连接github ssh -T git@github.com ssh: connect to host github.com port 22: Connection timed out 发现非ssh下连接超时 改成ssh的连接 ssh -T -p 443 git@ssh.github.com The authenticity of host '[ssh.github.com]:443 ([20.205.243.160]:443)' can't be established. ECDSA key fingerprint is SHA256:p2QAMXNIC1TJYWeIOttrVc98/R1BUFWu3/LiyKgUfQM. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added '[ssh.github.com]:443,[20.205.243.160]:443' (ECDSA) to the list of known hosts. Hi dohoby! You've successfully authenticated, but GitHub does not provide shell access. 叫选择时则输入yes，发现ssh连接是可以的 增加ssh的config C:\\Users\\hoby.ssh路径下找到config文件（没有则创建） 内容如下 Host github.com Hostname ssh.github.com Port 443 增加下，再测试ssh，发现不用输入yes了 ssh -T -p 443 git@ssh.github.com Hi dohoby! You've successfully authenticated, but GitHub does not provide shell access. 在github个人设置页面上增加ssh的key 地址为：https://github.com/settings/keys 最后再尝试提交代码到github上 参考： https://www.jianshu.com/p/c3aac5024877 "},"各种问题/http/http400问题.html":{"url":"各种问题/http/http400问题.html","title":"http400问题","keywords":"","body":" 1、后端controller加上@RequestBody就报错400 @ResponseBody @RequestMapping(value = \"/save\", method = RequestMethod.POST) public ResultBean save(HttpServletRequest request,@RequestBody IotInterfaceParamConfigDTO record) { ResultBean resultBean = new ResultBean(); IotUser user = super.getPortalUser(request); if (user == null) { return ResultBean.resultFail(\"0\", \"用户没登录\"); } if (record.getId() != null) { record.setCreator(user.getUserName()); iotInterfaceParamConfigService.update(record); } else { record.setModifier(user.getUserName()); iotInterfaceParamConfigService.add(record); } return resultBean; } 2、前端用ajax或者rest client 请求参数 { \"id\": \"\", \"interfacePlatformId\": \"12\", \"businessCategoryId\": \"11\", \"interfaceCategoryId\": \"11\", \"interfaceNumber\": \"aa\", \"interfaceName\": \"a\", \"serviceAddress\": \"a\", \"businessDesc\": \"a\", \"suitFor\": \"1\", \"enable\": \"1\", \"iotInterfaceParamRules\": [{ \"id\": \"undefined\", \"cardManageMode\": \"4\", \"condition\": \">1 >1\", \"priority\": \"3\", \"remarkDesc\": \"a\" }], \"iotInterfaceParamProperties\": [{ \"id\": \"\", \"attributeName\": \"a\", \"condition\": \"a\", \"remarkDesc\": \"a\" }] } 3、解决： log4j.properties加上debug，改为下面的， log4j.rootLogger=debug,info, CONSOLE, FILE,stdout 开启后查看日志： 2020-10-30 15:04:36.861 pid[] thread[http-nio-8080-exec-4hread] DEBUG hibernate4.support.OpenSessionInViewFilter:187 - Using SessionFactory 'sys_sessionFactory' for OpenSessionInViewFilter 2020-10-30 15:04:36,861 DEBUG [org.springframework.orm.hibernate4.support.OpenSessionInViewFilter] - Using SessionFactory 'sys_sessionFactory' for OpenSessionInViewFilter 2020-10-30 15:04:36.863 pid[] thread[http-nio-8080-exec-4hread] DEBUG factory.support.DefaultListableBeanFactory:243 - Returning cached instance of singleton bean 'sys_sessionFactory' 2020-10-30 15:04:36,863 DEBUG [org.springframework.beans.factory.support.DefaultListableBeanFactory] - Returning cached instance of singleton bean 'sys_sessionFactory' 2020-10-30 15:04:36.863 pid[] thread[http-nio-8080-exec-4hread] DEBUG hibernate4.support.OpenSessionInViewFilter:139 - Opening Hibernate Session in OpenSessionInViewFilter 2020-10-30 15:04:36,863 DEBUG [org.springframework.orm.hibernate4.support.OpenSessionInViewFilter] - Opening Hibernate Session in OpenSessionInViewFilter 2020-10-30 15:04:36.864 pid[] thread[http-nio-8080-exec-4hread] DEBUG hibernate.internal.SessionImpl:302 - Opened session at timestamp: 16040414768 2020-10-30 15:04:36,864 DEBUG [org.hibernate.internal.SessionImpl] - Opened session at timestamp: 16040414768 2020-10-30 15:04:36.864 pid[] thread[http-nio-8080-exec-4hread] DEBUG web.servlet.DispatcherServlet:819 - DispatcherServlet with name 'dispatchServlet' processing POST request for [/fzsiotcard/admin/interfacemanage/iotInterfaceParamConfig/save] 2020-10-30 15:04:36,864 DEBUG [org.springframework.web.servlet.DispatcherServlet] - DispatcherServlet with name 'dispatchServlet' processing POST request for [/fzsiotcard/admin/interfacemanage/iotInterfaceParamConfig/save] 2020-10-30 15:04:36.864 pid[] thread[http-nio-8080-exec-4hread] DEBUG method.annotation.RequestMappingHandlerMapping:229 - Looking up handler method for path /admin/interfacemanage/iotInterfaceParamConfig/save 2020-10-30 15:04:36,864 DEBUG [org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping] - Looking up handler method for path /admin/interfacemanage/iotInterfaceParamConfig/save 2020-10-30 15:04:36.865 pid[] thread[http-nio-8080-exec-4hread] DEBUG method.annotation.RequestMappingHandlerMapping:234 - Returning handler method [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)] 2020-10-30 15:04:36,865 DEBUG [org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping] - Returning handler method [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)] 2020-10-30 15:04:36.865 pid[] thread[http-nio-8080-exec-4hread] DEBUG factory.support.DefaultListableBeanFactory:243 - Returning cached instance of singleton bean 'iotInterfaceParamConfigController' 2020-10-30 15:04:36,865 DEBUG [org.springframework.beans.factory.support.DefaultListableBeanFactory] - Returning cached instance of singleton bean 'iotInterfaceParamConfigController' 2020-10-30 15:04:36.865 pid[] thread[http-nio-8080-exec-4hread] DEBUG component.interceptors.AuthenticationInterceptor:49 - HandlerMethod: /admin/interfacemanage/iotInterfaceParamConfig/save rights authentication. 2020-10-30 15:04:36,865 DEBUG [com.fzs.uniauth.component.interceptors.AuthenticationInterceptor] - HandlerMethod: /admin/interfacemanage/iotInterfaceParamConfig/save rights authentication. 2020-10-30 15:04:36.866 pid[] thread[http-nio-8080-exec-4hread] DEBUG method.annotation.RequestResponseBodyMethodProcessor:140 - Reading [class com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO] as \"application/json;charset=UTF-8\" using [org.springframework.http.converter.json.MappingJackson2HttpMessageConverter@77cc5550] 2020-10-30 15:04:36,866 DEBUG [org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor] - Reading [class com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO] as \"application/json;charset=UTF-8\" using [org.springframework.http.converter.json.MappingJackson2HttpMessageConverter@77cc5550] 2020-10-30 15:04:36.867 pid[] thread[http-nio-8080-exec-4hread] DEBUG method.annotation.ExceptionHandlerExceptionResolver:132 - Resolving exception from handler [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)]: org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]) 2020-10-30 15:04:36,867 DEBUG [org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver] - Resolving exception from handler [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)]: org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]) 2020-10-30 15:04:36.867 pid[] thread[http-nio-8080-exec-4hread] DEBUG mvc.annotation.ResponseStatusExceptionResolver:132 - Resolving exception from handler [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)]: org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]) 2020-10-30 15:04:36,867 DEBUG [org.springframework.web.servlet.mvc.annotation.ResponseStatusExceptionResolver] - Resolving exception from handler [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)]: org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]) 2020-10-30 15:04:36.868 pid[] thread[http-nio-8080-exec-4hread] DEBUG mvc.support.DefaultHandlerExceptionResolver:132 - Resolving exception from handler [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)]: org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]) 2020-10-30 15:04:36,868 DEBUG [org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolver] - Resolving exception from handler [public com.web.bean.ResultBean com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(javax.servlet.http.HttpServletRequest,com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO)]: org.springframework.http.converter.HttpMessageNotReadableException: Could not read JSON: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value at [Source: (org.apache.catalina.connector.CoyoteInputStream); line: 13, column: 9] (through reference chain: com.web.supplier.interfacemanage.bean.IotInterfaceParamConfigDTO[\"iotInterfaceParamRules\"]->java.util.ArrayList[0]->com.web.supplier.interfacemanage.entity.IotInterfaceParamRule[\"id\"]) 2020-10-30 15:04:36.868 pid[] thread[http-nio-8080-exec-4hread] DEBUG web.servlet.DispatcherServlet:993 - Null ModelAndView returned to DispatcherServlet with name 'dispatchServlet': assuming HandlerAdapter completed request handling 2020-10-30 15:04:36,868 DEBUG [org.springframework.web.servlet.DispatcherServlet] - Null ModelAndView returned to DispatcherServlet with name 'dispatchServlet': assuming HandlerAdapter completed request handling 2020-10-30 15:04:36.869 pid[] thread[http-nio-8080-exec-4hread] DEBUG web.servlet.DispatcherServlet:983 - Successfully completed request 2020-10-30 15:04:36,869 DEBUG [org.springframework.web.servlet.DispatcherServlet] - Successfully completed request 2020-10-30 15:04:36.869 pid[] thread[http-nio-8080-exec-4hread] DEBUG hibernate4.support.OpenSessionInViewFilter:159 - Closing Hibernate Session in OpenSessionInViewFilter 2020-10-30 15:04:36,869 DEBUG [org.springframework.orm.hibernate4.support.OpenSessionInViewFilter] - Closing Hibernate Session in OpenSessionInViewFilter 2020-10-30 15:05:05.847 pid[] thread[Apollo-RemoteConfigLongPollService-1hread] DEBUG apollo.internals.RemoteConfigLongPollService:172 - Long polling response: 304, url: http://dev-apollo-configservice:9012/notifications/v2?cluster=default&appId=fzs-iotcard&ip=10.20.11.161&notifications=%5B%7B%22namespaceName%22%3A%22application%22%2C%22notificationId%22%3A2154%7D%5D 2020-10-30 15:05:05,847 DEBUG [com.ctrip.framework.apollo.internals.RemoteConfigLongPollService] - Long polling response: 304, url: http://dev-apollo-configservice:9012/notifications/v2?cluster=default&appId=fzs-iotcard&ip=10.20.11.161&notifications=%5B%7B%22namespaceName%22%3A%22application%22%2C%22notificationId%22%3A2154%7D%5D 2020-10-30 15:05:05.849 pid[] thread[Apollo-RemoteConfigLongPollService-1hread] DEBUG apollo.internals.RemoteConfigLongPollService:163 - Long polling from http://dev-apollo-configservice:9012/notifications/v2?cluster=default&appId=fzs-iotcard&ip=10.20.11.161&notifications=%5B%7B%22namespaceName%22%3A%22application%22%2C%22notificationId%22%3A2154%7D%5D 2020-10-30 15:05:05,849 DEBUG [com.ctrip.framework.apollo.internals.RemoteConfigLongPollService] - Long polling from http://dev-apollo-configservice:9012/notifications/v2?cluster=default&appId=fzs-iotcard&ip=10.20.11.161&notifications=%5B%7B%22namespaceName%22%3A%22application%22%2C%22notificationId%22%3A2154%7D%5D 仔细观察发现是这行日志的问题： IotInterfaceParamRule[\"id\"]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String \"undefined\": not a valid Long value 也就是IotInterfaceParamRule对应的字段id设值为undefined了， 再仔细观察请求json参数，果然发现有个undefined \"iotInterfaceParamRules\": [{ \"id\": \"undefined\", \"cardManageMode\": \"4\", \"condition\": \">1 >1\", \"priority\": \"3\", \"remarkDesc\": \"a\" }] 干掉undefined再请求即可正常了 正确json如下： { \"id\": \"\", \"interfacePlatformId\": \"12\", \"businessCategoryId\": \"7\", \"interfaceCategoryId\": \"11\", \"interfaceNumber\": \"1\", \"interfaceName\": \"1\", \"serviceAddress\": \"1\", \"businessDesc\": \"1\", \"suitFor\": \"2\", \"enable\": \"1\", \"iotInterfaceParamRules\": [{ \"id\": \"\", \"cardManageMode\": \"1\", \"condition\": \" ajax请求： //获取rule数据 var ruleData = getRuleTableData(); var propertyData = getPropertyData(); var formdata = form.serialize();//序列化表单 var arr = formdata.split(\"&\");//转换成字符数组 var newData = new Object();//用来存储转换后的数组 for (var i = 0; i 别人的400(和我上面的不一样) 400问题 ajax错误返回： 参考： https://www.cnblogs.com/xinzhisoft/p/10648946.html 上面我自己打印的错误js日志： abort: ƒ (t) always: ƒ () complete: ƒ () done: ƒ () error: ƒ () fail: ƒ () getAllResponseHeaders: ƒ () getResponseHeader: ƒ (t) overrideMimeType: ƒ (t) pipe: ƒ () progress: ƒ () promise: ƒ (t) readyState: 4 responseText: \"HTTP状态 500 - 内部服务器错误body {font-family:Tahoma,Arial,sans-serif;} h1, h2, h3, b {color:white;background-color:#525D76;} h1 {font-size:22px;} h2 {font-size:16px;} h3 {font-size:14px;} p {font-size:12px;} a {color:black;} .line {height:1px;background-color:#525D76;border:none;}HTTP状态 500 - 内部服务器错误类型 异常报告消息 Request processing failed; nested exception is org.springframework.dao.DataIntegrityViolationException: 描述 服务器遇到一个意外的情况，阻止它完成请求。例外情况org.springframework.web.util.NestedServletException: Request processing failed; nested exception is org.springframework.dao.DataIntegrityViolationException: ↵### Error updating database. Cause: java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵ ↵### The error may exist in file [D:\\idea-workspace4\\FZS_IOT_CARD\\target\\project-practice\\WEB-INF\\classes\\mapper\\interfacemanage\\IotInterfaceParamRuleMapper.xml] ↵### The error may involve com.web.supplier.interfacemanage.mapper.IotInterfaceParamRuleMapper.insertSelective-Inline ↵### The error occurred while setting parameters ↵### SQL: insert into T_IOT_INTERFACE_PARAM_RULE ( ID, CARD_MANAGE_MODE, CONDITION, PRIORITY, REMARK_DESC, STATUS, CREATE_TIME, DELETED ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) ↵### Cause: java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵↵; SQL []; ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵; nested exception is java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵ ↵ org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:965) ↵ org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:855) ↵ javax.servlet.http.HttpServlet.service(HttpServlet.java:652) ↵ org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:829) ↵ javax.servlet.http.HttpServlet.service(HttpServlet.java:733) ↵ org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ↵ org.springframework.orm.hibernate4.support.OpenSessionInViewFilter.doFilterInternal(OpenSessionInViewFilter.java:151) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:88) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) ↵根本原因。org.springframework.dao.DataIntegrityViolationException: ↵### Error updating database. Cause: java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵ ↵### The error may exist in file [D:\\idea-workspace4\\FZS_IOT_CARD\\target\\project-practice\\WEB-INF\\classes\\mapper\\interfacemanage\\IotInterfaceParamRuleMapper.xml] ↵### The error may involve com.web.supplier.interfacemanage.mapper.IotInterfaceParamRuleMapper.insertSelective-Inline ↵### The error occurred while setting parameters ↵### SQL: insert into T_IOT_INTERFACE_PARAM_RULE ( ID, CARD_MANAGE_MODE, CONDITION, PRIORITY, REMARK_DESC, STATUS, CREATE_TIME, DELETED ) values ( ?, ?, ?, ?, ?, ?, ?, ? ) ↵### Cause: java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵↵; SQL []; ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵; nested exception is java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵ ↵ org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:249) ↵ org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72) ↵ org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:71) ↵ org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:365) ↵ com.sun.proxy.$Proxy26.insert(Unknown Source) ↵ org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:237) ↵ org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:79) ↵ org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:40) ↵ com.sun.proxy.$Proxy167.insertSelective(Unknown Source) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamRuleServiceImpl.insert(IotInterfaceParamRuleServiceImpl.java:59) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl.lambda$saveIotInterfaceParamProperties$1(IotInterfaceParamConfigServiceImpl.java:173) ↵ java.util.ArrayList.forEach(ArrayList.java:1249) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl.saveIotInterfaceParamProperties(IotInterfaceParamConfigServiceImpl.java:167) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl.add(IotInterfaceParamConfigServiceImpl.java:124) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl$$FastClassBySpringCGLIB$$b816365b.invoke(&lt;generated&gt;) ↵ org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ↵ org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:629) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl$$EnhancerBySpringCGLIB$$47ae7cb1.add(&lt;generated&gt;) ↵ com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(IotInterfaceParamConfigController.java:88) ↵ com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController$$FastClassBySpringCGLIB$$17aa7ed9.invoke(&lt;generated&gt;) ↵ org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ↵ org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:700) ↵ org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150) ↵ org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:91) ↵ org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) ↵ org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:633) ↵ com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController$$EnhancerBySpringCGLIB$$f44c91c5.save(&lt;generated&gt;) ↵ sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ↵ sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ↵ sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ↵ java.lang.reflect.Method.invoke(Method.java:498) ↵ org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215) ↵ org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132) ↵ org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104) ↵ org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:745) ↵ org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:685) ↵ org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:80) ↵ org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:919) ↵ org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:851) ↵ org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:953) ↵ org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:855) ↵ javax.servlet.http.HttpServlet.service(HttpServlet.java:652) ↵ org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:829) ↵ javax.servlet.http.HttpServlet.service(HttpServlet.java:733) ↵ org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ↵ org.springframework.orm.hibernate4.support.OpenSessionInViewFilter.doFilterInternal(OpenSessionInViewFilter.java:151) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:88) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) ↵根本原因。java.sql.SQLIntegrityConstraintViolationException: ORA-01400: 无法将 NULL 插入 (&quot;UIOTSYSTEM_DEV&quot;.&quot;T_IOT_INTERFACE_PARAM_RULE&quot;.&quot;EFFECTIVE_STATUS&quot;)↵ ↵ oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:439) ↵ oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:395) ↵ oracle.jdbc.driver.T4C8Oall.processError(T4C8Oall.java:802) ↵ oracle.jdbc.driver.T4CTTIfun.receive(T4CTTIfun.java:436) ↵ oracle.jdbc.driver.T4CTTIfun.doRPC(T4CTTIfun.java:186) ↵ oracle.jdbc.driver.T4C8Oall.doOALL(T4C8Oall.java:521) ↵ oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:205) ↵ oracle.jdbc.driver.T4CPreparedStatement.executeForRows(T4CPreparedStatement.java:1008) ↵ oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1307) ↵ oracle.jdbc.driver.OraclePreparedStatement.executeInternal(OraclePreparedStatement.java:3449) ↵ oracle.jdbc.driver.OraclePreparedStatement.execute(OraclePreparedStatement.java:3550) ↵ oracle.jdbc.driver.OraclePreparedStatementWrapper.execute(OraclePreparedStatementWrapper.java:1374) ↵ com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:2931) ↵ com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_execute(FilterEventAdapter.java:440) ↵ com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:2929) ↵ com.alibaba.druid.wall.WallFilter.preparedStatement_execute(WallFilter.java:601) ↵ com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:2929) ↵ com.alibaba.druid.proxy.jdbc.PreparedStatementProxyImpl.execute(PreparedStatementProxyImpl.java:131) ↵ com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493) ↵ sun.reflect.GeneratedMethodAccessor95.invoke(Unknown Source) ↵ sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ↵ java.lang.reflect.Method.invoke(Method.java:498) ↵ org.apache.ibatis.logging.jdbc.PreparedStatementLogger.invoke(PreparedStatementLogger.java:58) ↵ com.sun.proxy.$Proxy124.execute(Unknown Source) ↵ org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:41) ↵ org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:66) ↵ org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:45) ↵ org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:108) ↵ org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:75) ↵ org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:145) ↵ org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:134) ↵ sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ↵ sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ↵ sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ↵ java.lang.reflect.Method.invoke(Method.java:498) ↵ org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:355) ↵ com.sun.proxy.$Proxy26.insert(Unknown Source) ↵ org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:237) ↵ org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:79) ↵ org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:40) ↵ com.sun.proxy.$Proxy167.insertSelective(Unknown Source) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamRuleServiceImpl.insert(IotInterfaceParamRuleServiceImpl.java:59) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl.lambda$saveIotInterfaceParamProperties$1(IotInterfaceParamConfigServiceImpl.java:173) ↵ java.util.ArrayList.forEach(ArrayList.java:1249) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl.saveIotInterfaceParamProperties(IotInterfaceParamConfigServiceImpl.java:167) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl.add(IotInterfaceParamConfigServiceImpl.java:124) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl$$FastClassBySpringCGLIB$$b816365b.invoke(&lt;generated&gt;) ↵ org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ↵ org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:629) ↵ com.web.supplier.interfacemanage.service.impl.IotInterfaceParamConfigServiceImpl$$EnhancerBySpringCGLIB$$47ae7cb1.add(&lt;generated&gt;) ↵ com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController.save(IotInterfaceParamConfigController.java:88) ↵ com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController$$FastClassBySpringCGLIB$$17aa7ed9.invoke(&lt;generated&gt;) ↵ org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ↵ org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:700) ↵ org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150) ↵ org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:91) ↵ org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) ↵ org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:633) ↵ com.web.supplier.interfacemanage.controller.IotInterfaceParamConfigController$$EnhancerBySpringCGLIB$$f44c91c5.save(&lt;generated&gt;) ↵ sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ↵ sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ↵ sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ↵ java.lang.reflect.Method.invoke(Method.java:498) ↵ org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215) ↵ org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132) ↵ org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104) ↵ org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:745) ↵ org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:685) ↵ org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:80) ↵ org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:919) ↵ org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:851) ↵ org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:953) ↵ org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:855) ↵ javax.servlet.http.HttpServlet.service(HttpServlet.java:652) ↵ org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:829) ↵ javax.servlet.http.HttpServlet.service(HttpServlet.java:733) ↵ org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ↵ org.springframework.orm.hibernate4.support.OpenSessionInViewFilter.doFilterInternal(OpenSessionInViewFilter.java:151) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:88) ↵ org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:106) ↵ com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) ↵):注意 主要问题的全部 stack 信息可以在 server logs 里查看Apache Tomcat/8.5.57\" setRequestHeader: ƒ (t,e) state: ƒ () status: 500 statusCode: ƒ (t) statusText: \"error\" success: ƒ () then: ƒ () __proto__: Object "},"各种问题/http/http415问题.html":{"url":"各种问题/http/http415问题.html","title":"http415问题","keywords":"","body":" 1、请求参数 General Reqquest URL: http://localhost:8080/fzsiotcard/api/interfacemanage/iotInterfaceDictReview/add?_=1602662669347 Request Method: POST Status Code: 415 Remote Address: [::1]:8080 Referrer Policy: strict-origin-when-cross-origin Response Headers Connection: keep-alive Content-Language: zh-CN Content-Length: 675 Content-Type: text/html;charset=utf-8 Date: Wed, 14 Oct 2020 08:04:29 GMT Keep-Alive: timeout=20 Request Headers Accept: application/json, text/javascript, */*; q=0.01 Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9 Connection: keep-alive Content-Length: 54 Content-Type: application/x-www-form-urlencoded; charset=UTF-8 Cookie: JSESSIONID=F15DD56D87E5EA271E84A5F7F78BF302; login=P_-DAwEBDkNvb2tpZVJlbWVtYmVyAf-EAAEDAQhNZW1iZXJJZAEEAAEHQWNjb3VudAEMAAEEVGltZQH_hgAAABD_hQUBAQRUaW1lAf-GAAAAHf-EAQIBBWFkbWluAQ8BAAAADtbw0KQ6weScAeAA|1600051620985785500|8b02a18f03f527ff1ba9d83799970afc65e34045 Host: localhost:8080 Origin: http://localhost:8080 Referer: http://localhost:8080/fzsiotcard/api/interfacemanage/iotInterfaceDictContent/init?interfaceDictId=2&categoryName=%E5%B9%B3%E5%8F%B0%E7%B1%BB%E5%88%AB Sec-Fetch-Dest: empty Sec-Fetch-Mode: cors Sec-Fetch-Site: same-origin User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36 X-Requested-With: XMLHttpRequest Query String Parameters _: 1602662669347 Form data dictContentId: interfaceDictId: 2 name: - LiangQingXiang 2、响应结果 HTTP状态 415 - 不支持的媒体类型 类型 状态报告 描述 源服务器拒绝服务请求，因为有效负载的格式在目标资源上此方法不支持。 Apache Tomcat/8.5.57 3、后端 @ResponseBody @RequestMapping(value = \"/add\")//, method = RequestMethod.POST) public ResultBean insert(HttpServletRequest request, HttpServletResponse response, @RequestBody IotInterfaceDictReview record) { ResultBean resultBean = new ResultBean(); iotInterfaceDictReviewService.insert(record); return resultBean; } 4、解决 是后端controller请求参数里里多了个@RequestBody导致的，这个可能是前端以json才需要用这个吧 ``` "},"各种问题/java/指针引用问题和List删除元素.html":{"url":"各种问题/java/指针引用问题和List删除元素.html","title":"指针引用问题和List删除元素","keywords":"","body":" 1、引用对象发生变化导致的问题 如下图：分析此代码有啥问题 分析：看下面的红框处，该方法看起来是没什么大问题，proList传递进来的是个引用， 问题出在第二个红框(该方法是根据proList生成xml文件)处，该同事在第二个红框的代码里拦截掉一部分proList列表里的值， 但是该同事没有对拦截掉的部分进行删除，导致proList这个还是原来的， 而第三个红框该同事又对proList所有对象进行调用api后的返回结果进行设置，注意这里更改的proList包含了 刚才第二个框框里拦截的部分对象，这样就导致有问题,所以第二个框框拦截的时候，也要对proList里拦截的对象进行删除 2、常见删除List里元素的方法 1、使用iterator List list = new ArrayList<>(); list.add(\"aa\"); list.add(\"bb\"); list.add(\"cc\"); Iterator it = list.iterator(); while(it.hasNext()){ String str = (String)it.next(); if(\"aa\".equals(str)){ it.remove(); } } System.out.println(list.size()); 2、倒序(不能正序，否则有数组溢出) List list = new ArrayList<>(); list.add(\"aa\"); list.add(\"bb\"); list.add(\"cc\"); for (int i = list.size() - 1; i >= 0; i--) { String str = list.get(i); if (\"aa\".equals(str)) { list.remove(str); } } System.out.println(list.size()); 3、使用CopyOnWriteArrayList List list = new ArrayList<>(); list.add(\"aa\"); list.add(\"bb\"); list.add(\"cc\"); CopyOnWriteArrayList cowList = new CopyOnWriteArrayList(list); for (String str : cowList) { if (\"aa\".equals(str)) { cowList.remove(str); } } System.out.println(cowList.size()); "},"各种问题/java/hashmap删除问题.html":{"url":"各种问题/java/hashmap删除问题.html","title":"hashmap删除问题","keywords":"","body":" map删除元素 https://blog.csdn.net/qq_43325216/article/details/126555992 ``` "},"各种问题/java/java处理重复请求.html":{"url":"各种问题/java/java处理重复请求.html","title":"java处理重复请求","keywords":"","body":" 问题 h5页面请求生成支付订单时，客户连续点击2次，导致请求了2次，然后后面的请求把前面的请求覆盖了 解决方案 在Java中可以通过以下几种方式来解决重复提交的请求： 1、Token验证机制：每次用户发送请求时生成一个Token并将其返回给客户端。当客户端再次发送相同请求时，需要将之前获取到的Token作为参数传入服务器进行校验。如果Token有效且未被使用过，则处理该请求；否则认定为重复提交的请求。这样可以确保只接收第一次请求而不会对后续重复请求造成影响。 2、限流控制：通过设置合理的请求速度上限、IP地址白名单等手段，限制同一IP地址在特定时间内能够发起多少次请求。超过限制的请求将被视为重复提交的请求。 3、状态标记：在服务器端维护一个状态标记，表明某个操作已经完成。当客户端再次发送相同请求时，先判断该操作是否已经完成，若已完成则直接返回结果，无需再次处理。 4、加密技术：利用加密算法对请求参数进行加密，然后与服务器端计算得到的值进行比对。如果两者一致，则说明请求没有被修改过，可以正常处理；反之则认定为重复提交的请求。 5、双重提交检测：在页面中添加一个隐藏字段，用于存放一个令牌（Token）。当用户点击提交按钮时，首先向服务器发送一个Ajax请求，服务器根据该令牌判断是否已经处理了此请求。如果还未处理，则更新令牌并处理请求；如果已经处理，则告知客户端重复提交。 6、分布式锁：使用分布式锁来保证同一时间只有一台服务器能够处理某个请求。其他服务器在处理该请求时会被阻塞，从而达到避免重复提交的目的。 注意事项： 在开发Web应用程序时，建议始终验证所有输入数据，包括请求参数和Cookie等，以防止安全性问题。 在处理重复提交的情况下，最好显示友好的错误消息给用户，以避免用户因为重复提交导致的困惑。 ``` "},"各种问题/java/java指针引用问题.html":{"url":"各种问题/java/java指针引用问题.html","title":"java指针引用问题","keywords":"","body":" 1、java指针引用问题 如下图：分析此代码有啥问题 TParkingCommentConfig tParkingCommentConfig = tParkingCommentConfigMapper.selectOne(new QueryWrapper() .lambda().eq(TParkingCommentConfig::getChannelId, channelId)); TParkingCommentConfig oldParkingCommentConfig =tParkingCommentConfig; if (tParkingCommentConfig == null) { tParkingCommentConfig = new TParkingCommentConfig(); tParkingCommentConfig.setId(ObjectId.id()); tParkingCommentConfig.setDefaultCommentLevel(query.getDefaultCommentLevel()); tParkingCommentConfig.setOverTime(query.getOverTime()); tParkingCommentConfig.setStatus(query.getStatus()); tParkingCommentConfig.setCreateTime(LocalDateTime.now()); tParkingCommentConfig.setCreator(user.getName()); tParkingCommentConfig.setChannelId(channelId); tParkingCommentConfigMapper.insert(tParkingCommentConfig); type = \"新增\"; } else { Integer oldOverTime = tParkingCommentConfig.getOverTime(); if(CommentEnum.STATUS.OFF.getCode().equals(tParkingCommentConfig.getParkingCommentStatus()) && CommentEnum.STATUS.OPEN.getCode().equals(query.getStatus())){ throw new BusinessException(\"停车评价关闭中，不能开启自动评价\"); } tParkingCommentConfig.setDefaultCommentLevel(query.getDefaultCommentLevel()); tParkingCommentConfig.setOverTime(query.getOverTime()); tParkingCommentConfig.setStatus(query.getStatus()); tParkingCommentConfig.setUpdater(user.getName()); tParkingCommentConfig.setUpdateTime(LocalDateTime.now()); tParkingCommentConfigMapper.updateById(tParkingCommentConfig); if((query.getOverTime()-oldOverTime){ List linkList = configLinkParkingMapper.selectList(new QueryWrapper().eq(\"comment_config_id\",tParkingCommentConfig.getId())); if (CollectionUtils.isEmpty(linkList)){ return; } linkList.forEach(link ->{ LocalDateTime dateTime = LocalDateTime.now(); dateTime = dateTime.minus(tParkingCommentConfig.getOverTime(), ChronoUnit.DAYS); String commentDateStart = DateUtil.getFormatLocalDateTime(DateUtil.YMD, dateTime); String startDate=commentDateStart; LocalDateTime dateTime2 = LocalDateTime.now(); dateTime2 = dateTime2.minus(query.getOverTime(), ChronoUnit.DAYS); String commentDateEnd = DateUtil.getFormatLocalDateTime(DateUtil.YMD, dateTime2); String endDate=commentDateEnd; findNeedCommentCarLog(link.getParkingId(), startDate,endDate, tParkingCommentConfig.getDefaultCommentLevel()); }); }); t1.setName(\"asyncAutoComment\"); t1.start(); } catch (Exception e) { log.info(\"异步保存自动生成评论失败:\",e); } } 解答： TParkingCommentConfig oldParkingCommentConfig =tParkingCommentConfig; 这行代码赋值到旧的对象是没法赋值的，只要tParkingCommentConfig变了，oldParkingCommentConfig就会变， 所以要新建个新的TParkingCommentConfig对象，然后把内容复制过去. "},"各种问题/mybatis-plus/mybatis-plus无法更新空值问题.html":{"url":"各种问题/mybatis-plus/mybatis-plus无法更新空值问题.html","title":"mybatis-plus无法更新空值问题","keywords":"","body":" Mybatis-Plus中updateById方法不能更新空值问题 ``` "},"各种问题/springboot/springboot排除数据源自动装配失效问题.html":{"url":"各种问题/springboot/springboot排除数据源自动装配失效问题.html","title":"springboot排除数据源自动装配失效问题","keywords":"","body":" 1、问题描述 当springboot项目不需要连接数据库，当properties或yml文件没有配spring.datasource.url等数据库连接信息时，由于springboot会自动装配，将数据源自动加载进来， 所以得把数据源自动装配的去掉，否则会报错 2020-09-10 19:35:47.810 INFO 11356 --- [ main] com.fzs.iotcard.FzsIotCardApplication : Starting FzsIotCardApplication on LAPTOP-6VJBADD9 with PID 11356 (D:\\idea-workspace3\\lqx-project-demo-github\\fzs_iot_card2\\target\\classes started by hoby in D:\\idea-workspace3\\lqx-project-demo-github) 2020-09-10 19:35:47.815 INFO 11356 --- [ main] com.fzs.iotcard.FzsIotCardApplication : The following profiles are active: local 2020-09-10 19:35:56.373 WARN 11356 --- [ main] o.m.s.mapper.ClassPathMapperScanner : No MyBatis mapper was found in '[com.fzs.iotcard]' package. Please check your configuration. 2020-09-10 19:35:56.484 INFO 11356 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode! 2020-09-10 19:35:56.486 INFO 11356 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode. 2020-09-10 19:35:56.536 INFO 11356 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 19ms. Found 0 repository interfaces. 2020-09-10 19:35:57.018 INFO 11356 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$dfe19409] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-09-10 19:35:57.615 INFO 11356 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 2020-09-10 19:35:57.658 INFO 11356 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2020-09-10 19:35:57.658 INFO 11356 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.21] 2020-09-10 19:35:57.874 INFO 11356 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 2020-09-10 19:35:57.874 INFO 11356 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 6290 ms 2020-09-10 19:35:58.394 INFO 11356 --- [ main] pertySourcedRequestMappingHandlerMapping : Mapped URL path [/v2/api-docs] onto method [public org.springframework.http.ResponseEntity springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)] 2020-09-10 19:35:58.554 INFO 11356 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor' 2020-09-10 19:35:58.735 INFO 11356 --- [ main] c.a.d.s.b.a.DruidDataSourceAutoConfigure : Init DruidDataSource 2020-09-10 19:35:58.820 WARN 11356 --- [ main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/alibaba/druid/spring/boot/autoconfigure/DruidDataSourceAutoConfigure.class]: Invocation of init method failed; nested exception is org.springframework.boot.autoconfigure.jdbc.DataSourceProperties$DataSourceBeanCreationException: Failed to determine a suitable driver class 2020-09-10 19:35:58.821 INFO 11356 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Shutting down ExecutorService 'applicationTaskExecutor' 2020-09-10 19:35:58.824 INFO 11356 --- [ main] o.apache.catalina.core.StandardService : Stopping service [Tomcat] 2020-09-10 19:35:58.919 INFO 11356 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2020-09-10 19:35:58.923 ERROR 11356 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter : *************************** APPLICATION FAILED TO START *************************** Description: Failed to configure a DataSource: 'url' attribute is not specified and no embedded datasource could be configured. Reason: Failed to determine a suitable driver class Action: Consider the following: If you want an embedded database (H2, HSQL or Derby), please put it on the classpath. If you have database settings to be loaded from a particular profile you may need to activate it (no profiles are currently active). Process finished with exit code 1 2、问题分析 参考了网上把下面DataSourceAutoConfiguration.class, HibernateJpaAutoConfiguration.class进行了排除 @SpringBootApplication(exclude = {DataSourceAutoConfiguration.class, HibernateJpaAutoConfiguration.class) 但是排除掉后还是报相同的错，网上搜索了都不行然后自己仔细看打印的日志，发现有行 2020-09-10 19:35:58.735 INFO 11356 --- [ main] c.a.d.s.b.a.DruidDataSourceAutoConfigure : Init DruidDataSource 然后网上一搜DruidDataSourceAutoConfigure发现springboot也会默认装置druid的数据源，所以得把这个也排除掉 DruidDataSourceAutoConfigure源码如下: @Configuration @ConditionalOnClass(DruidDataSource.class) @AutoConfigureBefore(DataSourceAutoConfiguration.class) @EnableConfigurationProperties({DruidStatProperties.class, DataSourceProperties.class}) @Import({DruidSpringAopConfiguration.class, DruidStatViewServletConfiguration.class, DruidWebStatFilterConfiguration.class, DruidFilterConfiguration.class}) public class DruidDataSourceAutoConfigure { private static final Logger LOGGER = LoggerFactory.getLogger(DruidDataSourceAutoConfigure.class); @Bean(initMethod = \"init\") @ConditionalOnMissingBean public DataSource dataSource() { LOGGER.info(\"Init DruidDataSource\"); return new DruidDataSourceWrapper(); } } 当代码中缺失不配置DataSource就会默认创建一个DataSource，具体又是创建DruidDataSourceWrapper，而DruidDataSourceWrapper定义如下： @ConfigurationProperties(\"spring.datasource.druid\") class DruidDataSourceWrapper extends DruidDataSource implements InitializingBean { 看到这里是依赖了spring.datasource.druid相关的druid配置，所以得把DruidDataSourceAutoConfigure也排除掉 3、问题解决 同时把DataSourceAutoConfiguration.class, HibernateJpaAutoConfiguration.class, DruidDataSourceAutoConfigure.class 这3个排除掉即可 @SpringBootApplication(exclude = {DataSourceAutoConfiguration.class, HibernateJpaAutoConfiguration.class, DruidDataSourceAutoConfigure.class}) @EnableSwagger2 public class FzsIotCardApplication { public static void main(String[] args) { SpringApplication app = new SpringApplication(FzsIotCardApplication.class); app.setBannerMode(Banner.Mode.OFF); app.run(args); } } 或者把pom中的druid-spring-boot-starter去掉，DruidDataSourceAutoConfigure是存在这个包里的 com.alibaba druid-spring-boot-starter ${druid.starter.version} 参考： https://blog.csdn.net/superyu1992/article/details/80336928 "},"各种问题/springboot/springboot配置属性DataSource问题.html":{"url":"各种问题/springboot/springboot配置属性DataSource问题.html","title":"springboot配置属性DataSource问题","keywords":"","body":" 今天发现服务器内存彪升，如下： 查找日志发现报错： Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is com.alibaba.druid.pool.GetConnectionTimeoutException: wait millis 7217, active 8, maxActive 8, creating 0, runningSqlCount 2 分析日志应该是线程数不够，默认是8，重新设置为30，如下： spring.datasource.max-active=30 另外常见DataSource配置如下： spring.dao.exceptiontranslation.enabled是否开启PersistenceExceptionTranslationPostProcessor，默认为true spring.datasource.abandon-when-percentage-full设定超时被废弃的连接占到多少比例时要被关闭或上报 spring.datasource.allow-pool-suspension使用Hikari pool时，是否允许连接池暂停，默认为: false spring.datasource.alternate-username-allowed是否允许替代的用户名. spring.datasource.auto-commit指定updates是否自动提交. spring.datasource.catalog指定默认的catalog. spring.datasource.commit-on-return设置当连接被归还时，是否要提交所有还未完成的事务 spring.datasource.connection-init-sql指定连接被创建，再被添加到连接池之前执行的sql. spring.datasource.connection-init-sqls使用DBCP connection pool时，指定初始化时要执行的sql spring.datasource.connection-properties.[key]在使用DBCP connection pool时指定要配置的属性 spring.datasource.connection-test-query指定校验连接合法性执行的sql语句 spring.datasource.connection-timeout指定连接的超时时间，毫秒单位. spring.datasource.continue-on-error在初始化数据库时，遇到错误是否继续，默认false spring.datasource.data指定Data (DML)脚本 spring.datasource.data-source-class-name指定数据源的全限定名. spring.datasource.data-source-jndi指定jndi的地址 spring.datasource.data-source-properties.[key]使用Hikari connection pool时，指定要设置的属性 spring.datasource.db-properties使用Tomcat connection pool，指定要设置的属性 spring.datasource.default-auto-commit是否自动提交. spring.datasource.default-catalog指定连接默认的catalog. spring.datasource.default-read-only是否设置默认连接只读. spring.datasource.default-transaction-isolation指定连接的事务的默认隔离级别. spring.datasource.driver-class-name指定driver的类名，默认从jdbc url中自动探测. spring.datasource.fair-queue是否采用FIFO返回连接. spring.datasource.health-check-properties.[key]使用Hikari connection pool时，在心跳检查时传递的属性 spring.datasource.idle-timeout指定连接多久没被使用时，被设置为空闲，默认为10ms spring.datasource.ignore-exception-on-pre-load当初始化连接池时，是否忽略异常. spring.datasource.init-sql当连接创建时，执行的sql spring.datasource.initial-size指定启动连接池时，初始建立的连接数量 spring.datasource.initialization-fail-fast当创建连接池时，没法创建指定最小连接数量是否抛异常 spring.datasource.initialize指定初始化数据源，是否用data.sql来初始化，默认: true spring.datasource.isolate-internal-queries指定内部查询是否要被隔离，默认为false spring.datasource.jdbc-interceptors使用Tomcat connection pool时，指定jdbc拦截器，分号分隔 spring.datasource.jdbc-url指定JDBC URL. spring.datasource.jmx-enabled是否开启JMX，默认为: false spring.datasource.jndi-name指定jndi的名称. spring.datasource.leak-detection-threshold使用Hikari connection pool时，多少毫秒检测一次连接泄露. spring.datasource.log-abandoned使用DBCP connection pool，是否追踪废弃statement或连接，默认为: false spring.datasource.log-validation-errors当使用Tomcat connection pool是否打印校验错误. spring.datasource.login-timeout指定连接数据库的超时时间. spring.datasource.max-active指定连接池中最大的活跃连接数. spring.datasource.max-age指定连接池中连接的最大年龄 spring.datasource.max-idle指定连接池最大的空闲连接数量. spring.datasource.max-lifetime指定连接池中连接的最大生存时间，毫秒单位. spring.datasource.max-open-prepared-statements指定最大的打开的prepared statements数量. spring.datasource.max-wait指定连接池等待连接返回的最大等待时间，毫秒单位. spring.datasource.maximum-pool-size指定连接池最大的连接数，包括使用中的和空闲的连接. spring.datasource.min-evictable-idle-time-millis指定一个空闲连接最少空闲多久后可被清除. spring.datasource.min-idle指定必须保持连接的最小值(For DBCP and Tomcat connection pools) spring.datasource.minimum-idle指定连接维护的最小空闲连接数，当使用HikariCP时指定. spring.datasource.name指定数据源名. spring.datasource.num-tests-per-eviction-run指定运行每个idle object evictor线程时的对象数量 spring.datasource.password指定数据库密码. spring.datasource.platform指定schema要使用的Platform(schema-${platform}.sql)，默认为: all spring.datasource.pool-name指定连接池名字. spring.datasource.pool-prepared-statements指定是否池化statements. spring.datasource.propagate-interrupt-state在等待连接时，如果线程被中断，是否传播中断状态. spring.datasource.read-only当使用Hikari connection pool时，是否标记数据源只读 spring.datasource.register-mbeans指定Hikari connection pool是否注册JMX MBeans. spring.datasource.remove-abandoned指定当连接超过废弃超时时间时，是否立刻删除该连接. spring.datasource.remove-abandoned-timeout指定连接应该被废弃的时间. spring.datasource.rollback-on-return在归还连接时，是否回滚等待中的事务. spring.datasource.schema指定Schema (DDL)脚本. spring.datasource.separator指定初始化脚本的语句分隔符，默认: ; spring.datasource.sql-script-encoding指定SQL scripts编码. spring.datasource.suspect-timeout指定打印废弃连接前的超时时间. spring.datasource.test-on-borrow当从连接池借用连接时，是否测试该连接. spring.datasource.test-on-connect创建时，是否测试连接 spring.datasource.test-on-return在连接归还到连接池时是否测试该连接. spring.datasource.test-while-idle当连接空闲时，是否执行连接测试. spring.datasource.time-between-eviction-runs-millis指定空闲连接检查、废弃连接清理、空闲连接池大小调整之间的操作时间间隔 spring.datasource.transaction-isolation指定事务隔离级别，使用Hikari connection pool时指定 spring.datasource.url指定JDBC URL. spring.datasource.use-disposable-connection-facade是否对连接进行包装，防止连接关闭之后被使用. spring.datasource.use-equals比较方法名时是否使用String.equals()替换==. spring.datasource.use-lock是否对连接操作加锁 spring.datasource.username指定数据库名. spring.datasource.validation-interval指定多少ms执行一次连接校验. spring.datasource.validation-query指定获取连接时连接校验的sql查询语句. spring.datasource.validation-query-timeout指定连接校验查询的超时时间. spring.datasource.validation-timeout设定连接校验的超时时间，当使用Hikari connection pool时指定 spring.datasource.validator-class-name用来测试查询的validator全限定名. spring.datasource.xa.data-source-class-name指定数据源的全限定名. spring.datasource.xa.properties指定传递给XA data source的属性 "},"各种问题/springboot/springboot启动问题.html":{"url":"各种问题/springboot/springboot启动问题.html","title":"springboot启动问题","keywords":"","body":" Error:(3, 32) java: 无法访问org.springframework.boot.SpringApplication springboot 3.0.0版本，jdk8 可能2者版本不兼容，降低springboot版本即可 https://blog.csdn.net/Lcynsyw/article/details/128123459 Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2022-12-14 19:07:46.918 ERROR 21432 --- [ restartedMain] o.s.b.d.LoggingFailureAnalysisReporter : *************************** APPLICATION FAILED TO START *************************** Description: Failed to configure a DataSource: 'url' attribute is not specified and no embedded datasource could be configured. Reason: Failed to determine a suitable driver class Action: Consider the following: If you want an embedded database (H2, HSQL or Derby), please put it on the classpath. If you have database settings to be loaded from a particular profile you may need to activate it (no profiles are currently active). Process finished with exit code 0 要像下面排除数据源自动装配的才行 @SpringBootApplication(exclude= {DataSourceAutoConfiguration.class}) 应该是引入了下面自动装配的jar org.springframework.boot spring-boot-configuration-processor true https://blog.csdn.net/m0_51660523/article/details/117563226 https://blog.csdn.net/qq_40223688/article/details/88191732 ``` "},"各种问题/springboot/springboot日志问题.html":{"url":"各种问题/springboot/springboot日志问题.html","title":"springboot日志问题","keywords":"","body":" 1、springboot启动报日志错误问题 \"D:\\Program Files\\Java8\\jdk1.8.0_77\\bin\\java.exe\" -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:58693,suspend=y,server=n -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -javaagent:C:\\Users\\Administrator\\.IntelliJIdea2019.2\\system\\captureAgent\\debugger-agent.jar -Dfile.encoding=UTF-8 -classpath \"D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\charsets.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\deploy.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\access-bridge-64.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\cldrdata.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\dnsns.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\jaccess.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\jfxrt.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\localedata.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\nashorn.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\sunec.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\sunjce_provider.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\sunmscapi.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\sunpkcs11.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\ext\\zipfs.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\javaws.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\jce.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\jfr.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\jfxswt.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\jsse.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\management-agent.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\plugin.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\resources.jar;D:\\Program Files\\Java8\\jdk1.8.0_77\\jre\\lib\\rt.jar;D:\\2\\lqx-project-demo\\basic-server\\target\\classes;D:\\2\\lqx-project-demo\\demo\\search\\elasticsearch-starter\\target\\classes;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-autoconfigure\\2.1.6.RELEASE\\spring-boot-autoconfigure-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-configuration-processor\\2.1.6.RELEASE\\spring-boot-configuration-processor-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-json\\2.1.6.RELEASE\\spring-boot-starter-json-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-web\\5.1.8.RELEASE\\spring-web-5.1.8.RELEASE.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\datatype\\jackson-datatype-jdk8\\2.9.9\\jackson-datatype-jdk8-2.9.9.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\datatype\\jackson-datatype-jsr310\\2.9.9\\jackson-datatype-jsr310-2.9.9.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\module\\jackson-module-parameter-names\\2.9.9\\jackson-module-parameter-names-2.9.9.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-data-jpa\\2.1.6.RELEASE\\spring-boot-starter-data-jpa-2.1.6.RELEASE.jar;D:\\maven\\repository\\javax\\transaction\\javax.transaction-api\\1.3\\javax.transaction-api-1.3.jar;D:\\maven\\repository\\javax\\xml\\bind\\jaxb-api\\2.3.1\\jaxb-api-2.3.1.jar;D:\\maven\\repository\\javax\\activation\\javax.activation-api\\1.2.0\\javax.activation-api-1.2.0.jar;D:\\maven\\repository\\org\\hibernate\\hibernate-core\\5.3.10.Final\\hibernate-core-5.3.10.Final.jar;D:\\maven\\repository\\org\\jboss\\logging\\jboss-logging\\3.3.2.Final\\jboss-logging-3.3.2.Final.jar;D:\\maven\\repository\\antlr\\antlr\\2.7.7\\antlr-2.7.7.jar;D:\\maven\\repository\\org\\jboss\\jandex\\2.0.5.Final\\jandex-2.0.5.Final.jar;D:\\maven\\repository\\org\\dom4j\\dom4j\\2.1.1\\dom4j-2.1.1.jar;D:\\maven\\repository\\org\\hibernate\\common\\hibernate-commons-annotations\\5.0.4.Final\\hibernate-commons-annotations-5.0.4.Final.jar;D:\\maven\\repository\\org\\springframework\\data\\spring-data-jpa\\2.1.9.RELEASE\\spring-data-jpa-2.1.9.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\data\\spring-data-commons\\2.1.9.RELEASE\\spring-data-commons-2.1.9.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-orm\\5.1.8.RELEASE\\spring-orm-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-aspects\\5.1.8.RELEASE\\spring-aspects-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-web\\2.1.6.RELEASE\\spring-boot-starter-web-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-tomcat\\2.1.6.RELEASE\\spring-boot-starter-tomcat-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\apache\\tomcat\\embed\\tomcat-embed-core\\9.0.21\\tomcat-embed-core-9.0.21.jar;D:\\maven\\repository\\org\\apache\\tomcat\\embed\\tomcat-embed-el\\9.0.21\\tomcat-embed-el-9.0.21.jar;D:\\maven\\repository\\org\\apache\\tomcat\\embed\\tomcat-embed-websocket\\9.0.21\\tomcat-embed-websocket-9.0.21.jar;D:\\maven\\repository\\org\\hibernate\\validator\\hibernate-validator\\6.0.17.Final\\hibernate-validator-6.0.17.Final.jar;D:\\maven\\repository\\javax\\validation\\validation-api\\2.0.1.Final\\validation-api-2.0.1.Final.jar;D:\\maven\\repository\\org\\springframework\\spring-webmvc\\5.1.8.RELEASE\\spring-webmvc-5.1.8.RELEASE.jar;D:\\maven\\repository\\commons-codec\\commons-codec\\1.12\\commons-codec-1.12.jar;D:\\maven\\repository\\io\\springfox\\springfox-swagger2\\2.7.0\\springfox-swagger2-2.7.0.jar;D:\\maven\\repository\\io\\swagger\\swagger-annotations\\1.5.13\\swagger-annotations-1.5.13.jar;D:\\maven\\repository\\io\\swagger\\swagger-models\\1.5.13\\swagger-models-1.5.13.jar;D:\\maven\\repository\\io\\springfox\\springfox-spi\\2.7.0\\springfox-spi-2.7.0.jar;D:\\maven\\repository\\io\\springfox\\springfox-core\\2.7.0\\springfox-core-2.7.0.jar;D:\\maven\\repository\\io\\springfox\\springfox-schema\\2.7.0\\springfox-schema-2.7.0.jar;D:\\maven\\repository\\io\\springfox\\springfox-swagger-common\\2.7.0\\springfox-swagger-common-2.7.0.jar;D:\\maven\\repository\\io\\springfox\\springfox-spring-web\\2.7.0\\springfox-spring-web-2.7.0.jar;D:\\maven\\repository\\org\\reflections\\reflections\\0.9.11\\reflections-0.9.11.jar;D:\\maven\\repository\\com\\google\\guava\\guava\\18.0\\guava-18.0.jar;D:\\maven\\repository\\com\\fasterxml\\classmate\\1.4.0\\classmate-1.4.0.jar;D:\\maven\\repository\\org\\springframework\\plugin\\spring-plugin-core\\1.2.0.RELEASE\\spring-plugin-core-1.2.0.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\plugin\\spring-plugin-metadata\\1.2.0.RELEASE\\spring-plugin-metadata-1.2.0.RELEASE.jar;D:\\maven\\repository\\org\\mapstruct\\mapstruct\\1.1.0.Final\\mapstruct-1.1.0.Final.jar;D:\\maven\\repository\\io\\springfox\\springfox-swagger-ui\\2.7.0\\springfox-swagger-ui-2.7.0.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-log4j\\1.3.5.RELEASE\\spring-boot-starter-log4j-1.3.5.RELEASE.jar;D:\\maven\\repository\\org\\slf4j\\slf4j-log4j12\\1.7.26\\slf4j-log4j12-1.7.26.jar;D:\\maven\\repository\\log4j\\log4j\\1.2.17\\log4j-1.2.17.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-data-redis\\2.1.6.RELEASE\\spring-boot-starter-data-redis-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\data\\spring-data-redis\\2.1.9.RELEASE\\spring-data-redis-2.1.9.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\data\\spring-data-keyvalue\\2.1.9.RELEASE\\spring-data-keyvalue-2.1.9.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-oxm\\5.1.8.RELEASE\\spring-oxm-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-context-support\\5.1.8.RELEASE\\spring-context-support-5.1.8.RELEASE.jar;D:\\maven\\repository\\io\\lettuce\\lettuce-core\\5.1.7.RELEASE\\lettuce-core-5.1.7.RELEASE.jar;D:\\maven\\repository\\com\\alibaba\\fastjson\\1.2.44\\fastjson-1.2.44.jar;D:\\maven\\repository\\org\\apache\\httpcomponents\\httpclient\\4.4.1\\httpclient-4.4.1.jar;D:\\maven\\repository\\org\\apache\\httpcomponents\\httpcore\\4.4.11\\httpcore-4.4.11.jar;D:\\maven\\repository\\com\\google\\code\\gson\\gson\\2.8.5\\gson-2.8.5.jar;D:\\maven\\repository\\org\\elasticsearch\\elasticsearch\\6.4.3\\elasticsearch-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\elasticsearch-core\\6.4.3\\elasticsearch-core-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\elasticsearch-secure-sm\\6.4.3\\elasticsearch-secure-sm-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\elasticsearch-x-content\\6.4.3\\elasticsearch-x-content-6.4.3.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\dataformat\\jackson-dataformat-smile\\2.9.9\\jackson-dataformat-smile-2.9.9.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\dataformat\\jackson-dataformat-cbor\\2.9.9\\jackson-dataformat-cbor-2.9.9.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-core\\7.4.0\\lucene-core-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-analyzers-common\\7.4.0\\lucene-analyzers-common-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-backward-codecs\\7.4.0\\lucene-backward-codecs-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-grouping\\7.4.0\\lucene-grouping-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-highlighter\\7.4.0\\lucene-highlighter-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-join\\7.4.0\\lucene-join-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-memory\\7.4.0\\lucene-memory-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-misc\\7.4.0\\lucene-misc-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-queries\\7.4.0\\lucene-queries-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-queryparser\\7.4.0\\lucene-queryparser-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-sandbox\\7.4.0\\lucene-sandbox-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-spatial\\7.4.0\\lucene-spatial-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-spatial-extras\\7.4.0\\lucene-spatial-extras-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-spatial3d\\7.4.0\\lucene-spatial3d-7.4.0.jar;D:\\maven\\repository\\org\\apache\\lucene\\lucene-suggest\\7.4.0\\lucene-suggest-7.4.0.jar;D:\\maven\\repository\\org\\elasticsearch\\elasticsearch-cli\\6.4.3\\elasticsearch-cli-6.4.3.jar;D:\\maven\\repository\\net\\sf\\jopt-simple\\jopt-simple\\5.0.2\\jopt-simple-5.0.2.jar;D:\\maven\\repository\\com\\carrotsearch\\hppc\\0.7.1\\hppc-0.7.1.jar;D:\\maven\\repository\\joda-time\\joda-time\\2.10.2\\joda-time-2.10.2.jar;D:\\maven\\repository\\com\\tdunning\\t-digest\\3.2\\t-digest-3.2.jar;D:\\maven\\repository\\org\\hdrhistogram\\HdrHistogram\\2.1.9\\HdrHistogram-2.1.9.jar;D:\\maven\\repository\\org\\apache\\logging\\log4j\\log4j-api\\2.11.2\\log4j-api-2.11.2.jar;D:\\maven\\repository\\org\\elasticsearch\\jna\\4.5.1\\jna-4.5.1.jar;D:\\maven\\repository\\org\\elasticsearch\\client\\rest\\6.0.0-alpha1\\rest-6.0.0-alpha1.jar;D:\\maven\\repository\\org\\apache\\httpcomponents\\httpasyncclient\\4.1.4\\httpasyncclient-4.1.4.jar;D:\\maven\\repository\\org\\apache\\httpcomponents\\httpcore-nio\\4.4.11\\httpcore-nio-4.4.11.jar;D:\\maven\\repository\\org\\elasticsearch\\client\\elasticsearch-rest-high-level-client\\6.4.3\\elasticsearch-rest-high-level-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\client\\elasticsearch-rest-client\\6.4.3\\elasticsearch-rest-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\parent-join-client\\6.4.3\\parent-join-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\aggs-matrix-stats-client\\6.4.3\\aggs-matrix-stats-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\rank-eval-client\\6.4.3\\rank-eval-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\lang-mustache-client\\6.4.3\\lang-mustache-client-6.4.3.jar;D:\\maven\\repository\\com\\github\\spullara\\mustache\\java\\compiler\\0.9.3\\compiler-0.9.3.jar;D:\\maven\\repository\\org\\elasticsearch\\client\\transport\\6.4.3\\transport-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\reindex-client\\6.4.3\\reindex-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\percolator-client\\6.4.3\\percolator-client-6.4.3.jar;D:\\maven\\repository\\org\\elasticsearch\\plugin\\transport-netty4-client\\6.4.3\\transport-netty4-client-6.4.3.jar;D:\\maven\\repository\\io\\netty\\netty-codec-http\\4.1.36.Final\\netty-codec-http-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-resolver\\4.1.36.Final\\netty-resolver-4.1.36.Final.jar;D:\\maven\\repository\\org\\ansj\\ansj_seg\\5.1.1\\ansj_seg-5.1.1.jar;D:\\maven\\repository\\org\\nlpcn\\nlp-lang\\1.7.2\\nlp-lang-1.7.2.jar;D:\\maven\\repository\\org\\apache\\httpcomponents\\httpmime\\4.5.6\\httpmime-4.5.6.jar;D:\\maven\\repository\\org\\jsoup\\jsoup\\1.11.2\\jsoup-1.11.2.jar;D:\\maven\\repository\\javax\\servlet\\javax.servlet-api\\4.0.1\\javax.servlet-api-4.0.1.jar;D:\\maven\\repository\\javax\\persistence\\javax.persistence-api\\2.2\\javax.persistence-api-2.2.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-core\\1.4.0\\shiro-core-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-lang\\1.4.0\\shiro-lang-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-cache\\1.4.0\\shiro-cache-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-crypto-hash\\1.4.0\\shiro-crypto-hash-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-crypto-core\\1.4.0\\shiro-crypto-core-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-crypto-cipher\\1.4.0\\shiro-crypto-cipher-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-config-core\\1.4.0\\shiro-config-core-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-config-ogdl\\1.4.0\\shiro-config-ogdl-1.4.0.jar;D:\\maven\\repository\\commons-beanutils\\commons-beanutils\\1.9.3\\commons-beanutils-1.9.3.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-event\\1.4.0\\shiro-event-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-web\\1.4.0\\shiro-web-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-spring\\1.4.0\\shiro-spring-1.4.0.jar;D:\\maven\\repository\\org\\apache\\shiro\\shiro-ehcache\\1.4.0\\shiro-ehcache-1.4.0.jar;D:\\maven\\repository\\net\\sf\\ehcache\\ehcache-core\\2.6.11\\ehcache-core-2.6.11.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-amqp\\2.1.6.RELEASE\\spring-boot-starter-amqp-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-messaging\\5.1.8.RELEASE\\spring-messaging-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-beans\\5.1.8.RELEASE\\spring-beans-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\amqp\\spring-rabbit\\2.1.7.RELEASE\\spring-rabbit-2.1.7.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\amqp\\spring-amqp\\2.1.7.RELEASE\\spring-amqp-2.1.7.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\retry\\spring-retry\\1.2.4.RELEASE\\spring-retry-1.2.4.RELEASE.jar;D:\\maven\\repository\\com\\rabbitmq\\amqp-client\\5.4.3\\amqp-client-5.4.3.jar;D:\\maven\\repository\\org\\springframework\\spring-tx\\5.1.8.RELEASE\\spring-tx-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\projectlombok\\lombok\\1.16.10\\lombok-1.16.10.jar;D:\\maven\\repository\\org\\redisson\\redisson\\3.11.2\\redisson-3.11.2.jar;D:\\maven\\repository\\io\\netty\\netty-common\\4.1.36.Final\\netty-common-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-codec\\4.1.36.Final\\netty-codec-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-buffer\\4.1.36.Final\\netty-buffer-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-transport\\4.1.36.Final\\netty-transport-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-resolver-dns\\4.1.36.Final\\netty-resolver-dns-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-codec-dns\\4.1.36.Final\\netty-codec-dns-4.1.36.Final.jar;D:\\maven\\repository\\io\\netty\\netty-handler\\4.1.36.Final\\netty-handler-4.1.36.Final.jar;D:\\maven\\repository\\javax\\cache\\cache-api\\1.1.1\\cache-api-1.1.1.jar;D:\\maven\\repository\\io\\projectreactor\\reactor-core\\3.2.10.RELEASE\\reactor-core-3.2.10.RELEASE.jar;D:\\maven\\repository\\org\\reactivestreams\\reactive-streams\\1.0.2\\reactive-streams-1.0.2.jar;D:\\maven\\repository\\io\\reactivex\\rxjava2\\rxjava\\2.2.9\\rxjava-2.2.9.jar;D:\\maven\\repository\\de\\ruedigermoeller\\fst\\2.57\\fst-2.57.jar;D:\\maven\\repository\\org\\javassist\\javassist\\3.21.0-GA\\javassist-3.21.0-GA.jar;D:\\maven\\repository\\org\\objenesis\\objenesis\\2.5.1\\objenesis-2.5.1.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\dataformat\\jackson-dataformat-yaml\\2.9.9\\jackson-dataformat-yaml-2.9.9.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\core\\jackson-core\\2.9.9\\jackson-core-2.9.9.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\core\\jackson-databind\\2.9.9\\jackson-databind-2.9.9.jar;D:\\maven\\repository\\com\\fasterxml\\jackson\\core\\jackson-annotations\\2.9.0\\jackson-annotations-2.9.0.jar;D:\\maven\\repository\\net\\bytebuddy\\byte-buddy\\1.9.13\\byte-buddy-1.9.13.jar;D:\\maven\\repository\\org\\jodd\\jodd-bean\\5.0.10\\jodd-bean-5.0.10.jar;D:\\maven\\repository\\org\\jodd\\jodd-core\\5.0.10\\jodd-core-5.0.10.jar;D:\\maven\\repository\\org\\redisson\\redisson-spring-boot-starter\\3.11.2\\redisson-spring-boot-starter-3.11.2.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-actuator\\2.1.6.RELEASE\\spring-boot-starter-actuator-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-actuator-autoconfigure\\2.1.6.RELEASE\\spring-boot-actuator-autoconfigure-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-actuator\\2.1.6.RELEASE\\spring-boot-actuator-2.1.6.RELEASE.jar;D:\\maven\\repository\\io\\micrometer\\micrometer-core\\1.1.5\\micrometer-core-1.1.5.jar;D:\\maven\\repository\\org\\latencyutils\\LatencyUtils\\2.0.3\\LatencyUtils-2.0.3.jar;D:\\maven\\repository\\org\\redisson\\redisson-spring-data-21\\3.11.2\\redisson-spring-data-21-3.11.2.jar;D:\\maven\\repository\\org\\apache\\poi\\poi\\4.0.0\\poi-4.0.0.jar;D:\\maven\\repository\\org\\apache\\poi\\poi-ooxml\\4.0.0\\poi-ooxml-4.0.0.jar;D:\\maven\\repository\\org\\apache\\poi\\poi-ooxml-schemas\\4.0.0\\poi-ooxml-schemas-4.0.0.jar;D:\\maven\\repository\\org\\apache\\xmlbeans\\xmlbeans\\3.0.1\\xmlbeans-3.0.1.jar;D:\\maven\\repository\\org\\apache\\commons\\commons-compress\\1.18\\commons-compress-1.18.jar;D:\\maven\\repository\\com\\github\\virtuald\\curvesapi\\1.04\\curvesapi-1.04.jar;D:\\maven\\repository\\com\\xuxueli\\xxl-job-core\\1.8.2\\xxl-job-core-1.8.2.jar;D:\\maven\\repository\\javax\\servlet\\jsp\\jsp-api\\2.2\\jsp-api-2.2.jar;D:\\maven\\repository\\org\\eclipse\\jetty\\jetty-server\\9.4.19.v20190610\\jetty-server-9.4.19.v20190610.jar;D:\\maven\\repository\\org\\eclipse\\jetty\\jetty-http\\9.4.19.v20190610\\jetty-http-9.4.19.v20190610.jar;D:\\maven\\repository\\org\\eclipse\\jetty\\jetty-util\\9.4.19.v20190610\\jetty-util-9.4.19.v20190610.jar;D:\\maven\\repository\\org\\eclipse\\jetty\\jetty-io\\9.4.19.v20190610\\jetty-io-9.4.19.v20190610.jar;D:\\maven\\repository\\com\\caucho\\hessian\\4.0.38\\hessian-4.0.38.jar;D:\\maven\\repository\\org\\codehaus\\jackson\\jackson-mapper-asl\\1.9.13\\jackson-mapper-asl-1.9.13.jar;D:\\maven\\repository\\org\\codehaus\\jackson\\jackson-core-asl\\1.9.13\\jackson-core-asl-1.9.13.jar;D:\\maven\\repository\\org\\springframework\\spring-context\\5.1.8.RELEASE\\spring-context-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-aop\\5.1.8.RELEASE\\spring-aop-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-expression\\5.1.8.RELEASE\\spring-expression-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\codehaus\\groovy\\groovy-all\\2.4.5\\groovy-all-2.4.5.jar;D:\\maven\\repository\\org\\apache\\commons\\commons-exec\\1.3\\commons-exec-1.3.jar;D:\\maven\\repository\\com\\belerweb\\pinyin4j\\2.5.0\\pinyin4j-2.5.0.jar;D:\\maven\\repository\\org\\slf4j\\slf4j-api\\1.7.26\\slf4j-api-1.7.26.jar;D:\\maven\\repository\\org\\slf4j\\jcl-over-slf4j\\1.7.26\\jcl-over-slf4j-1.7.26.jar;D:\\maven\\repository\\org\\slf4j\\jul-to-slf4j\\1.7.26\\jul-to-slf4j-1.7.26.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter\\2.1.6.RELEASE\\spring-boot-starter-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot\\2.1.6.RELEASE\\spring-boot-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-logging\\2.1.6.RELEASE\\spring-boot-starter-logging-2.1.6.RELEASE.jar;D:\\maven\\repository\\ch\\qos\\logback\\logback-classic\\1.2.3\\logback-classic-1.2.3.jar;D:\\maven\\repository\\ch\\qos\\logback\\logback-core\\1.2.3\\logback-core-1.2.3.jar;D:\\maven\\repository\\org\\apache\\logging\\log4j\\log4j-to-slf4j\\2.11.2\\log4j-to-slf4j-2.11.2.jar;D:\\maven\\repository\\javax\\annotation\\javax.annotation-api\\1.3.2\\javax.annotation-api-1.3.2.jar;D:\\maven\\repository\\org\\springframework\\spring-core\\5.1.8.RELEASE\\spring-core-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\springframework\\spring-jcl\\5.1.8.RELEASE\\spring-jcl-5.1.8.RELEASE.jar;D:\\maven\\repository\\org\\yaml\\snakeyaml\\1.23\\snakeyaml-1.23.jar;D:\\maven\\repository\\redis\\clients\\jedis\\3.0.1\\jedis-3.0.1.jar;D:\\maven\\repository\\org\\apache\\commons\\commons-pool2\\2.6.2\\commons-pool2-2.6.2.jar;D:\\maven\\repository\\com\\baomidou\\mybatis-plus-boot-starter\\3.1.2\\mybatis-plus-boot-starter-3.1.2.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-jdbc\\2.1.6.RELEASE\\spring-boot-starter-jdbc-2.1.6.RELEASE.jar;D:\\maven\\repository\\com\\zaxxer\\HikariCP\\3.2.0\\HikariCP-3.2.0.jar;D:\\maven\\repository\\org\\springframework\\spring-jdbc\\5.1.8.RELEASE\\spring-jdbc-5.1.8.RELEASE.jar;D:\\maven\\repository\\com\\baomidou\\mybatis-plus\\3.1.2\\mybatis-plus-3.1.2.jar;D:\\maven\\repository\\com\\baomidou\\mybatis-plus-generator\\3.1.2\\mybatis-plus-generator-3.1.2.jar;D:\\maven\\repository\\com\\alibaba\\druid\\1.1.18\\druid-1.1.18.jar;D:\\maven\\repository\\com\\alibaba\\druid-spring-boot-starter\\1.1.18\\druid-spring-boot-starter-1.1.18.jar;D:\\maven\\repository\\org\\json\\json\\20180130\\json-20180130.jar;D:\\maven\\repository\\org\\apache\\oltu\\oauth2\\org.apache.oltu.oauth2.client\\0.31\\org.apache.oltu.oauth2.client-0.31.jar;D:\\maven\\repository\\org\\apache\\oltu\\oauth2\\org.apache.oltu.oauth2.common\\0.31\\org.apache.oltu.oauth2.common-0.31.jar;D:\\maven\\repository\\org\\codehaus\\jettison\\jettison\\1.2\\jettison-1.2.jar;D:\\maven\\repository\\com\\squareup\\okhttp3\\okhttp\\3.8.1\\okhttp-3.8.1.jar;D:\\maven\\repository\\com\\squareup\\okio\\okio\\1.13.0\\okio-1.13.0.jar;D:\\maven\\repository\\org\\apache\\commons\\commons-collections4\\4.4\\commons-collections4-4.4.jar;D:\\maven\\repository\\org\\apache\\commons\\commons-vfs2\\2.1\\commons-vfs2-2.1.jar;D:\\maven\\repository\\commons-logging\\commons-logging\\1.2\\commons-logging-1.2.jar;D:\\maven\\repository\\org\\apache\\commons\\commons-lang3\\3.4\\commons-lang3-3.4.jar;D:\\maven\\repository\\commons-collections\\commons-collections\\3.1\\commons-collections-3.1.jar;D:\\maven\\repository\\commons-fileupload\\commons-fileupload\\1.3.1\\commons-fileupload-1.3.1.jar;D:\\maven\\repository\\commons-io\\commons-io\\2.2\\commons-io-2.2.jar;D:\\maven\\repository\\com\\baomidou\\mybatis-plus-extension\\3.1.2\\mybatis-plus-extension-3.1.2.jar;D:\\maven\\repository\\com\\baomidou\\mybatis-plus-core\\3.1.2\\mybatis-plus-core-3.1.2.jar;D:\\maven\\repository\\com\\baomidou\\mybatis-plus-annotation\\3.1.2\\mybatis-plus-annotation-3.1.2.jar;D:\\maven\\repository\\com\\github\\jsqlparser\\jsqlparser\\1.2\\jsqlparser-1.2.jar;D:\\maven\\repository\\org\\mybatis\\mybatis\\3.5.1\\mybatis-3.5.1.jar;D:\\maven\\repository\\org\\mybatis\\mybatis-spring\\2.0.1\\mybatis-spring-2.0.1.jar;D:\\maven\\repository\\com\\baomidou\\dynamic-datasource-spring-boot-starter\\2.5.5\\dynamic-datasource-spring-boot-starter-2.5.5.jar;D:\\maven\\repository\\org\\springframework\\boot\\spring-boot-starter-aop\\2.1.6.RELEASE\\spring-boot-starter-aop-2.1.6.RELEASE.jar;D:\\maven\\repository\\org\\aspectj\\aspectjweaver\\1.9.4\\aspectjweaver-1.9.4.jar;D:\\IntelliJ IDEA 2019.2.1\\lib\\idea_rt.jar\" com.basic.BasicServerApplication Connected to the target VM, address: '127.0.0.1:58693', transport: 'socket' SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/D:/maven/repository/org/slf4j/slf4j-log4j12/1.7.26/slf4j-log4j12-1.7.26.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/D:/maven/repository/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory] Exception in thread \"main\" java.lang.IllegalArgumentException: LoggerFactory is not a Logback LoggerContext but Logback is on the classpath. Either remove Logback or the competing implementation (class org.slf4j.impl.Log4jLoggerFactory loaded from file:/D:/maven/repository/org/slf4j/slf4j-log4j12/1.7.26/slf4j-log4j12-1.7.26.jar). If you are using WebLogic you will need to add 'org.slf4j' to prefer-application-packages in WEB-INF/weblogic.xml: org.slf4j.impl.Log4jLoggerFactory at org.springframework.util.Assert.instanceCheckFailed(Assert.java:655) at org.springframework.util.Assert.isInstanceOf(Assert.java:555) at org.springframework.boot.logging.logback.LogbackLoggingSystem.getLoggerContext(LogbackLoggingSystem.java:279) at org.springframework.boot.logging.logback.LogbackLoggingSystem.beforeInitialize(LogbackLoggingSystem.java:103) at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationStartingEvent(LoggingApplicationListener.java:212) at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:193) at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:127) at org.springframework.boot.context.event.EventPublishingRunListener.starting(EventPublishingRunListener.java:69) at org.springframework.boot.SpringApplicationRunListeners.starting(SpringApplicationRunListeners.java:47) at org.springframework.boot.SpringApplication.run(SpringApplication.java:301) at com.basic.BasicServerApplication.main(BasicServerApplication.java:30) Disconnected from the target VM, address: '127.0.0.1:58693', transport: 'socket' Process finished with exit code 1 2、代码分析 通过点击报错日志里面的具体报错类，查找到对应LogbackLoggingSystem.java下面的代码 private LoggerContext getLoggerContext() { ILoggerFactory factory = StaticLoggerBinder.getSingleton().getLoggerFactory(); Assert.isInstanceOf(LoggerContext.class, factory, String.format( \"LoggerFactory is not a Logback LoggerContext but Logback is on \" + \"the classpath. Either remove Logback or the competing \" + \"implementation (%s loaded from %s). If you are using \" + \"WebLogic you will need to add 'org.slf4j' to \" + \"prefer-application-packages in WEB-INF/weblogic.xml\", factory.getClass(), getLocation(factory))); return (LoggerContext) factory; } private Object getLocation(ILoggerFactory factory) { try { ProtectionDomain protectionDomain = factory.getClass().getProtectionDomain(); CodeSource codeSource = protectionDomain.getCodeSource(); if (codeSource != null) { return codeSource.getLocation(); } } catch (SecurityException ex) { // Unable to determine location } return \"unknown location\"; } public static void isInstanceOf(Class type, @Nullable Object obj, String message) { notNull(type, \"Type to check against must not be null\"); if (!type.isInstance(obj)) { instanceCheckFailed(type, obj, message); } } 代码分析如下： LoggerContext这个通过import导入的包发现是logback的，就是logback-classic:jar:1.2.3.jar下的 factory通过getLocation获取到的结果是file:/D:/maven/repository/org/slf4j/slf4j-log4j12/1.7.26/slf4j-log4j12-1.7.26.jar路径下的 通过Assert.isInstanceOf(LoggerContext.class, factory比较发现这2者不是对应的关系 所以报String.format( \"LoggerFactory is not a Logback LoggerContext but Logback is on \" + \"the classpath. Either remove Logback or the competing \" + \"implementation (%s loaded from %s). If you are using \" + \"WebLogic you will need to add 'org.slf4j' to \" + \"prefer-application-packages in WEB-INF/weblogic.xml\", factory.getClass(), getLocation(factory))) 这段错误，也就是日志打印出来的错误 看maven仓库也会发现也存在slf4j-log4j12对应的包 3、解决 去到对应项目下，执行mvn dependency:tree,结果如下 搜索log4j或搜索slf4j-log4j12，看到存在slf4j-log4j12-1.7.26.jar这个jar包,看到他是在elasitcsearch-starter这个项目下的[INFO] +- com.basic.search:elasitcsearch-starter:jar:1.0.0:compile [INFO] | +- org.springframework.boot:spring-boot-starter-log4j:jar:1.3.5.RELEASE:compile [INFO] | | +- org.slf4j:slf4j-log4j12:jar:1.7.26:compile 查看elasitcsearch-starter这个项目的pom.xml，看到引入了spring-boot-starter-log4j，问题就在这里了，这里会依赖slf4j-log4j12 org.springframework.boot spring-boot-starter-log4j ${spring-log4j.version} 解决办法：引用elasitcsearch-starter时排除掉slf4j-log4j12即可 com.basic.search elasitcsearch-starter 1.0.0 org.slf4j slf4j-log4j12 附注：未解决之前项目依赖如下： λ mvn dependency:tree [INFO] Scanning for projects... [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building basic-server 2.0.2 [INFO] ------------------------------------------------------------------------ [INFO] [INFO] --- maven-dependency-plugin:3.1.1:tree (default-cli) @ basic-server --- [INFO] com.basic:basic-server:jar:2.0.2 [INFO] +- com.basic.search:elasitcsearch-starter:jar:1.0.0:compile [INFO] | +- org.springframework.boot:spring-boot-autoconfigure:jar:2.1.6.RELEASE:compile [INFO] | +- org.springframework.boot:spring-boot-configuration-processor:jar:2.1.6.RELEASE:compile [INFO] | +- org.springframework.boot:spring-boot-starter-json:jar:2.1.6.RELEASE:compile [INFO] | | +- org.springframework:spring-web:jar:5.1.8.RELEASE:compile [INFO] | | +- com.fasterxml.jackson.datatype:jackson-datatype-jdk8:jar:2.9.9:compile [INFO] | | +- com.fasterxml.jackson.datatype:jackson-datatype-jsr310:jar:2.9.9:compile [INFO] | | \\- com.fasterxml.jackson.module:jackson-module-parameter-names:jar:2.9.9:compile [INFO] | +- org.springframework.boot:spring-boot-starter-data-jpa:jar:2.1.6.RELEASE:compile [INFO] | | +- javax.transaction:javax.transaction-api:jar:1.3:compile [INFO] | | +- javax.xml.bind:jaxb-api:jar:2.3.1:compile [INFO] | | | \\- javax.activation:javax.activation-api:jar:1.2.0:compile [INFO] | | +- org.hibernate:hibernate-core:jar:5.3.10.Final:compile [INFO] | | | +- org.jboss.logging:jboss-logging:jar:3.3.2.Final:compile [INFO] | | | +- antlr:antlr:jar:2.7.7:compile [INFO] | | | +- org.jboss:jandex:jar:2.0.5.Final:compile [INFO] | | | +- org.dom4j:dom4j:jar:2.1.1:compile [INFO] | | | \\- org.hibernate.common:hibernate-commons-annotations:jar:5.0.4.Final:compile [INFO] | | +- org.springframework.data:spring-data-jpa:jar:2.1.9.RELEASE:compile [INFO] | | | +- org.springframework.data:spring-data-commons:jar:2.1.9.RELEASE:compile [INFO] | | | \\- org.springframework:spring-orm:jar:5.1.8.RELEASE:compile [INFO] | | \\- org.springframework:spring-aspects:jar:5.1.8.RELEASE:compile [INFO] | +- org.springframework.boot:spring-boot-starter-web:jar:2.1.6.RELEASE:compile [INFO] | | +- org.springframework.boot:spring-boot-starter-tomcat:jar:2.1.6.RELEASE:compile [INFO] | | | +- org.apache.tomcat.embed:tomcat-embed-core:jar:9.0.21:compile [INFO] | | | +- org.apache.tomcat.embed:tomcat-embed-el:jar:9.0.21:compile [INFO] | | | \\- org.apache.tomcat.embed:tomcat-embed-websocket:jar:9.0.21:compile [INFO] | | +- org.hibernate.validator:hibernate-validator:jar:6.0.17.Final:compile [INFO] | | | \\- javax.validation:validation-api:jar:2.0.1.Final:compile [INFO] | | \\- org.springframework:spring-webmvc:jar:5.1.8.RELEASE:compile [INFO] | +- commons-codec:commons-codec:jar:1.12:compile [INFO] | +- io.springfox:springfox-swagger2:jar:2.7.0:compile [INFO] | | +- io.swagger:swagger-annotations:jar:1.5.13:compile [INFO] | | +- io.swagger:swagger-models:jar:1.5.13:compile [INFO] | | +- io.springfox:springfox-spi:jar:2.7.0:compile [INFO] | | | \\- io.springfox:springfox-core:jar:2.7.0:compile [INFO] | | +- io.springfox:springfox-schema:jar:2.7.0:compile [INFO] | | +- io.springfox:springfox-swagger-common:jar:2.7.0:compile [INFO] | | +- io.springfox:springfox-spring-web:jar:2.7.0:compile [INFO] | | | \\- org.reflections:reflections:jar:0.9.11:compile [INFO] | | +- com.google.guava:guava:jar:18.0:compile [INFO] | | +- com.fasterxml:classmate:jar:1.4.0:compile [INFO] | | +- org.springframework.plugin:spring-plugin-core:jar:1.2.0.RELEASE:compile [INFO] | | +- org.springframework.plugin:spring-plugin-metadata:jar:1.2.0.RELEASE:compile [INFO] | | \\- org.mapstruct:mapstruct:jar:1.1.0.Final:compile [INFO] | +- io.springfox:springfox-swagger-ui:jar:2.7.0:compile [INFO] | +- org.springframework.boot:spring-boot-starter-log4j:jar:1.3.5.RELEASE:compile [INFO] | | +- org.slf4j:slf4j-log4j12:jar:1.7.26:compile [INFO] | | \\- log4j:log4j:jar:1.2.17:compile [INFO] | +- org.springframework.boot:spring-boot-starter-data-redis:jar:2.1.6.RELEASE:compile [INFO] | | +- org.springframework.data:spring-data-redis:jar:2.1.9.RELEASE:compile [INFO] | | | +- org.springframework.data:spring-data-keyvalue:jar:2.1.9.RELEASE:compile [INFO] | | | +- org.springframework:spring-oxm:jar:5.1.8.RELEASE:compile [INFO] | | | \\- org.springframework:spring-context-support:jar:5.1.8.RELEASE:compile [INFO] | | \\- io.lettuce:lettuce-core:jar:5.1.7.RELEASE:compile [INFO] | +- com.alibaba:fastjson:jar:1.2.44:compile [INFO] | +- org.apache.httpcomponents:httpclient:jar:4.4.1:compile [INFO] | | \\- org.apache.httpcomponents:httpcore:jar:4.4.11:compile [INFO] | +- com.google.code.gson:gson:jar:2.8.5:compile [INFO] | +- org.elasticsearch:elasticsearch:jar:6.4.3:compile [INFO] | | +- org.elasticsearch:elasticsearch-core:jar:6.4.3:compile [INFO] | | +- org.elasticsearch:elasticsearch-secure-sm:jar:6.4.3:compile [INFO] | | +- org.elasticsearch:elasticsearch-x-content:jar:6.4.3:compile [INFO] | | | +- com.fasterxml.jackson.dataformat:jackson-dataformat-smile:jar:2.9.9:compile [INFO] | | | \\- com.fasterxml.jackson.dataformat:jackson-dataformat-cbor:jar:2.9.9:compile [INFO] | | +- org.apache.lucene:lucene-core:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-analyzers-common:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-backward-codecs:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-grouping:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-highlighter:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-join:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-memory:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-misc:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-queries:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-queryparser:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-sandbox:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-spatial:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-spatial-extras:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-spatial3d:jar:7.4.0:compile [INFO] | | +- org.apache.lucene:lucene-suggest:jar:7.4.0:compile [INFO] | | +- org.elasticsearch:elasticsearch-cli:jar:6.4.3:compile [INFO] | | | \\- net.sf.jopt-simple:jopt-simple:jar:5.0.2:compile [INFO] | | +- com.carrotsearch:hppc:jar:0.7.1:compile [INFO] | | +- joda-time:joda-time:jar:2.10.2:compile [INFO] | | +- com.tdunning:t-digest:jar:3.2:compile [INFO] | | +- org.hdrhistogram:HdrHistogram:jar:2.1.9:compile [INFO] | | +- org.apache.logging.log4j:log4j-api:jar:2.11.2:compile [INFO] | | \\- org.elasticsearch:jna:jar:4.5.1:compile [INFO] | +- org.elasticsearch.client:rest:jar:6.0.0-alpha1:compile [INFO] | | +- org.apache.httpcomponents:httpasyncclient:jar:4.1.4:compile [INFO] | | \\- org.apache.httpcomponents:httpcore-nio:jar:4.4.11:compile [INFO] | +- org.elasticsearch.client:elasticsearch-rest-high-level-client:jar:6.4.3:compile [INFO] | | +- org.elasticsearch.client:elasticsearch-rest-client:jar:6.4.3:compile [INFO] | | +- org.elasticsearch.plugin:parent-join-client:jar:6.4.3:compile [INFO] | | +- org.elasticsearch.plugin:aggs-matrix-stats-client:jar:6.4.3:compile [INFO] | | +- org.elasticsearch.plugin:rank-eval-client:jar:6.4.3:compile [INFO] | | \\- org.elasticsearch.plugin:lang-mustache-client:jar:6.4.3:compile [INFO] | | \\- com.github.spullara.mustache.java:compiler:jar:0.9.3:compile [INFO] | +- org.elasticsearch.client:transport:jar:6.4.3:compile [INFO] | | +- org.elasticsearch.plugin:reindex-client:jar:6.4.3:compile [INFO] | | \\- org.elasticsearch.plugin:percolator-client:jar:6.4.3:compile [INFO] | +- org.elasticsearch.plugin:transport-netty4-client:jar:6.4.3:compile [INFO] | | +- io.netty:netty-codec-http:jar:4.1.36.Final:compile [INFO] | | \\- io.netty:netty-resolver:jar:4.1.36.Final:compile [INFO] | +- org.ansj:ansj_seg:jar:5.1.1:compile [INFO] | | \\- org.nlpcn:nlp-lang:jar:1.7.2:compile [INFO] | +- org.apache.httpcomponents:httpmime:jar:4.5.6:compile [INFO] | +- org.jsoup:jsoup:jar:1.11.2:compile [INFO] | +- javax.servlet:javax.servlet-api:jar:4.0.1:compile [INFO] | \\- javax.persistence:javax.persistence-api:jar:2.2:compile [INFO] +- org.postgresql:postgresql:jar:42.2.2:compile [INFO] +- org.apache.shiro:shiro-core:jar:1.4.0:compile [INFO] | +- org.apache.shiro:shiro-lang:jar:1.4.0:compile [INFO] | +- org.apache.shiro:shiro-cache:jar:1.4.0:compile [INFO] | +- org.apache.shiro:shiro-crypto-hash:jar:1.4.0:compile [INFO] | | \\- org.apache.shiro:shiro-crypto-core:jar:1.4.0:compile [INFO] | +- org.apache.shiro:shiro-crypto-cipher:jar:1.4.0:compile [INFO] | +- org.apache.shiro:shiro-config-core:jar:1.4.0:compile [INFO] | +- org.apache.shiro:shiro-config-ogdl:jar:1.4.0:compile [INFO] | | \\- commons-beanutils:commons-beanutils:jar:1.9.3:compile [INFO] | \\- org.apache.shiro:shiro-event:jar:1.4.0:compile [INFO] +- org.apache.shiro:shiro-web:jar:1.4.0:compile [INFO] +- org.apache.shiro:shiro-spring:jar:1.4.0:compile [INFO] +- org.apache.shiro:shiro-ehcache:jar:1.4.0:compile [INFO] | \\- net.sf.ehcache:ehcache-core:jar:2.6.11:compile [INFO] +- org.springframework.boot:spring-boot-starter-amqp:jar:2.1.6.RELEASE:compile [INFO] | +- org.springframework:spring-messaging:jar:5.1.8.RELEASE:compile [INFO] | | \\- org.springframework:spring-beans:jar:5.1.8.RELEASE:compile [INFO] | \\- org.springframework.amqp:spring-rabbit:jar:2.1.7.RELEASE:compile [INFO] | +- org.springframework.amqp:spring-amqp:jar:2.1.7.RELEASE:compile [INFO] | | \\- org.springframework.retry:spring-retry:jar:1.2.4.RELEASE:compile [INFO] | +- com.rabbitmq:amqp-client:jar:5.4.3:compile [INFO] | \\- org.springframework:spring-tx:jar:5.1.8.RELEASE:compile [INFO] +- org.projectlombok:lombok:jar:1.16.10:compile [INFO] +- org.redisson:redisson:jar:3.11.2:compile [INFO] | +- io.netty:netty-common:jar:4.1.36.Final:compile [INFO] | +- io.netty:netty-codec:jar:4.1.36.Final:compile [INFO] | +- io.netty:netty-buffer:jar:4.1.36.Final:compile [INFO] | +- io.netty:netty-transport:jar:4.1.36.Final:compile [INFO] | +- io.netty:netty-resolver-dns:jar:4.1.36.Final:compile [INFO] | | \\- io.netty:netty-codec-dns:jar:4.1.36.Final:compile [INFO] | +- io.netty:netty-handler:jar:4.1.36.Final:compile [INFO] | +- javax.cache:cache-api:jar:1.1.1:compile [INFO] | +- io.projectreactor:reactor-core:jar:3.2.10.RELEASE:compile [INFO] | | \\- org.reactivestreams:reactive-streams:jar:1.0.2:compile [INFO] | +- io.reactivex.rxjava2:rxjava:jar:2.2.9:compile [INFO] | +- de.ruedigermoeller:fst:jar:2.57:compile [INFO] | | +- org.javassist:javassist:jar:3.21.0-GA:compile [INFO] | | \\- org.objenesis:objenesis:jar:2.5.1:compile [INFO] | +- com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.9.9:compile [INFO] | +- com.fasterxml.jackson.core:jackson-core:jar:2.9.9:compile [INFO] | +- com.fasterxml.jackson.core:jackson-databind:jar:2.9.9:compile [INFO] | | \\- com.fasterxml.jackson.core:jackson-annotations:jar:2.9.0:compile [INFO] | +- net.bytebuddy:byte-buddy:jar:1.9.13:compile [INFO] | \\- org.jodd:jodd-bean:jar:5.0.10:compile [INFO] | \\- org.jodd:jodd-core:jar:5.0.10:compile [INFO] +- org.redisson:redisson-spring-boot-starter:jar:3.11.2:compile [INFO] | +- org.springframework.boot:spring-boot-starter-actuator:jar:2.1.6.RELEASE:compile [INFO] | | +- org.springframework.boot:spring-boot-actuator-autoconfigure:jar:2.1.6.RELEASE:compile [INFO] | | | \\- org.springframework.boot:spring-boot-actuator:jar:2.1.6.RELEASE:compile [INFO] | | \\- io.micrometer:micrometer-core:jar:1.1.5:compile [INFO] | | \\- org.latencyutils:LatencyUtils:jar:2.0.3:compile [INFO] | \\- org.redisson:redisson-spring-data-21:jar:3.11.2:compile [INFO] +- org.apache.poi:poi:jar:4.0.0:compile [INFO] +- org.apache.poi:poi-ooxml:jar:4.0.0:compile [INFO] | +- org.apache.poi:poi-ooxml-schemas:jar:4.0.0:compile [INFO] | | \\- org.apache.xmlbeans:xmlbeans:jar:3.0.1:compile [INFO] | +- org.apache.commons:commons-compress:jar:1.18:compile [INFO] | \\- com.github.virtuald:curvesapi:jar:1.04:compile [INFO] +- com.xuxueli:xxl-job-core:jar:1.8.2:compile [INFO] | +- javax.servlet.jsp:jsp-api:jar:2.2:compile [INFO] | +- org.eclipse.jetty:jetty-server:jar:9.4.19.v20190610:compile [INFO] | | +- org.eclipse.jetty:jetty-http:jar:9.4.19.v20190610:compile [INFO] | | | \\- org.eclipse.jetty:jetty-util:jar:9.4.19.v20190610:compile [INFO] | | \\- org.eclipse.jetty:jetty-io:jar:9.4.19.v20190610:compile [INFO] | +- com.caucho:hessian:jar:4.0.38:compile [INFO] | +- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile [INFO] | | \\- org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile [INFO] | +- org.springframework:spring-context:jar:5.1.8.RELEASE:compile [INFO] | | +- org.springframework:spring-aop:jar:5.1.8.RELEASE:compile [INFO] | | \\- org.springframework:spring-expression:jar:5.1.8.RELEASE:compile [INFO] | +- org.codehaus.groovy:groovy-all:jar:2.4.5:compile [INFO] | \\- org.apache.commons:commons-exec:jar:1.3:compile [INFO] +- com.belerweb:pinyin4j:jar:2.5.0:compile [INFO] +- junit:junit:jar:4.12:test [INFO] | \\- org.hamcrest:hamcrest-core:jar:1.3:test [INFO] +- org.slf4j:slf4j-api:jar:1.7.26:compile [INFO] +- org.slf4j:jcl-over-slf4j:jar:1.7.26:compile [INFO] +- org.slf4j:jul-to-slf4j:jar:1.7.26:compile [INFO] +- org.springframework.boot:spring-boot-starter:jar:2.1.6.RELEASE:compile [INFO] | +- org.springframework.boot:spring-boot:jar:2.1.6.RELEASE:compile [INFO] | +- org.springframework.boot:spring-boot-starter-logging:jar:2.1.6.RELEASE:compile [INFO] | | +- ch.qos.logback:logback-classic:jar:1.2.3:compile [INFO] | | | \\- ch.qos.logback:logback-core:jar:1.2.3:compile [INFO] | | \\- org.apache.logging.log4j:log4j-to-slf4j:jar:2.11.2:compile [INFO] | +- javax.annotation:javax.annotation-api:jar:1.3.2:compile [INFO] | +- org.springframework:spring-core:jar:5.1.8.RELEASE:compile [INFO] | | \\- org.springframework:spring-jcl:jar:5.1.8.RELEASE:compile [INFO] | \\- org.yaml:snakeyaml:jar:1.23:compile [INFO] +- redis.clients:jedis:jar:3.0.1:compile [INFO] | \\- org.apache.commons:commons-pool2:jar:2.6.2:compile [INFO] +- com.baomidou:mybatis-plus-boot-starter:jar:3.1.2:compile [INFO] | \\- org.springframework.boot:spring-boot-starter-jdbc:jar:2.1.6.RELEASE:compile [INFO] | +- com.zaxxer:HikariCP:jar:3.2.0:compile [INFO] | \\- org.springframework:spring-jdbc:jar:5.1.8.RELEASE:compile [INFO] +- com.baomidou:mybatis-plus:jar:3.1.2:compile [INFO] +- com.baomidou:mybatis-plus-generator:jar:3.1.2:compile (optional) [INFO] +- com.alibaba:druid:jar:1.1.18:compile [INFO] +- com.alibaba:druid-spring-boot-starter:jar:1.1.18:compile [INFO] +- org.json:json:jar:20180130:compile [INFO] +- org.apache.oltu.oauth2:org.apache.oltu.oauth2.client:jar:0.31:compile [INFO] | +- org.apache.oltu.oauth2:org.apache.oltu.oauth2.common:jar:0.31:compile [INFO] | \\- org.codehaus.jettison:jettison:jar:1.2:compile [INFO] +- com.squareup.okhttp3:okhttp:jar:3.8.1:compile [INFO] | \\- com.squareup.okio:okio:jar:1.13.0:compile [INFO] +- org.apache.commons:commons-collections4:jar:4.4:compile [INFO] +- org.apache.commons:commons-vfs2:jar:2.1:compile [INFO] | \\- commons-logging:commons-logging:jar:1.2:compile [INFO] +- org.apache.commons:commons-lang3:jar:3.4:compile [INFO] +- commons-collections:commons-collections:jar:3.1:compile [INFO] +- commons-fileupload:commons-fileupload:jar:1.3.1:compile [INFO] | \\- commons-io:commons-io:jar:2.2:compile [INFO] +- com.baomidou:mybatis-plus-extension:jar:3.1.2:compile [INFO] | +- com.baomidou:mybatis-plus-core:jar:3.1.2:compile [INFO] | | +- com.baomidou:mybatis-plus-annotation:jar:3.1.2:compile [INFO] | | +- com.github.jsqlparser:jsqlparser:jar:1.2:compile [INFO] | | \\- org.mybatis:mybatis:jar:3.5.1:compile [INFO] | \\- org.mybatis:mybatis-spring:jar:2.0.1:compile [INFO] +- com.baomidou:dynamic-datasource-spring-boot-starter:jar:2.5.5:compile [INFO] | \\- org.springframework.boot:spring-boot-starter-aop:jar:2.1.6.RELEASE:compile [INFO] | \\- org.aspectj:aspectjweaver:jar:1.9.4:compile [INFO] \\- org.springframework.boot:spring-boot-starter-test:jar:2.1.6.RELEASE:test [INFO] +- org.springframework.boot:spring-boot-test:jar:2.1.6.RELEASE:test [INFO] +- org.springframework.boot:spring-boot-test-autoconfigure:jar:2.1.6.RELEASE:test [INFO] +- com.jayway.jsonpath:json-path:jar:2.4.0:test [INFO] | \\- net.minidev:json-smart:jar:2.3:test [INFO] | \\- net.minidev:accessors-smart:jar:1.2:test [INFO] | \\- org.ow2.asm:asm:jar:5.0.4:test [INFO] +- org.assertj:assertj-core:jar:3.11.1:test [INFO] +- org.mockito:mockito-core:jar:2.23.4:test [INFO] | \\- net.bytebuddy:byte-buddy-agent:jar:1.9.13:test [INFO] +- org.hamcrest:hamcrest-library:jar:1.3:test [INFO] +- org.skyscreamer:jsonassert:jar:1.5.0:test [INFO] | \\- com.vaadin.external.google:android-json:jar:0.0.20131108.vaadin1:test [INFO] +- org.springframework:spring-test:jar:5.1.8.RELEASE:test [INFO] \\- org.xmlunit:xmlunit-core:jar:2.6.2:test [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 3.200 s [INFO] Finished at: 2019-10-11T16:00:25+08:00 [INFO] Final Memory: 43M/449M [INFO] ------------------------------------------------------------------------ D:\\2\\lqx-project-demo\\basic-server (v2.0.3) λ "},"各种问题/springboot/springboot自动装配问题.html":{"url":"各种问题/springboot/springboot自动装配问题.html","title":"springboot自动装配问题","keywords":"","body":" 报错问题 java.lang.IllegalStateException: Unable to read meta-data for class 可以看到这个路径是有问题的 于是找到starter的spring.factories 发现原来是添加自动配置类时忘记使用逗号分割 解决：加上逗号即可 # Auto Configure org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.fzs.parking.live.configuration.HttpFactoryConfiguration,\\ com.fzs.parking.live.configuration.LiveConfiguration 注意多个自动装配的类要用逗号隔开， http://www.manongjc.com/detail/22-qvcmdejoyfkcjhx.html 引用时若出现下面问题 解决jackson报错：java.lang.ClassNotFoundException: com.fasterxml.jackson.databind.ser.std.ToStringSerializerBase 则使用2.10以上的jackson https://devnote.pro/posts/10000062631238 ``` "},"开发工具/模板引擎/freemarker模板语法.html":{"url":"开发工具/模板引擎/freemarker模板语法.html","title":"freemarker模板语法","keywords":"","body":" 列表 import ${pkg}; 条件if import io.swagger.annotations.ApiModel; import io.swagger.annotations.ApiModelProperty; 判断不为空K 加上??两个问号 我的例子： @KeySequence(value=\"${cfg.KeySequenceMap[tableNameKey]}\") 其中KeySequenceMap是一个Map，判断这个map中是否包含tableNameKey这个key， 有才执行if里面的 freemarker输出特殊字符 https://blog.csdn.net/xiaojin21cen/article/details/113844342 在 ${ } 中加入 r ，即 ${r'原样输入的内容'} ，即可原样输出。 例如，想原样输出 ${user.name} ，如下： ${r'user.name'} freemarker遍历list处理第一个、最后一个元素 https://blog.csdn.net/moshowgame/article/details/82744463 ``` "},"开发工具/excel/excel拼接字符串.html":{"url":"开发工具/excel/excel拼接字符串.html","title":"excel拼接字符串","keywords":"","body":" 1.前言 开发过程难免与数据打交道，业务人员有时会以excel表格提供数据给开发人员，所以掌握excel一些基本的技巧也很重要很有帮助 2.需求 如下图,将excel表格里的数据插入或者更新数据库，方法有很多 将excel转换为csv文件，然后用awk\\cat基本命令处理 利用excel直接拼接 3.实战 1.定义拼接的字符串函数如下： =\"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'\"&A3&\"','\"&B3&\"','\"&C3&\"','\"&D3&\"','\"&E3&\"','\"&F3&\"','\"&G3&\"','\"&H3&\"','\"&J3&\"','\"&K3&\"','\"&L3&\"');\" 2.点击excel的M3单元格，将上面内容复制到工具栏的fx函数处，如下： 3.然后焦点回到M3单元格，点击回车，即可拼接了字符串 4.再次点击M3单元格，鼠标移动到该单元格右下角，鼠标变成十字后,按住ctrl键,往下拉,松手即可 5.然后复制M列出来即可，内容如下，把前后的双引号去掉即可 \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'MOROCCO','MA','wonderful_sea-MA','0.2','1','0.1','0','0.05','10','DHS','2');\" \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'EGYPT','EG','wonderful_sea-EG','0.25','1','0.1','0','0.05','19','EGP','0');\" \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'KENYA','KE','wonderful_sea-KE','0.2','1','0.1','0','0.05','105','KSH','0');\" \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'KENYA','KE','SMARTEST-KE','0.2','1','0.1','0','0.05','105','KSH','0');\" \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'KENYA','KE','NICEST store-KE','0.2','1','0.1','0','0.05','105','KSH','0');\" \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'NIGERIA','NG','Celmia official store-NG','0.2','1','0.1','0','0.05','370','NGN','0');\" \"INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'NIGERIA','NG','INCERUN official store-NG','0.2','1','0.1','0','0.05','370','NGN','0');\" 4.函数分析 结果是需要下面的，对比开始的那个函数，也就是'\"&A3&\"'这地方不同的地方是单引号里面的东西\"&A3&\"，所以用这个替换单引号里的值，再前后加上双引号即可 INSERT INTO sp_business.jumia_price_msg(id,site_name,short_name,shop_name,profit,incidental,deal_rate,poundage_rate, other_rate,fixed_rate,currency,other_cost) VALUES(127,'NIGERIA','NG','INCERUN official store-NG','0.2','1','0.1','0','0.05','370','NGN','0'); 另外更新的可以如下： =\"UPDATE sp_common.shop SET access_token='\"&D2&\"',site_url='\"&C2&\"',shop_mail='\"&A2&\"',site_id='CM',site_name='CAMEROO' WHERE shop_name='\"&B2&\"';\" "},"开发工具/git/git打tag.html":{"url":"开发工具/git/git打tag.html","title":"git打tag","keywords":"","body":" 1、 2、 3、 ``` "},"开发工具/git/git提交注释规范.html":{"url":"开发工具/git/git提交注释规范.html","title":"git提交注释规范","keywords":"","body":" 1、git commit 时报错 remote: commit message: 增加gitnore文件和启动项目要配置的说明 remote: 你提交的commit注释格式有问题，请按格式提交. remote: (): remote: Example: remote: docs(phoneapi.java): 新添加phone接口 remote: or Merge/merge 提交 type 用于说明 commit 的类别，只允许使用下面7个标识。 2、 3、 ``` "},"开发工具/git/git新建项目常见操作.html":{"url":"开发工具/git/git新建项目常见操作.html","title":"git新建项目常见操作","keywords":"","body":" 1、新建项目流程 初始化 git init 添加文件 git add . 提交 git commit -am 'init' 关联远程git git remote add origin git@github.com:xxx.git 关联远程分支 git branch --set-upstream-to=origin/master master 拉取代码（若远程有代码了） git pull 拉取代码(有历史记录，拉取不了则用下面的) git pull origin master --allow-unrelated-histories 推送 git push 推送到远程 git push -u origin master 2、打标签和发release版本 、 3、 ``` "},"开发工具/idea/idea-git操作.html":{"url":"开发工具/idea/idea-git操作.html","title":"idea-git操作","keywords":"","body":" 1、idea中对git版本回滚 1、项目或文件夹右键-> git-> show history-> Copy Revision Number（复制想要的版本号） 2、项目或文件夹右键-> git-> Repository -> Reset HEAD 参考： https://blog.csdn.net/weixin_40836179/article/details/87006285 2、 3、 "},"开发工具/idea/idea插件.html":{"url":"开发工具/idea/idea插件.html","title":"idea插件","keywords":"","body":" 快速通过mapper跳转到xml文件 free-idea-mybatis 官网：https://github.com/wuzhizhan/free-idea-mybatis 点击快速查看调用处和被调用处，快速切换 mybatis-lite 注意： 此功能默认打开(可能会与Mybatis Plugin / free mybatis plugin等插件冲突)，需要关闭的同学，请在IDEA->File菜单->Setting菜单->Other Setting菜单->Mybatis菜单->导航开关 关闭 使用方法：如下图，按住ctrl健，点击方法名，会显示跳转到xml文件还是impl实训类，自己选择 官网：https://github.com/mustfun/mybatis-lite 常用插件 Grep console 自定义日志颜色，idea控制台可以彩色显示各种级别的log，安装完成后，在console中右键就能打开。 settings->other setting MyBatis Log Plugin 直接将Mybatis执行的sql脚本显示出来，无需处理，可以直接复制出来执行的 Tools -- > Mybatis Log Plugin 打开其日志框，注意其转换的SQL不是输出到IDE的控制台!!! String Manipulation 强大的字符串转换工具。使用快捷键，Alt+m。 或者点击右键 CodeGlance CodeGlance是一款代码编辑区缩略图插件，可以快速定位代码，使用起来比拖动滚动条方便多了 Maven Helper 分析依赖冲突插件 打开项目中的pom文件，在底部会显示一个“Dependency Analyzer”, Rainbow Brackets 彩虹颜色的括号 在黑色主题下看的比较清楚舒服，白色主题下看的很不明显，看自己选择了，除了看着舒服，也有助于 帮助区分前后括号对应关系。 GenerateAllSetter 一键调用一个对象的所有set方法并且赋予默认值 在对象字段多的时候非常方便，在做项目时，每层都有各自的实体对象需要相互转换，但是考虑BeanUtil.copyProperties()等这些工具的弊端，有些地方就需要手动的赋值时，有这个插件就会很方便，创建完对象后在变量名上面按Alt+Enter就会出来 generate all setter选项。 https://github.com/gejun123456/intellij-generateAllSetMethod https://blog.csdn.net/qq_38225558/article/details/88388841 注意：若alter+enter没出现菜单，则看看对象里面有没set方法，必须有set方法才能出现菜单 看：https://github.com/gejun123456/intellij-generateAllSetMethod/issues/32 Lombok 代码注解插件 Key promoter X 快捷键提示工具 https://github.com/halirutan/IntelliJ-Key-Promoter-X GsonFormat jsonFormat JSON转领域对象工具 Restfultookit 一套 RESTful 服务开发辅助工具集。 1.根据 URL 直接跳转到对应的方法定义 ( or Ctrl Alt N ); 2.提供了一个 Services tree 的显示窗口; 3.一个简单的 http 请求工具; 4.在请求方法上添加了有用功能: 复制生成 URL;,复制方法参数... 5.其他功能: java 类上添加 Convert to JSON 功能，格式化 json 数据 ( Windows: Ctrl + Enter; Mac: Command + Enter )。 CamelCase 将不是驼峰格式的名称，快速转成驼峰格式，安装好后，选中要修改的名称，按快捷键shift+alt+u。 Mybatis plugin 可以在mapper接口中和mapper的xml文件中来回跳转，就想接口跳到实现类那样简单。 Translation 中英文翻译工具 CodeMaker 代码生成工具 https://github.com/x-hansong/CodeMaker Iedis Redis可视化 Alibaba Java Coding Guidelines K8s工具：Kubernetes SonarLint FindBugs-IDEA CheckStyle-IDEA mybatis-generator https://gitee.com/rohou/mybatis-generator 阿里java规范 https://github.com/alibaba/p3c/blob/master/idea-plugin/README_cn.md "},"开发工具/idea/idea快捷键.html":{"url":"开发工具/idea/idea快捷键.html","title":"idea快捷键","keywords":"","body":" 常见快捷键 文件 重名文件名(重命名变量)： shift+F6 新建文件: alt+insert （注意要先选择文件夹） 搜索 搜索类: ctrl+n 搜索文件: ctrl+shift+n 全局搜索: ctrl+shift+f （注意在搜狗输入法下才行，在其他输入法可能有影响） 调试 debug调试： shift+F9 停止调试: ctrl+F2 修改js或jsp后更新: ctrl+F10 打开窗口 打开services日志窗口： alt+8 打开terminal窗口： alt+F12 打开左边窗口： alt+1 代码窗口 重新方法(或实现): ctrl+o 生成get/set/构造方法:　alt+insert 跳到实现: ctrl+b 关掉编辑窗口： ctrl+F4 设置 打开idea设置：ctrl+alt+s 打开项目设置：ctrl+shift+alt+s 关掉idea: alt+F4 git提交 commit提交: ctrl+k push提交: ctrl+alt+k 类图 生成类图，显示Diagrams： CTRL+ALT+SHIFT+U 或 ctrl+alt+u IDEA编写快捷生成代码 idea 快速打出for循环 "},"开发工具/idea/idea中文乱码.html":{"url":"开发工具/idea/idea中文乱码.html","title":"idea中文乱码","keywords":"","body":" https://blog.csdn.net/weixin_43912972/article/details/104098821 1、 2、 3、 "},"开发工具/idea/ieda快捷生成代码.html":{"url":"开发工具/idea/ieda快捷生成代码.html","title":"ieda快捷生成代码","keywords":"","body":" 1. psvm //生成main方法: public static void main(String[] args) {} 2. sout //生成打印输出: System.out.println(); 3. \"abc\".sout //生成打印字符串: System.out.println(\"adc\"); 4. \"abc\".format //生成字符串格式化: String.format(\"abc\", ) //如List或者Array: List list = new ArrayList<>(); 5. itli //生成for循环 for (int i = 0; i 6. itco // 生成Collection迭代器 for (Iterator iterator = list.iterator(); iterator.hasNext(); ) { String next = iterator.next(); } 7. iter ///生成增强for循环 for (String s : list) { } 8.iten ///生成 enumeration遍历 while (enumeration.hasMoreElements()) { Object nextElement = enumeration.nextElement(); } 9. itar ///生成数组for循环 int[] array = {1,2,3,4,5}; for (int i = 0; i 10. itit ///生成迭代器 iterator Iterator iterator = list.iterator(); while (iterator.hasNext()) { Object next = iterator.next(); } 11. ittok //ittok 生成String token遍历 for (StringTokenizer stringTokenizer = new StringTokenizer(APP_NAME); stringTokenizer.hasMoreTokens(); ) { String s = stringTokenizer.nextToken(); } 12. itws //生成Axis2 web service调用 try { MyServiceLocator locator = new MyServiceLocator(); Activator service = locator.get(); // If authorization is required //((MyService_Soap_BindingStub)service).setUsername(\"user3\"); //((MyService_Soap_BindingStub)service).setPassword(\"pass3\"); // invoke business method service.businessMethod(); } catch (javax.xml.rpc.ServiceException ex) { ex.printStackTrace(); } catch (java.rmi.RemoteException ex) { ex.printStackTrace(); } 13 .try 如:\"abc\".try //生成try.....catch try { \"abc\" } catch (Exception e) { e.printStackTrace(); } 14. ifn //生成判断是否为空 if (list == null) { } 15. inn ///生成判断是否不为空 if (list != null) { } 16. fori //生成简单for循环 for (int i = 0; i 17. inst //生成是否是该对象引用 if (list instanceof Object) { Object o = (Object) list; } 18.psf ///生成 共有 静态最终的 public static final 19. psfi ///生成 共有 静态最终的 int public static final int 20.psfs ///生成 共有 静态最终的 String public static final String "},"开发工具/postman/postman调上传文件接口.html":{"url":"开发工具/postman/postman调上传文件接口.html","title":"postman调上传文件接口","keywords":"","body":" ``` "},"开发工具/ppt/markdown制作ppt.html":{"url":"开发工具/ppt/markdown制作ppt.html","title":"markdown制作ppt","keywords":"","body":" ppt内容 Spring中注册Bean的方式有哪些？https://blog.csdn.net/Weixiaohuai/article/details/123210761 slidev教程 https://cn.sli.dev/guide/#scaffolding-your-first-presentation 新拉项目 npm init slidev 启动 npm run dev 打包 npm run build 备注：打包完后去到dist文件夹下，直接cmd下输入anywhere即可访问静态页面 导出 npm run export 图片要放在public目录下，引入以/开头 其中m-60 h-60调整图片的大小的 居中参考下面的 https://blog.csdn.net/Jivove/article/details/123496699 我的培训例子 try also 'default' to start simple theme: seriph random image from a curated Unsplash collection by Anthony like them? see https://unsplash.com/collections/94734566/slidev background: https://source.unsplash.com/collection/94734566/1920x1080 apply any windi css classes to the current slide class: 'text-center' https://sli.dev/custom/highlighters.html highlighter: shiki show line numbers in code blocks lineNumbers: false some information about the slides, markdown enabled info: | Slidev Starter Template Presentation slides for developers. Learn more at Sli.dev persist drawings in exports and build drawings: persist: false use UnoCSS css: unocss Bean的注册方式 主讲人：梁庆祥 begin --- # Bean注册几种方式? - ① **XML文件配置** - ② **使用@Component注解 + @ComponentScan包扫描方式** - ③ **@Configuration + @Bean方式** - ④ **使用FactoryBean** - ⑤ **@Import方式** - ⑥ **@Import + ImportSelector方式** - ⑦ **@Import + ImportBeanDefinitionRegistrar方式** - ⑧ **BeanDefinitionRegistryPostProcessor方式** - ⑨ **BeanFactoryPostProcessor方式** Read more about h1 { background-color: #2B90B6; background-image: linear-gradient(45deg, #4EC5D4 10%, #146b8c 20%); background-size: 100%; -webkit-background-clip: text; -moz-background-clip: text; -webkit-text-fill-color: transparent; -moz-text-fill-color: transparent; } --- # (1)XML文件配置 ```java class Student { } public class Client { public static void main(String[] args) { ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"classpath:spring-config.xml\"); System.out.println(applicationContext.getBean(\"student\")); } } ``` .footnotes-sep { @apply mt-20 opacity-10; } .footnotes { @apply text-sm opacity-75; } .footnote-backref { display: none; } --- # (2)@Component注解 + @ComponentScan包扫描方式 ```java {all} @Component class UserHandler { } @Service class UserService { } @Repository class UserDao { } @Controller class UserController { } @ComponentScan(\"com.basic.test2\") @Configuration class AppConfig { } ``` --- # (3)@Configuration + @Bean方式 ```java {all} class Student { } @Configuration class AppConfig { @Bean public Student student() { return new Student(); } } ``` --- # (4)使用FactoryBean ```java {all} class User { } @Component class UserFactoryBean implements FactoryBean { @Override public User getObject() throws Exception { return new User(); } @Override public Class getObjectType() { return User.class; } @Override public boolean isSingleton() { return true; } } @Configuration @ComponentScan(\"com.basic.test4\") class AppConfig { } ``` --- # (5)@Import方式 ```java {all} class Student { } @Import({Student.class}) @Configuration class AppConfig { } ``` --- # (6)@Import + ImportSelector方式 ```java {all} class Product { } class User { } class MyImportSelector implements ImportSelector { /// 指定需要定义bean的类名，注意要包含完整路径，而非相对路径 @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) { return new String[]{\"com.basic.test6.Product\", \"com.basic.test6.User\"}; } } @Import({MyImportSelector.class}) @Configuration class AppConfig { } ``` --- # (7)@Import + ImportBeanDefinitionRegistrar方式 ```java {all} class User { } class Product { } class CustomImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { // 可以自定义bean的名称、作用域等很多参数 registry.registerBeanDefinition(\"user\", new RootBeanDefinition(User.class)); RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Product.class); rootBeanDefinition.setScope(BeanDefinition.SCOPE_SINGLETON); registry.registerBeanDefinition(\"product\", rootBeanDefinition); } } @Import({CustomImportBeanDefinitionRegistrar.class}) @Configuration class AppConfig { } ``` --- # (8)BeanDefinitionRegistryPostProcessor方式 ```java {all} class User { } @Component class CustomBeanDefinitionRegistryPostProcessor implements BeanDefinitionRegistryPostProcessor { @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException { registry.registerBeanDefinition(\"user\", new RootBeanDefinition(User.class)); } @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException { } } @Configuration @ComponentScan(\"com.basic.test8\") class AppConfig { } ``` --- # (9)BeanFactoryPostProcessor方式 ```java {all} class Product { } @Component class CustomBeanFactoryPostProcessor implements BeanFactoryPostProcessor { @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException { DefaultListableBeanFactory registry = (DefaultListableBeanFactory) beanFactory; registry.registerBeanDefinition(\"product\", new RootBeanDefinition(Product.class)); } } @Configuration @ComponentScan(\"com.basic.test9\") class AppConfig { } ``` --- # Thanks .center{ text-align: center; } "},"开发工具/typora/typora画图教程.html":{"url":"开发工具/typora/typora画图教程.html","title":"typora画图教程","keywords":"","body":" Typora内置了对Mermaid的支持，才阔以画各种图。 使用方法： 首先在 Typora 中，输入 mermaid 然后敲击回车，即可初始化一张空白图。 上面的三个也就是esc健对应下面的健。 在空白处输入下面的源码即可，按照mermaid语法格式来操作即可。 一、流程图 1）、竖向（TD 表示从上到下） graph TD; A-->B; A-->C; B-->D; D-->E; D-->F; 2）、横向（LR 表示从左到右） graph LR; A[方形]-->B(圆角) B-->C{条件a} C-->|a=1|D[结果1] C-->|a=2|E[结果2] 3）、标准（竖向） 先输入```flow 然后敲击回车，在输入栏，输入下面的语法即可。 st=>start: 开始框 op=>operation: 处理框 cond=>condition: 判断框(是或否?) sub1=>subroutine: 子流程 io=>inputoutput: 输入输出框 e=>end: 结束框 st->op->cond cond(yes)->io->e cond(no)->sub1(right)->op 4）、标准（横向） st=>start: 开始框 op=>operation: 处理框 cond=>condition: 判断框(是或否?) sub1=>subroutine: 子流程 io=>inputoutput: 输入输出框 e=>end: 结束框 st(right)->op(right)->cond cond(yes)->io(bottom)->e cond(no)->sub1(right)->op 二、UML时序图 先输入```mermaid (或）sequence ->> 代表实线箭头，–>> 则代表虚线箭头 -> 直线，–>虚线 使用sequenceDiagram 则不使用``sequence 1）、简单 sequenceDiagram 客户->>银行柜台: 我要存钱 银行柜台->>后台: 改一下这个账户数字哦 后台->>银行柜台: 账户的数字改完了，明天起息 银行柜台->>客户: 好了，给你回单 ，下一位 2）、复杂 复杂1-备注 sequenceDiagram title:标题：复杂使用 对象A->>对象B:对象B你好吗（请求） Note right of 对象B:对象B的描述（提示） Note left of 对象A:提示 对象B-->>对象A:我很好（响应） 对象B->>对象C:你好吗？ 对象C-->>对象A: B找我了 对象A->>对象B:你确定？ note over 对象C,对象B:朋友 participant D note right of D:没人陪我 复杂2-循环 sequenceDiagram participant A participant B participant C A->>C:hello loop health C->>C:no end Note right of C:you should eat doctor B-->>A:nice C->>B:how are you? B-->>C:great 复杂3-alt sequenceDiagram participant A participant B participant C participant D title:\"练习时序图\" A->>B:request B->>B:verify sign B->>C:123 C-->>B:321 B->>C:456 C->>C:code C->>D:789 D-->>B:987 alt yes Note right of B:yes的结果 else no B-->>D:login D-->>B:login success end B->>B:加密 B-->>A:return 复杂4-alt-loop-note-activate-rect -opt-par sequenceDiagram title:时序图例子 Alice->>Alice:自言自语 Alice-->>John:hello john, %% over 可以用于单独一个角色上，也可以用于相邻的两个角色间： note over Alice,John:friend %% loop 后跟循环体说明文字 loop healthcheck John-->>John:Fight agaist hypochondra end note right of John: Rational John-->>Alice:Great! John->>Bob:How about you? %% 控制焦点：用来表示时序图中对象执行某个操作的一段时间 %% activate 角色名：表示激活控制焦点 activate Bob Bob-->>John:Jolly good! %% deactivate 角色名 表示控制焦点结束 deactivate Bob Alice->>+Bob: Hello Bob, how are you? rect rgb(175, 255, 212) alt is sick Bob-->>Alice: Not so good :( else is well Bob-->>Alice: Feeling fresh like a daisy end opt Extra response Bob-->>Alice: Thanks for asking end end loop communicating Alice->>+John: asking some questions John-->>-Alice: answer end par Alice to John Alice->>John: Bye and Alice to Bob Alice->>Bob: Bye end Alice-xJohn: 这是一个异步调用 Alice--xBob: 这是一个异步调用 3）、标准 %% 时序图例子,-> 直线，-->虚线，->>实线箭头 sequenceDiagram participant 张三 participant 李四 张三->王五: 王五你好吗？ loop 健康检查 王五->王五: 与疾病战斗 end Note right of 王五: 合理 食物 看医生... 李四-->>张三: 很好! 王五->李四: 你怎么样? 李四-->王五: 很好!A 三、甘特图 %% 语法示例 gantt dateFormat YYYY-MM-DD title 软件开发甘特图 section 设计 需求 :done, des1, 2014-01-06,2014-01-08 原型 :active, des2, 2014-01-09, 3d UI设计 : des3, after des2, 5d 未来任务 : des4, after des3, 5d section 开发 学习准备理解需求 :crit, done, 2014-01-06,24h 设计框架 :crit, done, after des2, 2d 开发 :crit, active, 3d 未来任务 :crit, 5d 耍 :2d section 测试 功能测试 :active, a1, after des3, 3d 压力测试 :after a1 , 20h 测试报告 : 48h 四、类图 语法解释： 表示继承，+ 表示 public，- 表示 private, #表示Protected，~表示Package/Internal（包或内部类） classDiagram Animal 五、状态图 stateDiagram [*] --> s1 s1 --> [*] 六、饼图 pie title Key elements in Product X \"Calcium\" : 42.96 \"Potassium\" : 50.05 \"Magnesium\" : 10.01 \"Iron\" : 5 参考 https://blog.csdn.net/u010164190/article/details/128190915 "},"开发工具/window/jna问题.html":{"url":"开发工具/window/jna问题.html","title":"jna问题","keywords":"","body":" NoSuchMethodError: com.sun.jna.Native.load(Ljava/lang/String;Ljava/lang/Class;Ljava/util/Map;)Lcom/sun/jna/Library; basic-server项目一直报这个错，找了好久，才发现是elasticsearch里面引入了jna-4.5.1,而这个jar包比较旧的 8228@LAPTOP-6VJBADD9 tasklist /fi \"imagename eq ffmpeg.exe\" /fo list 5e1d82e8d5dee1224447267b/5d7f9944d5de554b6d29241b 输出线程执行完毕 Exception in thread \"Thread-48\" java.lang.NoSuchMethodError: com.sun.jna.Native.load(Ljava/lang/String;Ljava/lang/Class;Ljava/util/Map;)Lcom/sun/jna/Library; at com.sun.jna.platform.win32.Kernel32.(Kernel32.java:42) at com.fzs.parking.live.util.ProcessUtil.getPid(ProcessUtil.java:101) at com.fzs.parking.live.service.impl.ProcessServiceImpl.getFFmpegIdByProcess(ProcessServiceImpl.java:149) at com.fzs.parking.live.service.impl.ProcessServiceImpl.assembleProcessId(ProcessServiceImpl.java:76) at com.fzs.parking.live.service.impl.ProcessServiceImpl.processHandle(ProcessServiceImpl.java:38) at com.fzs.parking.live.service.impl.DeviceLiveServiceImpl$1.start(DeviceLiveServiceImpl.java:119) at com.phone580.avserver.FFmpegCommandManagerImpl$1$1.start(FFmpegCommandManagerImpl.java:190) at com.phone580.avserver.handler.TaskHandlerImpl$1.start(TaskHandlerImpl.java:37) at com.phone580.avserver.handler.OutMsgHandler.run(OutMsgHandler.java:118) tasklist /fi \"imagename eq ffmpeg.exe\" /fo list 2023-01-10 15:26:35,234 http-nio-8180-exec-2 INFO com.basic.util.aop.WebExceptionConfig:37 [http-nio-8180-exec-2] org.springframework.web.util.NestedServletException: Handler dispatch failed; nested exception is java.lang.NoClassDefFoundError: Could not initialize class com.sun.jna.platform.win32.Kernel32 at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1055) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:645) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.basic.config.CorsFilter.doFilter(CorsFilter.java:31) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.basic.config.AccessControlFilter.doFilter(AccessControlFilter.java:45) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.basic.config.AccessControlFilter.doFilter(AccessControlFilter.java:45) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745) Caused by: java.lang.NoClassDefFoundError: Could not initialize class com.sun.jna.platform.win32.Kernel32 at com.fzs.parking.live.util.ProcessUtil.getPid(ProcessUtil.java:101) at com.fzs.parking.live.service.impl.ProcessServiceImpl.getFFmpegIdByProcess(ProcessServiceImpl.java:149) at com.fzs.parking.live.service.impl.DeviceLiveServiceImpl.getFFmpegIdByProcess(DeviceLiveServiceImpl.java:494) at com.basic.controller.live.LiveTestController.startLive(LiveTestController.java:168) at com.basic.controller.live.LiveTestController$$FastClassBySpringCGLIB$$3a8f7d77.invoke() at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:771) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88) at com.basic.config.ControllerLogAspect.around(ControllerLogAspect.java:113) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:691) at com.basic.controller.live.LiveTestController$$EnhancerBySpringCGLIB$$e45fdac9.startLive() at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) ... 44 more 看下图，利用dependency analyzer可以看到elasticsearch自带了jna包 解决办法：干掉elasticsearch或者引入elasticsearch时干掉jna 注意groupId为org.elasticsearch，和上面的jna有点不一样 org.elasticsearch jna 参考： https://www.codenong.com/55982008/ 里面说的 与JNA相关的NoSuchMethodError几乎总是与在您的依赖项列表中某处拥有较旧版本的JNA有关，即使您也具有当前版本 非常有用 "},"开发工具/window/window端口占用查询.html":{"url":"开发工具/window/window端口占用查询.html","title":"window端口占用查询","keywords":"","body":" 查看端口 netstat -ano netstat -ano |grep 8090 netstat -ano |findstr \"8719\" 查看端口对应那个任务 tasklist|findstr \"17752\" 例子： C:\\Users\\hoby λ netstat -ano |grep 8090 TCP 0.0.0.0:8090 0.0.0.0:0 LISTENING 17752 TCP [::]:8090 [::]:0 LISTENING 17752 C:\\Users\\hoby λ netstat -ano |grep 8719 TCP 0.0.0.0:8719 0.0.0.0:0 LISTENING 17752 TCP [::]:8719 [::]:0 LISTENING 17752 C:\\Users\\hoby λ netstat -ano |findstr \"8719\" TCP 0.0.0.0:8719 0.0.0.0:0 LISTENING 17752 TCP [::]:8719 [::]:0 LISTENING 17752 C:\\Users\\hoby λ tasklist|findstr \"17752\" java.exe 17752 Console 10 430,904 K 参考： windows本地端口占用查看 tasklist 查看Windows运行中的进程 找到相同的名称，可以看到名称是tasklist 里的名称是 chromedriver.exe Windows命令行模式快速杀掉进程 taskkill杀掉进程 public static void stopProcess(long pid) { // 拼接命令 String cmd = \"taskkill /PID \" + pid + \" /F\"; // 运行命令 String[] returnContent = RunUtils.run2(cmd); } // 阻塞 public static String[] run2(String cmd) { String returnPrintContent = null; String returnErrorContent = null; String[] returnContent = new String[2]; try { Process child = Runtime.getRuntime().exec(cmd); // 获取程序输入流 OutputStream os = child.getOutputStream(); // 正常输出流和异常输出流 InputStream stdin = child.getInputStream(); InputStream stderr = child.getErrorStream(); // 启动线程 ConsoleSimulator cs1 = new ConsoleSimulator(stdin, 0); ConsoleSimulator cs2 = new ConsoleSimulator(stderr, 1); Thread tIn = new Thread(cs1); Thread tErr = new Thread(cs2); tIn.start(); tErr.start(); int result = child.waitFor(); tIn.join(); tErr.join(); returnPrintContent = cs1.getReturnPrintContent(); returnErrorContent = cs2.getReturnErrorContent(); // 处理中文乱码，需更改服务器端编码 // 0是全部信息 returnContent[0] = returnPrintContent; // 1是错误信息 returnContent[1] = returnErrorContent; return returnContent; } catch (Exception e) { e.printStackTrace(); return returnContent; } } https://www.freesion.com/article/9141153359/ https://blog.csdn.net/m0_58719994/article/details/122961648 "},"开发工具/window/window开机启动.html":{"url":"开发工具/window/window开机启动.html","title":"window开机启动","keywords":"","body":" nssm做成window服务 nssm和上面instsrv+srvany的原理是一样的，而且还简单点，都是弄到注册表和服务哪里 拷贝nssm.exe到对应目录下，执行 nssm install mediaService 其中mediaService是服务名这时会弹出一个界面 application path项输入 MediaServer.exe startup directory输入 D:\\idea-workspace4-2\\zlmediakit 然后点install即可安装服务，这时去到服务下可以看到新建的服务，或者去到注册表下也可以看到 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\mediaService\\Parameters\\ instsrv+srvany做成window服务 https://www.cnblogs.com/firespeed/p/16867825.html https://blog.csdn.net/okmkjh/article/details/120486544https://www.modb.pro/db/424196 去到instsrv.exe的目录下，才能执行instsrv命令 貌似按文章介绍的弄了，注册表弄出的服务的不完整的，不知道为什么 install.bat @echo off cd /d %~dp0 call run-install.bat mediaService \"D:\\idea-workspace4-2\\zlmediakit\\MediaServer.exe\" pause run-install.bat @echo off rem 参数依次为 服务名称 可执行文件名称 @echo 服务名称:%1 @echo 程序名称:%2 rem 定义需要运行的程序路径 set curExe=%~dp0%2 rem 定义注册表路径 set regpath=HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\mediaService\\Parameters\\ rem 定义srvany.exe文件路径 set sourcePath=%~dp0srvany.exe rem 进入当前目录 cd /d \"%~dp0\" rem 安装引导服务 instsrv %1 \"%sourcePath%\" @echo 服务添加完成 rem 添加注册表语法: reg add 注册表路径 /v 项名称 /t 值类型 /d 数据 /f 表示强行修改不提示 rem 名称 Application 值为你要作为服务运行的程序地址 /d对应的参数有斜杠不是为了转义引号，而是路径还有斜杠，默认将引号转义了，额外添加斜杠是为了保留引号 reg add %regpath% /v AppDirectory /t REG_SZ /d \"%~dp0\\\" /f rem 名称 AppDirectory 值为你要作为服务运行的程序所在文件夹路径 reg add %regpath% /v Application /t REG_SZ /d \"%curExe%\" /f rem 名称 AppParameters 值为你要作为服务运行的程序启动所需要的参数 reg add %regpath% /v AppParameters /t REG_SZ /f @echo 注册表添加完成 del.bat @echo off cd /d %~dp0 call run-del.bat mediaService pause run-del.bat @echo off rem 参数依次为 你的服务名称 @echo 你的服务名称:%1 rem 进入当前目录 cd /d %~dp0 rem 停止服务 net stop %1 rem 卸载引导服务 instsrv %1 remove "},"开发工具/常见工具.html":{"url":"开发工具/常见工具.html","title":"常见工具","keywords":"","body":" 1、json在线格式化 http://jsoneditoronline.org/ 2、xml和json格式化 http://www.bejson.com/ http://www.json.cn/ 3、各种编码和格式化工具 https://1024tools.com/hmac 4、将propertyies转yml https://www.toyaml.com/index.html 5、google浏览器手势插件访问地址 chrome-extension://jlgkpaicikihijadgifklkbpdajbkhjo/options.html 6、jemeter jemter字体优化 7、xml在线格式化 xml在线格式化 8、二维码在线生成 https://www.liantu.com/ 微信图片转换 https://blog.csdn.net/qq_24473765/article/details/123938257 "},"开源项目/阿里开源项目.html":{"url":"开源项目/阿里开源项目.html","title":"阿里开源项目","keywords":"","body":" 分布式应用服务开发的一站式解决方案 Spring Cloud Alibaba 设计语言 & 前端框架 Ant Design JDBC 连接池、监控组件 Druid Java 的 JSON 处理器 fastjson 服务框架 Dubbo 企业级流式计算引擎 JStorm apns4j 数据驱动的高交互可视化图形语法 AntV - G2 前端构建和工程化工具 Dawn 分布式数据层 TDDL 轻量级分布式数据访问层 CobarClient 淘宝定制 JVM：TaobaoJVM Java 图片处理类库 SimpleImage Redis 的 Java 客户端 Tedis 开源 Java 诊断工具 Arthas 动态服务发现、配置和服务管理平台 Nacos Java 解析 Excel 工具 easyexcel 高可用流量管理框架 Sentinel 基于多维度 Metrics 的系统度量和监控中间件 SOFALookout 基于 Spring Boot 的研发框架 SOFABoot 轻量级 Java 类隔离容器 SOFAArk 分布式链路追踪中间件 SOFATracer 高性能 Java RPC 框架 SOFARPC 基于 Netty 的网络通信框架 SOFABolt 动态非侵入 AOP 解决方案 JVM-Sandbox 面向云的分布式消息领域标准 OpenMessaging P2P 文件分发系统 Dragonfly LayoutManager 定制化布局方案 vlayout Java 代码规约扫描插件 P3C 前言 众所周知，阿里巴巴是 apache基金会成员、Linux基金会成员，同时是Xen顾问委员会成员。上述身份可见阿里在开源方面的重视程度，阿里通过开源贡献更多技术、分享更多理念。其开源的很多项目大受欢迎，今日就来盘点阿里29个开源项目，你用过几个，哪个最好用，欢迎在留言区告诉小编。 分布式应用服务开发的一站式解决方案 Spring Cloud Alibaba Spring Cloud Alibaba 致力于提供分布式应用服务开发的一站式解决方案。此项目包含开发分布式应用服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。 依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里分布式应用解决方案，通过阿里中间件来迅速搭建分布式应用系统。 地址：https://github.com/spring-cloud-incubator/spring-cloud-alibaba 设计语言 & 前端框架 Ant Design Ant Design 是蚂蚁金服开发和正在使用的一套企业级的前端设计语言和基于 React 的前端框架实现。 它的特性：企业级金融产品的交互语言和视觉体系；丰富实用的 React UI 组件；基于 React 的组件化开发模式；背靠 npm 生态圈；基于 webpack 的调试构建方案，支持 ES6。 地址：https://github.com/ant-design/ant-design JDBC 连接池、监控组件 Druid Druid是一个 JDBC 组件。 1.监控数据库访问性能。 2.提供了一个高效、功能强大、可扩展性好的数据库连接池。 3.数据库密码加密。 4.SQL执行日志。 地址：https://github.com/alibaba/druid Java 的 JSON 处理器 fastjson fastjson 是一个性能很好的 Java 语言实现的 JSON 解析器和生成器，来自阿里巴巴的工程师开发。 主要特点：快速FAST (比其它任何基于Java的解析器和生成器更快，包括jackson）；强大（支持普通JDK类包括任意Java Bean Class、Collection、Map、Date或enum）；零依赖（没有依赖其它任何类库除了JDK）。 地址：https://github.com/alibaba/fastjson 服务框架 Dubbo Apache Dubbo (incubating) |是阿里巴巴的一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。 地址：https://github.com/alibaba/dubbo 企业级流式计算引擎 JStorm JStorm 是参考 Apache Storm 实现的实时流式计算框架，在网络IO、线程模型、资源调度、可用性及稳定性上做了持续改进，已被越来越多企业使用。JStorm 可以看作是 storm 的 java 增强版本，除了内核用纯java实现外，还包括了thrift、python、facet ui。从架构上看，其本质是一个基于 zk 的分布式调度系统。 地址：https://github.com/alibaba/jstorm apns4j apns4j 是 Apple Push Notification Service 的 Java 实现。 地址：https://github.com/teaey/apns4j 数据驱动的高交互可视化图形语法 AntV - G2 G2 是一套基于可视化编码的图形语法，以数据驱动，具有高度的易用性和扩展性，用户无需关注各种繁琐的实现细节，一条语句即可构建出各种各样的可交互的统计图表。 同时，G2 也是 AntV 最重要的组成，始于《The Grammar of Graphics》一书描述的视觉编码语法系统（这也是 G2 项目命名的由来）。 项目地址：https://github.com/antvis/g2 前端构建和工程化工具 Dawn Dawn 取「黎明、破晓」之意，原为「阿里云·业务运营团队」内部的前端构建和工程化工具，现已完全开源。 它通过 pipeline 和 middleware 将开发过程抽象为相对固定的阶段和有限的操作，简化并统一了开发人员的日常构建与开发相关的工作。 地址：https://alibaba.github.io/dawn/ 分布式数据层 TDDL TDDL 是一个基于集中式配置的 jdbc datasource实现，具有主备，读写分离，动态数据库配置等功能。 地址：https://github.com/alibaba/tb_tddl 轻量级分布式数据访问层 CobarClient Cobar Client是一个轻量级分布式数据访问层（DAL）基于iBatis(已更名为MyBatis)和Spring框架实现。 地址：https://github.com/alibaba/cobarclient 淘宝定制 JVM：TaobaoJVM TaobaoJVM 基于 OpenJDK HotSpot VM，是国内第一个优化、定制且开源的服务器版Java虚拟机。目前已经在淘宝、天猫上线，全部替换了Oracle官方JVM版本，在性能，功能上都初步体现了它的价值。 地址：http://jvm.taobao.org Java 图片处理类库 SimpleImage SimpleImage是阿里巴巴的一个Java图片处理的类库，可以实现图片缩略、水印等处理。 地址：https://github.com/alibaba/simpleimage Redis 的 Java 客户端 Tedis Tedis 是另一个 redis 的 java 客户端。Tedis 的目标是打造一个可在生产环境直接使用的高可用 Redis 解决方案。 地址：https://github.com/justified/tedis 开源 Java 诊断工具 Arthas Arthas（阿尔萨斯）是阿里巴巴开源的 Java 诊断工具，深受开发者喜爱。 Arthas 采用命令行交互模式，同时提供丰富的 Tab 自动补全功能，进一步方便进行问题的定位和诊断。 地址：https://alibaba.github.io/arthas/ 动态服务发现、配置和服务管理平台 Nacos Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您实现动态服务发现、服务配置管理、服务及流量管理。 Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。Nacos 是构建以“服务”为中心的现代应用架构(例如微服务范式、云原生范式)的服务基础设施。 地址：https://nacos.io/en-us/ Java 解析 Excel 工具 easyexcel Java 解析、生成 Excel 比较有名的框架有 Apache poi、jxl 。但他们都存在一个严重的问题就是非常的耗内存，poi 有一套 SAX 模式的 API 可以一定程度的解决一些内存溢出的问题，但 POI 还是有一些缺陷，比如 07 版 Excel 解压缩以及解压后存储都是在内存中完成的，内存消耗依然很大。 easyexcel 重写了 poi 对 07 版 Excel 的解析，能够原本一个 3M 的 excel 用 POI sax 依然需要 100M 左右内存降低到 KB 级别，并且再大的 excel 不会出现内存溢出，03 版依赖 POI 的 sax 模式。在上层做了模型转换的封装，让使用者更加简单方便。 地址：https://github.com/alibaba/easyexcel 高可用流量管理框架 Sentinel Sentinel 是面向微服务的轻量级流量控制框架，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。 地址：https://github.com/alibaba/Sentinel 基于多维度 Metrics 的系统度量和监控中间件 SOFALookout Lookout 是一个利用多维度的 metrics 对目标系统进行度量和监控的项目。Lookout 的多维度 metrics 参考 Metrics 2.0 标准。Lookout 项目分为客户端部分与服务器端部分。 客户端是一个 Java 的类库，可以将它植入您的应用代码中采集 metrics 信息，客户端更多详情。 服务端代码部分，将于下一版本提供。通过 LOOKOUT 的服务，可以对 metrics 数据进行收集、加工、存储和查询等处理，另外结合 grafana，可做数据可视化展示。 地址：https://github.com/alipay/sofa-lookout 基于 Spring Boot 的研发框架 SOFABoot SOFABoot 是蚂蚁金服开源的基于 Spring Boot 的研发框架，它在 Spring Boot 的基础上，提供了诸如 Readiness Check，类隔离，日志空间隔离等等能力。在增强了 Spring Boot 的同时，SOFABoot 提供了让用户可以在 Spring Boot 中非常方便地使用 SOFAStack 相关中间件的能力。 地址：https://github.com/alipay/sofa-boot 轻量级 Java 类隔离容器 SOFAArk SOFAArk 是一款基于 Java 实现的轻量级类隔离容器，由蚂蚁金服公司开源贡献；主要为应用程序提供类隔离和依赖包隔离的能力；基于 Fat Jar 技术，应用可以被打包成一个自包含可运行的 Fat Jar，应用既可以是简单的单模块 Java 应用也可以是 Spring Boot 应用。可访问网址进入快速开始并获取更多详细信息。 地址：https://alipay.github.io/sofastack.github.io/ 分布式链路追踪中间件 SOFATracer SOFATracer 是一个用于分布式系统调用跟踪的组件，通过统一的 traceId 将调用链路中的各种网络调用情况以日志的方式记录下来，以达到透视化网络调用的目的。这些日志可用于故障的快速发现，服务治理等。 地址：https://github.com/alipay/sofa-tracer 高性能 Java RPC 框架 SOFARPC SOFARPC 是一个高可扩展性、高性能、生产级的 Java RPC 框架。在蚂蚁金服 SOFARPC 已经经历了十多年及五代版本的发展。SOFARPC 致力于简化应用之间的 RPC 调用，为应用提供方便透明、稳定高效的点对点远程服务调用方案。为了用户和开发者方便的进行功能扩展，SOFARPC 提供了丰富的模型抽象和可扩展接口，包括过滤器、路由、负载均衡等等。同时围绕 SOFARPC 框架及其周边组件提供丰富的微服务治理方案。 地址：https://github.com/alipay/sofa-rpc 基于 Netty 的网络通信框架 SOFABolt SOFABolt 是蚂蚁金融服务集团开发的一套基于 Netty 实现的网络通信框架。 为了让 Java 程序员能将更多的精力放在基于网络通信的业务逻辑实现上，而不是过多的纠结于网络底层 NIO 的实现以及处理难以调试的网络问题，Netty 应运而生。 为了让中间件开发者能将更多的精力放在产品功能特性实现上，而不是重复地一遍遍制造通信框架的轮子，SOFABolt 应运而生。 地址：https://github.com/alipay/sofa-bolt 动态非侵入 AOP 解决方案 JVM-Sandbox JVM-Sandbox，JVM 沙箱容器，一种基于 JVM 的非侵入式运行期 AOP 解决方案。 地址：https://github.com/alibaba/jvm-sandbox 面向云的分布式消息领域标准 OpenMessaging OpenMessaging 是由阿里巴巴发起，与雅虎、滴滴出行、Streamlio 公司共同参与创立，旨在创立厂商无关、平台无关的分布式消息及流处理领域的应用开发标准。 地址：https://github.com/openmessaging/openmessaging-java P2P 文件分发系统 Dragonfly Dragonfly（蜻蜓）是阿里自研的 P2P 文件分发系统，用于解决大规模文件分发场景下分发耗时、成功率低、带宽浪费等难题。大幅提升发布部署、数据预热、大规模容器镜像分发等业务能力。 开源版的 Dragonfly 可用于 P2P 文件分发、容器镜像分发、局部限速、磁盘容量预检等。它支持多种容器技术，对容器本身无需做任何改造，镜像分发比 natvie 方式提速可高达 57 倍，Registry 网络出流量降低99.5%以上。 地址：https://github.com/alibaba/Dragonfly LayoutManager 定制化布局方案 vlayout VirtualLayout是一个针对RecyclerView的LayoutManager扩展, 主要提供一整套布局方案和布局间的组件复用的问题。 地址：https://github.com/alibaba/vlayout Java 代码规约扫描插件 P3C 项目包含三部分：PMD 实现、IntelliJ IDEA 插件、Eclipse 插件 地址：https://github.com/alibaba/p3c "},"前端/弹窗/layer/layer弹窗.html":{"url":"前端/弹窗/layer/layer弹窗.html","title":"layer弹窗","keywords":"","body":" layer弹窗用法 layer弹窗效果 artTemplate模板 1、 2、 3、 ``` "},"前端/后台模板/ngx-admin后台模板学习.html":{"url":"前端/后台模板/ngx-admin后台模板学习.html","title":"ngx-admin后台模板学习","keywords":"","body":" ngx-admin是开源的基于angular的后台管理模板 1.用命令或者idea下载 git clone https://github.com/akveo/ngx-admin.git 2.去到ngx-admin目录下，任意用下面1个命令安装 npm i 或命令 npm install 3.启动项目 npm start 4.访问 http://localhost:4200 5.线上模式 npm run build:prod 文档地址 ngx-admin文档地址 "},"前端/angular/angular基础/angular-generate命令.html":{"url":"前端/angular/angular基础/angular-generate命令.html","title":"angular-generate命令","keywords":"","body":" "},"前端/jquery基础/jquery按钮用法.html":{"url":"前端/jquery基础/jquery按钮用法.html","title":"jquery按钮用法","keywords":"","body":" 1、 JQuery控制radio选中和不选中方法 2、 3、 ``` "},"前端/json/前端json字符串和js对象转换.html":{"url":"前端/json/前端json字符串和js对象转换.html","title":"前端json字符串和js对象转换","keywords":"","body":" 1、object转化为json字符串 var data = new Object(); var jsonData = JSON.stringify(data); 2、json字符串转为js对象 var jsonObj = eval(jsonStr); var jsonObj = JSON.parse(jsonStr); 参考： https://blog.csdn.net/wangzhibo666/article/details/87718123?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf https://blog.csdn.net/yo746862873/article/details/52468683 3、 ``` "},"前端/node/node学习.html":{"url":"前端/node/node学习.html","title":"node学习","keywords":"","body":" 1、node待学习 commander学习 https://www.cnblogs.com/1wen/p/10142210.html https://www.iteye.com/blog/witcheryne-1196170 https://segmentfault.com/q/1010000000367285 2、 3、 "},"前端/vue/vue待学习.html":{"url":"前端/vue/vue待学习.html","title":"vue待学习","keywords":"","body":" 待学习网址 vue后台模板 https://github.com/dohoby/vue-admin-template/blob/master/README-zh.md https://panjiachen.gitee.io/vue-element-admin-site/zh/guide/#%E5%8A%9F%E8%83%BD 下载项目后用yarn安装，不要用npm install安装（会报错） yarn "},"日常开发/常见时间操作2.html":{"url":"日常开发/常见时间操作2.html","title":"常见时间操作","keywords":"","body":" ``` "},"数据库/导数据/导出数百万级别数据.html":{"url":"数据库/导数据/导出数百万级别数据.html","title":"导出数百万级别数据","keywords":"","body":" 问题 表数据非常大，有几百万数据，用Navicat直接查询出来会崩掉，怎么样导出？ postgres数据库的解决方案 利用row_number进行排序查询，再一段段查询出来，如下： SELECT *,row_number() OVER(ORDER BY now()) as seq from t1 where seq BETWEEN 2000001 and 3000000 "},"数据库/mysql/mysql版本升级.html":{"url":"数据库/mysql/mysql版本升级.html","title":"mysql版本升级","keywords":"","body":" 将mysql版本从5.6升级到5.7 window下mysql版本从5.6升级5.7 1、下载 下载地址：https://dev.mysql.com/downloads/mysql/ 最新的mysql5.7的压缩包解压开你会发现，没有data目录和my.ini文件，跟之前的版本不一样 我下载的是mysql-5.7.31-winx64.zip 2、查看原来运行的mysql5.6 控制面板-管理工具-服务 搜索mysql，并且点击属性，查看可执行文件路径，看到如下 ```shell script \"D:\\Program Files\\MySQL\\MySQL Server 5.6\\bin\\mysqld\" --defaults-file=\"D:\\Program Files\\myqldata\\my.ini\" MySQL56 可以看到启动的mysql进程为myqld，这个在任务管理器哪里也可以看到，可以在任务管理器或者服务里关掉mysql进程 同时可以看到使用的配置文件是D:\\Program Files\\myqldata\\my.ini，这个就是之前安装mysql5.6时指定的配置文件 打开这个文件对应的目录D:\\Program Files\\myqldata就看到有个data，这个就是存放数据的的目录 #### 3、关闭mysql 服务-右键停止启动mysql56 使用cmd窗口，进入到mysql目录下面，将mysql服务移除（注意用管理员身份运行） ```shell script D:\\Program Files\\MySQL\\MySQL Server 5.6\\bin λ mysqld.exe --remove mysql56 Service successfully removed. 再次搜索服务，发现没有mysql56这个服务了 4、修改my.ini文件 主要是修改basedir改为上面下载的mysql5.7解压的目录，如下： ```shell script basedir=\"D:\\Program Files\\mysql-5.7.31-winx64\\\" #### 5、将mysql5.7的服务添加到win的服务队列中，并且启动mysql服务。 cd 到D:\\Program Files\\mysql-5.7.31-winx64\\bin，执行下面的，如下： ```shell script mysqld.exe --install MySQL57 --defaults-file=\"D:\\Program Files\\myqldata\\my.ini\" Service successfully installed. 其中MySQL57是指安装的服务，--defaults-file指向my.ini配置文件再次看服务，刷新就看到mysql57的服务 6、启动mysql服务 ```shell script net start mysql57 (1)然后报下面的错 ```shell script D:\\Program Files\\mysql-5.7.31-winx64\\bin λ net start mysql57 MySQL57 服务正在启动 .. MySQL57 服务无法启动。 服务没有报告任何错误。 请键入 NET HELPMSG 3534 以获得更多的帮助。 将mysql5.7安装目录添加到path环境变量也不行 (2)解决办法： 直接干掉my.ini文件里的内容，将下面的内容复制进去 ```shell script [mysqld] 设置mysql的安装目录[根据本地情况进行修改] basedir=\"D:\\Program Files\\mysql-5.7.31-winx64\" 设置mysql数据库的数据的存放目录[根据本地情况进行修改] datadir=\"D:\\Program Files\\myqldata\\data\" 设置3306端口 port = 3306 允许最大连接数 max_connections=200 服务端使用的字符集默认为8比特编码的latin1字符集 character-set-server=utf8 创建新表时将使用的默认存储引擎 default-storage-engine=INNODB sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES [mysql] 设置mysql客户端默认字符集 default-character-set=utf8 原因：mysql5.7的my.ini和mysql5.6的有些不一样 (3)cd 到D:\\Program Files\\mysql-5.7.31-winx64目录下 若有data文件夹，则删掉，然后执行下面的 ```shell script mysqld.exe　--initialize 不行就执行下面的的 ```shell script mysqld.exe --initialize-insecure 这个命令会在安装目录下产生data文件夹，对个人在D:\\Program Files\\myqldata目录下建的data文件夹(my.ini指定的datadir)没影响的 (4)重新执行net start mysql57命令 经过上面步骤，这个就可以启动了 #### 7、升级mysql：mysql_upgrade -uroot -p ```shell script mysql_upgrade -uroot -proot 升级速度具体看data目录的大小情况而定。 必须升级，要不原来mysql5.6中的数据库，在navicate中连接报错 8、升级成功后，再次重启mysql5.7服务 ```shell script D:\\Program Files\\mysql-5.7.31-winx64\\bin λ net stop mysql57 MySQL57 服务正在停止. MySQL57 服务已成功停止。 D:\\Program Files\\mysql-5.7.31-winx64\\bin λ net start mysql57 MySQL57 服务正在启动 . MySQL57 服务已经启动成功。 启动完就可以了 #### 9、查看mysql版本 登录 ```shell script mysql -uroot -proot 输入select version(); ```shell script mysql> select version(); +-----------+ | version() | +-----------+ | 5.7.31 | +-----------+ 1 row in set (0.00 sec) 或者status ```shell script mysql> status -------------- mysql Ver 14.14 Distrib 5.7.31, for Win64 (x86_64) Connection id: 5 Current database: Current user: root@localhost SSL: Cipher in use is ECDHE-RSA-AES128-GCM-SHA256 Using delimiter: ; Server version: 5.7.31 MySQL Community Server (GPL) Protocol version: 10 Connection: localhost via TCP/IP Server characterset: utf8 Db characterset: utf8 Client characterset: gbk Conn. characterset: gbk TCP port: 3306 Uptime: 4 min 5 sec Threads: 3 Questions: 40 Slow queries: 0 Opens: 124 Flush tables: 1 Open tables: 117 Queries per second avg: 0.163 -------------- 参考： https://www.cnblogs.com/java-123/p/10624600.html 扩展知识 修改mysql用户密码 ```shell script mysqld -nt --skip-grant-tables 以管理员身份运行这段命令，相当于在my.ini中[mysqld]下加入skip-grant-tables，就可以跳过登录校验 ，此时命令窗口不会动啦， 重开一个窗口 ，直接接登录： ```shell script mysql -uroot -proot use mysql update mysql.user set authentication_string=password('root') where user='root' and Host = 'localhost'; flush privileges; 查看注册表 win10左下角搜索框输入 regedit 然后依次打开 计算机\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\MySQL57 "},"数据库/oracle/oracle常见查询语句.html":{"url":"数据库/oracle/oracle常见查询语句.html","title":"oracle常见查询语句","keywords":"","body":" 1、常见查询 //当前用户拥有的表 select table_name from user_tables; //当前表字段 select * from user_tab_columns where Table_Name='T_IOT_CARD' ORDER BY COLUMN_name asc; //获取表注释： select * from user_tab_comments //获取字段注释： select * from user_col_comments where table_name='T_IOT_CARD' //查看序列 select * from user_sequences; //查看某个特定的序列 select * from user_sequences where sequence_name like '%SEQ_IOT_INTERFACE_DICT%' 参考：https://blog.51cto.com/meiling/2068902 2、oracle中如何查找表在哪个模式下？ select * from dba_tables where table_name like '%PROCESS_TEMPLATE%' demo: select * from dba_tables where table_name ='T_IOT_CARD' 3、 oracle 查看当前用户名 show user select user from dual oracle 查看所有用户名 select * from all_users https://www.cnblogs.com/tdskee/p/5848334.html plsql选择 command window ,不是sql window , 然后输入命令 start D:\\aa.sql Oracle trunc()函数的用法 https://www.cnblogs.com/zhangxiaoxia/p/10270840.html "},"数据库/oracle/oracle常见更新操作.html":{"url":"数据库/oracle/oracle常见更新操作.html","title":"oracle常见更新操作","keywords":"","body":" Oracle 在原有内容上继续添加内容 SET DTL.REMARK = DTL.REMARK||'无权限操作;' 注意只能用||，不能用+，否则更新不成功的 UPDATE T_SMS_TASK_DETAIL DTL SET DTL.REMARK = DTL.REMARK||'无权限操作;',DTL.MODIFY_TIME=SYSTIMESTAMP WHERE DTL.TASK_NO = #{taskNo} AND EXISTS(SELECT 1 FROM T_CARD CARD WHERE CARD.CARD_NO=DTL.CARD_NO AND CARD.channel_id!=#{channelId}) UPDATE T_RE_INVENTORY_IN_DETAIL d SET d.REMARK = '卡号不存在或卡处于预约销户' WHERE d.ORDER_NO = #{orderNo} AND (SELECT COUNT(1) FROM T_CARD c WHERE c.CARD_NO = d.CARD_NO AND c.CARD_STATE != '5') = 0 UPDATE T_RENEWAL_DETAIL DTL SET DTL.REMARK = '卡处于预约销户状态' ,DTL.STATE='3', DTL.MODIFIER=#{userName},DTL.MODIFY_TIME=SYSTIMESTAMP WHERE DTL.ORDER_NO = #{orderNo} AND EXISTS(SELECT 1 FROM T_CARD CARD WHERE CARD.CARD_NO=DTL.CARD_NO AND CARD.CUSTOMER_STATE='5') AND DTL.REMARK IS NULL UPDATE T_CHARGE_ORDER co SET co.REMARK = '充值卡存在不属于当前商户的卡', co.STATE = '1', co.MODIFIER = #{userName}, MODIFY_TIME = SYSDATE WHERE co.ORDER_NO = #{orderNo} AND ( SELECT COUNT(1) FROM T_CARD c LEFT JOIN T_PORTAL_DISTRIBUTE pd ON pd.CARD_ID = c.ID LEFT JOIN T_PORTAL_MERCHANT pm ON pd.MERCHANT_ID = pm.ID WHERE c.CARD_NO = co.CARD_NO AND pm.ID = #{merchantId} ) = 0 ``` "},"数据库/oracle/oracle的mergeinto用法.html":{"url":"数据库/oracle/oracle的mergeinto用法.html","title":"oracle的mergeinto更新用法","keywords":"","body":" MERGE INTO T_INVENTORY i USING T_RE_INVENTORY_IN_DETAIL d ON (d.ORDER_NO = #{orderNo} AND i.CARD_NO = d.CARD_NO) WHEN MATCHED THEN UPDATE SET i.INVENTORY_STATE = '1' merge into t_agent_transact_record tr using t_card c on (tr.card_no = c.card_no and tr.order_no = #{orderNo} and c.agent_discount_id is null) when matched then update set tr.remark = #{remark} merge into T_CARD c using T_CARD_STATE_UPDATE_RECORD r on (r.state = '1' and r.order_no = #{record.orderNo} and r.import_no = c.CARD_NO c.ICCID c.CARD_IMSI c.CARD_IMEI ) when matched then update set c.card_state = #{record.modifyType},c.modifier = #{record.creator},c.modify_time = SYSTIMESTAMP MERGE INTO T_CARD A USING ( SELECT CARD.CARD_NO, MAX(DISCOUNT.ID) AS \"FLOW_SALE_DISCOUNT_ID\" FROM T_CARD CARD JOIN ( SELECT DTL.CARD_NO,DTL.DISCOUNT_CODE FROM T_RENEWAL_DETAIL DTL WHERE DTL.ORDER_NO=#{orderNo,jdbcType=VARCHAR} ) DTL ON CARD.CARD_NO = DTL.CARD_NO JOIN T_CHANNEL_PRODUCT_DISCOUNT DISCOUNT ON DISCOUNT.DISCOUNT_CODE=DTL.DISCOUNT_CODE GROUP BY CARD.CARD_NO ) C ON (A.CARD_NO=C.CARD_NO) WHEN MATCHED THEN UPDATE SET A.FLOW_SALE_DISCOUNT_ID=C.FLOW_SALE_DISCOUNT_ID https://blog.csdn.net/qq_35606010/article/details/120213562 ``` "},"数据库/oracle/oracle分批插入更新.html":{"url":"数据库/oracle/oracle分批插入更新.html","title":"oracle分批插入更新","keywords":"","body":" 分批插入更新 才哥模板： declare inum=0; begin for p in (select * from t_temp_table) loop 更新或插入逻辑 inum:=inum+1; if inum=50000 then commit; inum:=0; end if; end loop; commit; end; 我的实例： select count(CARD_NO) INTO v_count 这句是将查询的count数目赋值给变量v_count 再根据v_count>0(说明数据库中存在记录)则更新，否则新增 declare inum number; v_count number; begin inum:=0; for p in (select * from T_DATA_TEMP) loop select count(CARD_NO) INTO v_count from T_RISK_INFO where CARD_NO=p.CARD_NO; if v_count>0 then update T_RISK_INFO a set a.last_position=p.ICCID,a.LAST_POSITION_UPDATE_TIME=p.CARD_ACTIVE_DATE where a.CARD_NO=p.CARD_NO; else insert INTO T_RISK_INFO(id,CARD_NO,last_position,LAST_POSITION_UPDATE_TIME,CREATOR,CREATE_TIME) values (SEQ_RISK_INFO.nextval,p.card_no,p.ICCID,p.CARD_ACTIVE_DATE,'lqx',sysdate); end if; inum:=inum+1; if inum=50000 then commit; inum:=0; end if; end loop; commit; end; merge into 插入或者更新 注意这种方式不能分批提交 https://blog.csdn.net/spw55381155/article/details/79891305 https://javaforall.cn/134030.html merge into 目标表 a using 源表 b on(a.条件字段1=b.条件字段1 and a.条件字段2=b.条件字段2 ……) when matched then update set a.字段=b.字段 --目标表别称a和源表别称b都不要省略 when not matched then insert (a.字段1,a.字段2……)values(b.字段1,b.字段2……) --目标表别称a可省略,源表别称b不可省略 ``` "},"数据库/oracle/oracle约束.html":{"url":"数据库/oracle/oracle约束.html","title":"oracle约束","keywords":"","body":" -- 创建一个测试表 CREATE TABLE employees ( department_id NUMBER, employee_id NUMBER, name VARCHAR2(100), -- 其他字段... CONSTRAINT emp_dept_uk UNIQUE (department_id, employee_id) ); -- 或者，如果你想要创建一个主键约束 CREATE TABLE employees ( department_id NUMBER, employee_id NUMBER, name VARCHAR2(100), -- 其他字段... CONSTRAINT emp_dept_pk PRIMARY KEY (department_id, employee_id) ); 在这个例子中，emp_dept_uk 是一个唯一约束，它基于department_id和employee_id两个字段的组合来确保记录的唯一性。如果你想要创建一个主键约束，可以像上面例子中那样将约束命名为emp_dept_pk，并将关键字UNIQUE替换为PRIMARY KEY。 https://blog.csdn.net/pan_junbiao/article/details/78166095 https://www.cnblogs.com/lijiaman/p/7225831.html ``` "},"数据库/oracle/oracle注意问题.html":{"url":"数据库/oracle/oracle注意问题.html","title":"oracle注意问题","keywords":"","body":" 在oraclre不要用char类型 在oraclre不要用char类型，这次的我帮你改成varchar了 char在例如换库时会导致数据在实际值前或后自动补上空格 ``` "},"数据库/postgres/postgres创建序列.html":{"url":"数据库/postgres/postgres创建序列.html","title":"postgres创建序列","keywords":"","body":" postgres创建序列并设置到某个主键上 CREATE SEQUENCE jumia_brand_seq START WITH 1 INCREMENT BY 1 NO MINVALUE NO MAXVALUE CACHE 1; alter table jumia_brand alter column id set default nextval('jumia_brand_seq'); "},"数据库/sql优化/存在一个表不存在另外一个表.html":{"url":"数据库/sql优化/存在一个表不存在另外一个表.html","title":"存在一个表不存在另外一个表","keywords":"","body":" A、B两表，找出ID字段中，存在A表，但是不存在B表的数据。A表总共13w数据，去重后大约3W条数据，B表有2W条数据，且B表的ID字段有索引。 方法一 　　使用 not in ,容易理解,效率低 select distinct A.ID from A where A.ID not in (select ID from B) SQL查询~ 存在一个表而不在另一个表中的数据 方法二 使用 left join...on... , \"B.ID isnull\" 表示左连接之后在B.ID 字段为 null的记录 select A.ID from A left join B on A.ID=B.ID where B.ID is null 方法三 逻辑相对复杂,但是速度最快 select * from B where (select count(1) as num from A where A.ID = B.ID) = 0 "},"微信支付/微信支付相关.html":{"url":"微信支付/微信支付相关.html","title":"微信支付相关","keywords":"","body":" 网页授权 https://developers.weixin.qq.com/doc/offiaccount/OA_Web_Apps/Wechat_webpage_authorization.html 第一步：用户同意授权，获取code 在确保微信公众账号拥有授权作用域（scope参数）的权限的前提下（已认证服务号，默认拥有scope参数中的snsapi_base和snsapi_userinfo 权限），引导关注者打开如下页面： https://open.weixin.qq.com/connect/oauth2/authorize?appid=APPID&redirect_uri=REDIRECT_URI&response_type=code&scope=SCOPE&state=STATE#wechat_redirect 组装好参数后发消息到微信公众号，然后打开，提示下面 比如：https://open.weixin.qq.com/connect/oauth2/authorize?appid=xxx&redirect_uri=http%3A%2F%2Fdevelopers.weixin.qq.com&response_type=code&scope=snsapi_userinfo&state=STATE#wechat_redirect 应该是要在这下面JS接口安全域名或者是网页授权域名 开通微信支付功能 "},"中间件/mybatis-plus/mybatis-plus生成器相关问题.html":{"url":"中间件/mybatis-plus/mybatis-plus生成器相关问题.html","title":"mybatis-plus生成器相关问题","keywords":"","body":" 实体名重新命名问题 数据库表名字建得不规范(缩写等),而实体名字和数据库表名字不同 参考： https://github.com/baomidou/mybatis-plus/blob/1ea2629a12344f77dd5aa318e4bbee96740cc8e5/mybatis-plus-generator/src/main/java/com/baomidou/mybatisplus/generator/config/INameConvert.java#L70-L75 https://github.com/baomidou/mybatis-plus/blob/3.0/mybatis-plus-generator/src/main/java/com/baomidou/mybatisplus/generator/config/INameConvert.java 整合oracle 自增序列配置 oracle的id一般自己定义个sequence来自增，而不是数据库默认自增，所以实体id要弄成序列的 看如下代码： @TableName(\"T_USER\") @KeySequence(value = \"SEQ_USER\") public class User extends Model { private static final long serialVersionUID = 1L; /** * 用户ID */ @TableId(value = \"USER_ID\", type = IdType.INPUT) private Integer userId; } 主要是： @KeySequence(value = \"SEQ_USER\") @TableId(value = \"USER_ID\", type = IdType.INPUT)这2行代码,type必须指定为IdType.INPUT 使用时，mybatis-plus 3.0版本的必须配置下面注入注解id的默认生成实现 /** * Sequence主键自增 * https://blog.csdn.net/ancdc/article/details/86517796 * @return 返回oracle自增类 */ @Bean public OracleKeyGenerator oracleKeyGenerator(){ return new OracleKeyGenerator(); } 参考： https://blog.csdn.net/ancdc/article/details/86517796 代码生成器自定义数据库表字段类型转换 mybatis-plus提供的oracle转换类如下： com.baomidou.mybatisplus.generator.config.converts.OracleTypeConvert 其中处理数字类型的如下： /** * 将对应的类型名称转换为对应的 java 类类型 * * String.valueOf(Integer.MAX_VALUE).length() == 10 * Integer 不一定能装下 10 位的数字 * * String.valueOf(Long.MAX_VALUE).length() == 19 * Long 不一定能装下 19 位的数字 * * @param typeName 类型名称 * @return 返回列类型 */ private static IColumnType toNumberType(String typeName) { if (typeName.matches(\"number\\\\([0-9]\\\\)\")) { return DbColumnType.INTEGER; } else if (typeName.matches(\"number\\\\(1[0-8]\\\\)\")) { return DbColumnType.LONG; } return DbColumnType.BIG_DECIMAL; } 在实际的生成代码上发现，若数据库定义NUMBER(15,2) （表示15位，后面有2位小数点）然后上面返回的数据类型都是BigDecimal，而在旧代码里定义的是double然后看了下，发现没有定义返回double类型的，所以只好重写了个方法返回double类型的 private static IColumnType toNumberType(String typeName) { if (typeName.matches(\"number\\\\([0-9]\\\\)\")) { return DbColumnType.INTEGER; } else if (typeName.matches(\"number\\\\(1[0-8]\\\\)\")) { return DbColumnType.LONG; } //TODO add on 20201208 if (typeName.matches(\"number\\\\(1[0-8],[0-9]\\\\)\")) { return DOUBLE; } if (typeName.matches(\"number\\\\(3[0-8],[0-9]\\\\)\")) { return DOUBLE; } return DbColumnType.BIG_processTypeConvertDECIMAL; } 然后在引用上，发现自己重写了OracleTypeConvert中的processTypeConvert方法没有生效， 只好自己写了个类MyOracleTypeConvert，然后再引入 protected DataSourceConfig getOracleDataSourceConfig() { DataSourceConfig d = new DataSourceConfig() .setDbType(DbType.ORACLE)// 数据库类型 /*.setTypeConvert(new OracleTypeConvert() { // 自定义数据库表字段类型转换【可选】 public IColumnType processTypeConvert(String fieldType) { System.out.println(\"转换类型：\" + fieldType); // if ( fieldType.toLowerCase().contains( \"tinyint\" ) ) { // return DbColumnType.BOOLEAN; // } if (fieldType.toLowerCase().contains(\"number\")) { return AbstractMybatisPlusGenerator.toNumberType(fieldType); } return super.processTypeConvert(getGlobalConfig(), fieldType); } })*/ //TODO 上面重写processTypeConvert不生效，所以改为用自己的 .setTypeConvert(new MyOracleTypeConvert() { // 自定义数据库表字段类型转换【可选】 public IColumnType processTypeConvert(String fieldType) { System.out.println(\"转换类型：\" + fieldType); return super.processTypeConvert(getGlobalConfig(), fieldType); } }) .setDriverName(\"oracle.jdbc.driver.OracleDriver\") .setUsername(getDataBaseInfo().getUsername()) .setPassword(getDataBaseInfo().getPassword()) .setUrl(getDataBaseInfo().getUrl()); if (!StringUtils.isEmpty(getDataBaseInfo().getSchemaname())) { //oracle的看使用处ConfigBuilder类中，会默认设置为用户名，也就是username d.setSchemaName(getDataBaseInfo().getSchemaname()); } return d; } 参考： https://blog.csdn.net/kanglong129/article/details/98360631 "},"中间件/redis/redis发布订阅-消息接收.html":{"url":"中间件/redis/redis发布订阅-消息接收.html","title":"redis发布订阅-消息接收","keywords":"","body":" io.lettuce.core.pubsub.PubSubCommandHandler#doNotifyMessage ``` "},"中间件/redis/redis和redisson自动装配.html":{"url":"中间件/redis/redis和redisson自动装配.html","title":"redis和redisson自动装配","keywords":"","body":" RedisAutoConfiguration spring-boot-autoconfigure包下： package org.springframework.boot.autoconfigure.data.redis; import java.net.UnknownHostException; import org.springframework.boot.autoconfigure.condition.ConditionalOnClass; import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean; import org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Import; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.core.RedisOperations; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.core.StringRedisTemplate; @Configuration( proxyBeanMethods = false ) @ConditionalOnClass({RedisOperations.class}) @EnableConfigurationProperties({RedisProperties.class}) @Import({LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class}) public class RedisAutoConfiguration { public RedisAutoConfiguration() { } @Bean @ConditionalOnMissingBean( name = {\"redisTemplate\"} ) public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { RedisTemplate template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } } 可以看到我们不配置RedisTemplate，只需要在配置文件添加RedisProperties里的属性即可但是他这个保存到redis的时候没有序列化的,在redis里看可能会乱码 RedissonAutoConfiguration 看redisson-spring-boot-starter下的RedissonAutoConfiguration org.redisson.spring.starter.RedissonAutoConfiguration 下面也会创建redissonConnectionFactory、RedisTemplate等，同时RedissonAutoConfiguration用了AutoConfigureBefore，会比RedisAutoConfiguration先装配 @Configuration @ConditionalOnClass({Redisson.class, RedisOperations.class}) @AutoConfigureBefore({RedisAutoConfiguration.class}) @EnableConfigurationProperties({RedissonProperties.class, RedisProperties.class}) public class RedissonAutoConfiguration { @Autowired private RedissonProperties redissonProperties; @Autowired private RedisProperties redisProperties; @Autowired private ApplicationContext ctx; public RedissonAutoConfiguration() { } @Bean @ConditionalOnMissingBean( name = {\"redisTemplate\"} ) public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean({StringRedisTemplate.class}) public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean({RedisConnectionFactory.class}) public RedissonConnectionFactory redissonConnectionFactory(RedissonClient redisson) { return new RedissonConnectionFactory(redisson); } "},"中间件/shardingsphere/sharding-jdbc实现读写分离.html":{"url":"中间件/shardingsphere/sharding-jdbc实现读写分离.html","title":"sharding-jdbc实现读写分离","keywords":"","body":" 1、准备数据库 创建3个数据库，然后在各自数据库里创建一个user表 CREATE DATABASE `ds-master` CHARACTER SET 'utf8' COLLATE 'utf8_general_ci'; CREATE DATABASE `ds-slave0` CHARACTER SET 'utf8' COLLATE 'utf8_general_ci'; CREATE DATABASE `ds-slave1` CHARACTER SET 'utf8' COLLATE 'utf8_general_ci'; CREATE TABLE `user`( id bigint(64) auto_increment not null, city varchar(20) not null, name varchar(20) not null, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 2、引入Maven依赖 4.0.0-RC1 org.apache.shardingsphere sharding-jdbc-spring-boot-starter ${sharding-sphere.version} org.apache.shardingsphere sharding-jdbc-spring-namespace ${sharding-sphere.version} 3、配置数据源和读写分离 spring: shardingsphere: datasource: names: ds-master,ds-slave0,ds-slave1 ds-master: type: com.alibaba.druid.pool.DruidDataSource driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ds-master?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai username: root password: root ds-slave0: type: com.alibaba.druid.pool.DruidDataSource driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ds-slave0?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai username: root password: root ds-slave1: type: com.alibaba.druid.pool.DruidDataSource driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ds-slave1?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai username: root password: root masterslave: name: ds-ms # 名称,合法的字符串即可,但如果涉及到在读写分离的基础上设置分库分表,则名称需要有意义才可以,另外,虽然目前没有强制要求,但主从库配置需要配置在实际关联的主从库上,如果配置的数据源之间主从是断开的状态,那么可能会发生写入的数据对于只读会话无法读取到的问题 masterDataSourceName: ds-master # 主库的DataSource名称 slaveDataSourceNames: # 从库的DataSource列表,至少需要有一个 - ds-slave0 - ds-slave1 loadBalanceAlgorithmClassName: org.apache.shardingsphere.api.algorithm.masterslave # MasterSlaveLoadBalanceAlgorithm接口的实现类,允许自定义实现 默认提供两个,配置路径为org.apache.shardingsphere.api.algorithm.masterslave下的RandomMasterSlaveLoadBalanceAlgorithm(随机Random)与RoundRobinMasterSlaveLoadBalanceAlgorithm(轮询:次数%从库数量) #loadBalanceAlgorithmType: #从库负载均衡算法类型，可选值：ROUND_ROBIN，RANDOM。若loadBalanceAlgorithmClassName存在则忽略该配置,默认为ROUND_ROBIN props: sql.show: true #是否开启SQL显示，默认值: false # acceptor.size: # accept连接的线程数量,默认为cpu核数2倍 # executor.size: #工作线程数量最大，默认值: 无限制 # max.connections.size.per.query: # 每个查询可以打开的最大连接数量,默认为1 # proxy.frontend.flush.threshold: # proxy的服务时候,对于单个大查询,每多少个网络包返回一次 # proxy.transaction.type: # 默认LOCAL,proxy的事务模型 允许LOCAL,XA,BASE三个值 LOCAL无分布式事务,XA则是采用atomikos实现的分布式事务 BASE目前尚未实现 # proxy.opentracing.enabled: # 是否启用opentracing # proxy.backend.use.nio: # 是否采用netty的NIO机制连接后端数据库,默认False ,使用epoll机制 # proxy.backend.max.connections: # 使用NIO而非epoll的话,proxy后台连接每个netty客户端允许的最大连接数量(注意不是数据库连接限制) 默认为8 # proxy.backend.connection.timeout.seconds: #使用nio而非epoll的话,proxy后台连接的超时时间,默认60s # check.table.metadata.enabled: # 是否在启动时候,检查sharing的表的实际元数据是否一致,默认False 4、新建springboot的Application应用启动类 注意排除掉DruidDataSourceAutoConfigure类的自动加载，引入Swagger package com.demo; import com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceAutoConfigure; import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.Banner; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import springfox.documentation.swagger2.annotations.EnableSwagger2; import java.util.HashMap; @SpringBootApplication(exclude = {DruidDataSourceAutoConfigure.class}) @EnableSwagger2 @MapperScan({ \"com.demo.mapper*\", \"com.demo.open.mapper*\" })//这里不定义的话，则要在mapper文件里加上@Mapper注解 public class ShardingJdbcDemoApplication { public static void main(String[] args) { SpringApplication app = new SpringApplication(ShardingJdbcDemoApplication.class); app.setBannerMode(Banner.Mode.OFF); app.run(args); HashMap hashMap=new HashMap(); } } 5、新建实体对象User package com.demo.entity; import lombok.Data; import java.io.Serializable; @Data public class User implements Serializable { private static final long serialVersionUID = -1; private Long id; private String city = \"\"; private String name = \"\"; } 6、新建mapper package com.demo.mapper; import java.util.List; import com.demo.entity.User; import org.apache.ibatis.annotations.Mapper; @Mapper public interface UserMapper { Long addUser(User user); List list(); User findById(Long id); User findByName(String name); } 7、新建UserService以及实现类 package com.demo.service; import com.demo.entity.User; import java.util.List; public interface UserService { List list(); Long add(User user); User findById(Long id); User findByName(String name); } 实现： package com.demo.service.impl; import com.demo.entity.User; import com.demo.mapper.UserMapper; import com.demo.service.UserService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import java.util.List; @Service public class UserServiceImpl implements UserService { @Autowired private UserMapper userMapper; public List list() { return userMapper.list(); } public Long add(User user) { return userMapper.addUser(user); } @Override public User findById(Long id) { return userMapper.findById(id); } @Override public User findByName(String name) { return userMapper.findByName(name); } } 8、新建UserController package com.demo.web; import com.demo.entity.User; import com.demo.service.UserService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; @RestController public class UserController { @Autowired private UserService userService; @GetMapping(\"/users\") public Object list() { return userService.list(); } @GetMapping(\"/add\") public Object add() { for (long i = 0; i 9、swagger测试 访问http://localhost:8081/swagger-ui.html#/ 9.1、增加数据 先调用http://localhost:8081/add方法增加主库ds-master的数据 查看数据库，ds-master已有数据，而ds-slave0,ds-slave1没有数据 9.2、查询 调用http://localhost:8081/users查询，查看后台日志如下： 2019-08-07 11:40:09,920 http-nio-8081-exec-4 INFO org.apache.shardingsphere.core.route.SQLLogger:89 [http-nio-8081-exec-4] Rule Type: master-slave 2019-08-07 11:40:09,920 http-nio-8081-exec-4 INFO org.apache.shardingsphere.core.route.SQLLogger:89 [http-nio-8081-exec-4] SQL: SELECT u.* FROM user u ::: DataSources: ds-slave0 分析日志： 1、Rule Type规则类型为主从master-slave，也就是读写分离2、SQL: SELECT u.* FROM user u ::: DataSources: ds-slave0 这句说明是从从库ds-slave0查询的 参考：https://shardingsphere.apache.org/document/current/cn/manual/sharding-jdbc/usage/read-write-splitting/ "},"中间件/spring/spring-core工具包.html":{"url":"中间件/spring/spring-core工具包.html","title":"spring-core工具包","keywords":"","body":" org.springframework.util.ReflectionUtils#findMethod(java.lang.Class, java.lang.String, java.lang.Class...) 使用举例： org.redisson.spring.starter.RedissonAutoConfiguration Method clusterMethod = ReflectionUtils.findMethod(RedisProperties.class, \"getCluster\"); ``` "},"自动化/文档自动化生成.html":{"url":"自动化/文档自动化生成.html","title":"文档自动化生成","keywords":"","body":" ``` "},"devops/docker/docker-install.html":{"url":"devops/docker/docker-install.html","title":"docker安装","keywords":"","body":"CentOS 7 (使用yum进行安装) # step 1: 安装必要的一些系统工具 sudo yum install -y yum-utils device-mapper-persistent-data lvm2 # Step 2: 添加软件源信息 sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # Step 3: 更新并安装 Docker-CE sudo yum makecache fast sudo yum -y install docker-ce # Step 4: 开启Docker服务 sudo service docker start # 注意： # 官方软件源默认启用了最新的软件，您可以通过编辑软件源的方式获取各个版本的软件包。例如官方并没有将测试版本的软件源置为可用，你可以通过以下方式开启。同理可以开启各种测试版本等。 # vim /etc/yum.repos.d/docker-ee.repo # 将 [docker-ce-test] 下方的 enabled=0 修改为 enabled=1 # # 安装指定版本的Docker-CE: # Step 1: 查找Docker-CE的版本: # yum list docker-ce.x86_64 --showduplicates | sort -r # Loading mirror speeds from cached hostfile # Loaded plugins: branch, fastestmirror, langpacks # docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable # docker-ce.x86_64 17.03.1.ce-1.el7.centos @docker-ce-stable # docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable # Available Packages # Step2 : 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.0.ce.1-1.el7.centos) # sudo yum -y install docker-ce-[VERSION] docker阿里安装 https://yq.aliyun.com/articles/110806 将docker加入随主机自启动列表：sudo chkconfig docker on [root@localhost hoby]# sudo chkconfig docker on Note: Forwarding request to 'systemctl enable docker.service'. Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service. [root@localhost hoby]# "},"devops/docker/docker实战1.html":{"url":"devops/docker/docker实战1.html","title":"docker实战1","keywords":"","body":" 运行docker cd /opt/zch docker build . --tag=\"tobe/pc-admin-web:v1.0.0\" docker run -d -p 9096:9096 -v /usr/local/logs/:/opt/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 firewall-cmd --zone=public --add-port=9096/tcp --permanent firewall-cmd --reload docker ps 拉取镜像 命令格式为： docker pull [选项] [Docker Registry地址]: Docker Registry地址：地址的格式一般是 [:端口号]。默认地址是 Docker Hub。 例如： docker pull ubuntu:14.04 公司的: docker pull 192.168.1.1/tobe/java:8-jre 镜像构建 docker build 命令进行镜像构建。其格式为： docker build [选项] $ docker build -t nginx:v3 . 在这里我们指定了最终镜像的名称 -t nginx:v3 ，构建成功后，我们可以像之前运行 nginx:v2 那样来运行这个镜像，其结果会和 nginx:v2 一样。 镜像运行 docker run --name web2 -d -p 81:80 nginx:v2 这里我们命名为新的服务为 web2 ，并且映射到 81 端口。如果是 Docker for Mac/Windows 或 Linux 桌面的话，我们就可以直接访问 http://localhost:81 看到结果，其内容应该和之前修 改后的 webserver 一样。 docker run --name webserver -d -p 80:80 nginx 这条命令会用 nginx 镜像启动一个容器，命名为 webserver ，并且映射了 80 端口，这样我 们可以用浏览器去访问这个 nginx 服务器。 Docker重命名镜像名称和TAG # docker tag IMAGEID(镜像id) REPOSITORY:TAG（仓库：标签） [root@localhost hoby]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE dohoby/kubernetes 3.1.12 0c14773001c8 16 minutes ago 193MB [root@localhost hoby]# docker tag 0c14773001c8 k8s.gcr.io/etcd-amd64:3.1.12 [root@localhost hoby]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE dohoby/kubernetes 3.1.12 0c14773001c8 16 minutes ago 193MB k8s.gcr.io/etcd-amd64 3.1.12 0c14773001c8 16 minutes ago 193MB "},"devops/docker/docker实战3-运行和查看.html":{"url":"devops/docker/docker实战3-运行和查看.html","title":"docker实战3-运行和查看","keywords":"","body":" Dockerfile FROM java:8-jre MAINTAINER tobe ADD pc-admin-web.jar /usr/local/tobe/pc/ CMD [\"java\", \"-Xms500m\", \"-Xmx1024m\", \"-jar\", \"/usr/local/tobe/pc/pc-admin-web.jar\"] EXPOSE 8080 运行docker步骤 cd /opt/zch docker build . --tag=\"tobe/pc-admin-web:v1.0.0\" docker run -d -p 8080:8080 -v /usr/local/logs/:/opt/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 注：经实战，发现必须配置成8080:8080，而且Dockfile文件里也是8080才能访问 问题1：-v是挂载宿主主机的目录，实战发现那个目录下没有日志文件， 问题2：删除容器和重新docker run都发现项目接口没有更新，是不是只能重新build个镜像 docker run -d -p 8080:8080 -v /usr/local/logs/:/var/lib/docker/containers/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 docker run -d -p 8080:8080 -v /usr/local/logs/:/opt/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 开放防火墙 firewall-cmd --zone=public --add-port=9096/tcp --permanent firewall-cmd --reload 查看容器 docker ps -a 查看日志 docker logs -f 容器名，用docker ps查看，比如 docker logs -f pc-admin-web-1.0.0 docker logs -f fullfilment --tail=500 访问： curl -v http://172.16.17.250:8080/swagger-ui.html 删除容器 删除容器 docker rmi 容器id 停止所有容器（删除容器才能删除images）： docker stop $(docker ps -a -q) 删除所有容器： docker rm $(docker ps -a -q) 删除镜像 删除images docker rmi 删除untagged images，也就是那些id为的image docker rmi $(docker images | grep \"^\" | awk \"{print $3}\") 删除全部image docker rmi $(docker images -q) Linux上tobe项目做的操作 vi pc-admin-web/src/main/resources/application.yaml cp pc-admin-web/target/pc-admin-web.jar /opt/zch 下面的是实战，可以不看 docker build [root@localhost zch]# pwd /opt/zch [root@localhost zch]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hello-world latest 05a3bd381fc2 7 weeks ago 1.84kB 192.168.1.1/tobe/java 8-jre e44d62cf8862 9 months ago 311MB [root@localhost zch]# docker build . --tag=\"tobe/pc-admin-web:v1.0.0\" Sending build context to Docker daemon 32.74MB Step 1/5 : FROM java:8-jre 8-jre: Pulling from library/java Digest: sha256:b91008e234402fc87e7889d6af1f36b6ece844c05989236d83d1f658a6f329b0 Status: Downloaded newer image for java:8-jre ---> e44d62cf8862 Step 2/5 : MAINTAINER tobe ---> Running in bd1e3b4e96c1 ---> 77598a1df94a Removing intermediate container bd1e3b4e96c1 Step 3/5 : ADD pc-admin-web.jar /usr/local/tobe/pc/ ---> 31ce18cf19af Step 4/5 : CMD java -Xms500m -Xmx1024m -jar /usr/local/tobe/pc/pc-admin-web.jar ---> Running in d68f92bec092 ---> 75c9a968da39 Removing intermediate container d68f92bec092 Step 5/5 : EXPOSE 9096 ---> Running in 219782caa18b ---> 1bd7a778ba13 Removing intermediate container 219782caa18b Successfully built 1bd7a778ba13 Successfully tagged tobe/pc-admin-web:v1.0.0 [root@localhost zch]# 看下面的，看到最终构建的是上面运行docker中的 docker build . --tag=\"tobe/pc-admin-web:v1.0.0\" 这个命令打的tag标签,如果上面命令报错，尝试把逗号放最后:分号前面对应REPOSITORY，分号后面对应TAG [root@localhost zch]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE tobe/pc-admin-web v1.0.0 1bd7a778ba13 4 minutes ago 344MB hello-world latest 05a3bd381fc2 7 weeks ago 1.84kB 192.168.1.1/tobe/java 8-jre e44d62cf8862 9 months ago 311MB java 8-jre e44d62cf8862 9 months ago 311MB [root@localhost zch]# docker run： [root@localhost zch]# docker run -d -p 9096:9096 -v /usr/local/logs/:/opt/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 f9a08bb82e2650bebed3eb3185a383ec121114ce3ef79ee2166d7a46329ced85 [root@localhost zch]# 经实战，发现必须配置成8080:8080，而且Dockfile文件里也是8080才能访问 docker run -d -p 8080:8080 -v /usr/local/logs/:/opt/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 [root@localhost zch]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f9a08bb82e26 tobe/pc-admin-web:v1.0.0 \"java -Xms500m -Xm...\" 2 minutes ago Up 2 minutes pc-admin-web-1.0.0 [root@localhost zch]# [root@localhost zch]# firewall-cmd --zone=public --add-port=9096/tcp --permanent FirewallD is not running [root@localhost zch]# firewall-cmd --reload FirewallD is not running [root@localhost zch]# 移除容器和镜像 http://www.cnblogs.com/q4486233/p/6482711.html 1.停止所有的container，这样才能够删除其中的images： docker stop $(docker ps -a -q) 如果想要删除所有container的话再加一个指令： docker rm $(docker ps -a -q) 2.查看当前有些什么images docker images 3.删除images，通过image的id来指定删除谁 docker rmi 想要删除untagged images，也就是那些id为的image的话可以用 docker rmi $(docker images | grep \"^\" | awk \"{print $3}\") 要删除全部image的话 docker rmi $(docker images -q) 实战 命令必须加-a才会显示容器出来 ， docker ps -a 查询出来用下面命令删除某个容器 docker rm 容器id [root@localhost zch]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 11b8d5b0a241 tobe/pc-admin-web:v1.0.0 \"java -Xms500m -Xm...\" 2 days ago Exited (143) 5 minutes ago pc-admin-web-1.0.0 [root@localhost zch]# docker rm 11b8d5b0a241 11b8d5b0a241 [root@localhost zch]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 查看日志 docker logs -f pc-admin-web-1.0.0 "},"devops/docker/docker实战4-挂载目录.html":{"url":"devops/docker/docker实战4-挂载目录.html","title":"docker实战4-挂载目录","keywords":"","body":" 查看容器的详细信息 docker inspect 容器id [root@localhost zch]# docker inspect 65db9b511573 [ { \"Id\": \"65db9b511573294c25d5ab42e7f9f14c44b12d562037d111b6a385d43c2f0fa1\", \"Created\": \"2017-11-06T01:32:39.592582918Z\", \"Path\": \"java\", \"Args\": [ \"-Xms500m\", \"-Xmx1024m\", \"-jar\", \"/usr/local/tobe/pc/pc-admin-web.jar\" ], \"State\": { \"Status\": \"running\", \"Running\": true, \"Paused\": false, \"Restarting\": false, \"OOMKilled\": false, \"Dead\": false, \"Pid\": 4042, \"ExitCode\": 0, \"Error\": \"\", \"StartedAt\": \"2017-11-06T01:32:39.729399639Z\", \"FinishedAt\": \"0001-01-01T00:00:00Z\" }, \"Image\": \"sha256:d7f0891abbd7a77169fa646ab1da8778ee15643a64322b982bf512b01fd080d0\", \"ResolvConfPath\": \"/var/lib/docker/containers/65db9b511573294c25d5ab42e7f9f14c44b12d562037d111b6a385d43c2f0fa1/resolv.conf\", \"HostnamePath\": \"/var/lib/docker/containers/65db9b511573294c25d5ab42e7f9f14c44b12d562037d111b6a385d43c2f0fa1/hostname\", \"HostsPath\": \"/var/lib/docker/containers/65db9b511573294c25d5ab42e7f9f14c44b12d562037d111b6a385d43c2f0fa1/hosts\", \"LogPath\": \"/var/lib/docker/containers/65db9b511573294c25d5ab42e7f9f14c44b12d562037d111b6a385d43c2f0fa1/65db9b511573294c25d5ab42e7f9f14c44b12d562037d111b6a385d43c2f0fa1-json.log\", \"Name\": \"/pc-admin-web-1.0.0\", \"RestartCount\": 0, \"Driver\": \"overlay\", \"Platform\": \"linux\", \"MountLabel\": \"\", \"ProcessLabel\": \"\", \"AppArmorProfile\": \"\", \"ExecIDs\": null, \"HostConfig\": { \"Binds\": [ \"/usr/local/logs/:/opt/\" ], \"ContainerIDFile\": \"\", \"LogConfig\": { \"Type\": \"json-file\", \"Config\": {} }, \"NetworkMode\": \"host\", \"PortBindings\": { \"8080/tcp\": [ { \"HostIp\": \"\", \"HostPort\": \"8080\" } ] }, \"RestartPolicy\": { \"Name\": \"no\", \"MaximumRetryCount\": 0 }, \"AutoRemove\": false, \"VolumeDriver\": \"\", \"VolumesFrom\": null, \"CapAdd\": null, \"CapDrop\": null, \"Dns\": [], \"DnsOptions\": [], \"DnsSearch\": [], \"ExtraHosts\": null, \"GroupAdd\": null, \"IpcMode\": \"\", \"Cgroup\": \"\", \"Links\": null, \"OomScoreAdj\": 0, \"PidMode\": \"\", \"Privileged\": false, \"PublishAllPorts\": false, \"ReadonlyRootfs\": false, \"SecurityOpt\": null, \"UTSMode\": \"\", \"UsernsMode\": \"\", \"ShmSize\": 67108864, \"Runtime\": \"runc\", \"ConsoleSize\": [ 0, 0 ], \"Isolation\": \"\", \"CpuShares\": 0, \"Memory\": 0, \"NanoCpus\": 0, \"CgroupParent\": \"\", \"BlkioWeight\": 0, \"BlkioWeightDevice\": [], \"BlkioDeviceReadBps\": null, \"BlkioDeviceWriteBps\": null, \"BlkioDeviceReadIOps\": null, \"BlkioDeviceWriteIOps\": null, \"CpuPeriod\": 0, \"CpuQuota\": 0, \"CpuRealtimePeriod\": 0, \"CpuRealtimeRuntime\": 0, \"CpusetCpus\": \"\", \"CpusetMems\": \"\", \"Devices\": [], \"DeviceCgroupRules\": null, \"DiskQuota\": 0, \"KernelMemory\": 0, \"MemoryReservation\": 0, \"MemorySwap\": 0, \"MemorySwappiness\": null, \"OomKillDisable\": false, \"PidsLimit\": 0, \"Ulimits\": null, \"CpuCount\": 0, \"CpuPercent\": 0, \"IOMaximumIOps\": 0, \"IOMaximumBandwidth\": 0 }, \"GraphDriver\": { \"Data\": { \"LowerDir\": \"/var/lib/docker/overlay/259ae4941ced45fa1397474685a29b680143b2017c59079aa4cc79360f2974f2/root\", \"MergedDir\": \"/var/lib/docker/overlay/f6fc30704f20c0538c159a9e388ddbde79696b0c841d2cf6ee3a57ec92b4210a/merged\", \"UpperDir\": \"/var/lib/docker/overlay/f6fc30704f20c0538c159a9e388ddbde79696b0c841d2cf6ee3a57ec92b4210a/upper\", \"WorkDir\": \"/var/lib/docker/overlay/f6fc30704f20c0538c159a9e388ddbde79696b0c841d2cf6ee3a57ec92b4210a/work\" }, \"Name\": \"overlay\" }, \"Mounts\": [ { \"Type\": \"bind\", \"Source\": \"/usr/local/logs\", \"Destination\": \"/opt\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" } ], \"Config\": { \"Hostname\": \"localhost.localdomain\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"ExposedPorts\": { \"8080/tcp\": {} }, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\", \"LANG=C.UTF-8\", \"JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre\", \"JAVA_VERSION=8u111\", \"JAVA_DEBIAN_VERSION=8u111-b14-2~bpo8+1\", \"CA_CERTIFICATES_JAVA_VERSION=20140324\" ], \"Cmd\": [ \"java\", \"-Xms500m\", \"-Xmx1024m\", \"-jar\", \"/usr/local/tobe/pc/pc-admin-web.jar\" ], \"ArgsEscaped\": true, \"Image\": \"tobe/pc-admin-web:v1.0.0\", \"Volumes\": null, \"WorkingDir\": \"\", \"Entrypoint\": null, \"OnBuild\": null, \"Labels\": {} }, \"NetworkSettings\": { \"Bridge\": \"\", \"SandboxID\": \"8ec994d4adf3a820ccfff026d220506e4fe28a1542f72321eac09319da4ec386\", \"HairpinMode\": false, \"LinkLocalIPv6Address\": \"\", \"LinkLocalIPv6PrefixLen\": 0, \"Ports\": {}, \"SandboxKey\": \"/var/run/docker/netns/default\", \"SecondaryIPAddresses\": null, \"SecondaryIPv6Addresses\": null, \"EndpointID\": \"\", \"Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"IPAddress\": \"\", \"IPPrefixLen\": 0, \"IPv6Gateway\": \"\", \"MacAddress\": \"\", \"Networks\": { \"host\": { \"IPAMConfig\": null, \"Links\": null, \"Aliases\": null, \"NetworkID\": \"dac528ad522ee4f3d29f73d3c8e25bf85891cedfd4d21e8a9f2cd6d573268b23\", \"EndpointID\": \"d8545b90b5730af9e28649144d3774a23a0b1d7d0a6f9b3fb14aab66b75bf795\", \"Gateway\": \"\", \"IPAddress\": \"\", \"IPPrefixLen\": 0, \"IPv6Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"MacAddress\": \"\", \"DriverOpts\": null } } } } ] [root@localhost zch]# 进入容器 -it 命令是以交互方式进入容器 [root@localhost zch]# docker run -it -p 8080:8080 -v /usr/local/logs/:/opt/ --name=\"pc-admin-web-1.0.0\" --net=host tobe/pc-admin-web:v1.0.0 /bin/bash 列出容器的目录 root@localhost:/# ls bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var root@localhost:/# 查看Dockerfile文件复制进去的jar包 Dockerfile文件中有句： ADD pc-admin-web.jar /usr/local/tobe/pc/ 查看 root@localhost:/# ls /usr/local/tobe/pc/ pc-admin-web.jar 检查挂载是否成功 docker run命令中有个参数，冒号前面是宿主主机的目录，冒号后面是容器的目录，是将宿主主机的目录挂载到容器的/opt/目录下， -v /usr/local/logs/:/opt/ 检查，在容器的/opt/目录下新建个a文件，然后到宿主主机上发现有个a文件,同样，在宿主主机新建个b文件，然后在容器里发现也有b文件 后台进程运行容器，如何进入容器 docker exec -i -t ea0928cfcad2 /bin/bash 从容器拷贝文件到宿主机 拷贝方式为： docker cp 容器名：容器中要拷贝的文件名及其路径 要拷贝到宿主机里面对应的路径 docker cp sp-comm:/logs/192.168.1.1mon/192.168.1.1mon.log . docker cp sp-comm:/logs/192.168.1.1mon/20180907/192.168.1.1mon.0.log.zip . 参考：https://blog.csdn.net/dongdong9223/article/details/71425077 "},"devops/docker/docker实战5-曲线拉取国外镜像.html":{"url":"devops/docker/docker实战5-曲线拉取国外镜像.html","title":"docker实战5-曲线拉取国外镜像","keywords":"","body":"创建镜像仓库 安装k8s需要很多镜像，这些镜像，若翻墙不了或者公司禁止上谷歌的镜像仓库，就没法获取，这里就需要曲线拉取镜像了， 如 [root@k8s-node-2 flannel]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE k8s.gcr.io/kube-proxy-amd64 v1.10.3 4261d315109d 2 weeks ago 97.1 MB k8s.gcr.io/kube-apiserver-amd64 v1.10.3 e03746fe22c3 2 weeks ago 225 MB k8s.gcr.io/kube-scheduler-amd64 v1.10.3 353b8f1d102e 2 weeks ago 50.4 MB k8s.gcr.io/kube-controller-manager-amd64 v1.10.3 40c8d10b2d11 2 weeks ago 148 MB k8s.gcr.io/etcd-amd64 3.1.12 52920ad46f5b 2 months ago 193 MB quay.io/coreos/flannel v0.10.0-amd64 f0fad859c909 4 months ago 44.6 MB k8s.gcr.io/pause-amd64 3.1 da86e6ba6ca1 5 months ago 742 kB docker.io/kubernetes/pause latest f9d5de079539 3 years ago 240 kB gcr.io/google_containers/pause-amd64 3.0 f9d5de079539 3 years ago 240 kB 根据上面所需要的镜像，制作Dockerfile，并且上传到github仓库，参考我的https://github.com/dohoby/kubernetes 制作镜像 https://hub.docker.com 登录此网站，参考：https://blog.csdn.net/sjyu_ustc/article/details/79990858 构建镜像 拉取镜像 新建拉取镜像脚本 #!/bin/bash images=(kube-apiserver-amd64:v1.10.3 kube-controller-manager-amd64:v1.10.3 kube-proxy-amd64:v1.10.3 kube-scheduler-amd64:v1.10.3 pause-amd64:3.1 etcd-amd64:3.1.12) for image in ${images[@]} ; do docker pull dohoby/$image docker tag dohoby/$image k8s.gcr.io/$image docker rmi dohoby/$image done 拉取结果： [root@localhost hoby]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE k8s.gcr.io/etcd-amd64 3.1.12 a63d07bcb093 29 minutes ago 193MB k8s.gcr.io/pause-amd64 3.1 623c4d30c6b4 32 minutes ago 742kB k8s.gcr.io/kube-scheduler-amd64 v1.10.3 788f5b9849cd 35 minutes ago 50.4MB k8s.gcr.io/kube-proxy-amd64 v1.10.3 0dce35f14844 39 minutes ago 97.1MB k8s.gcr.io/kube-controller-manager-amd64 v1.10.3 298bb46456e1 43 minutes ago 148MB k8s.gcr.io/kube-apiserver-amd64 v1.10.3 d866c9b24ddd About an hour ago 225MB "},"devops/jenkins/Jenkins全局工具配置.html":{"url":"devops/jenkins/Jenkins全局工具配置.html","title":"Jenkins全局工具配置","keywords":"","body":" 因为是在下面配置了全局工具，所以Jenkins能识别java命令，git命令和mvn命令，但是没有配置node相关的npm命令， 所以Jenkins跑node项目时会报错，但是不知道为什么docker的不用配置就可以 "},"devops/kettle/kettle数据同步技术攻克.html":{"url":"devops/kettle/kettle数据同步技术攻克.html","title":"kettle数据同步技术攻克","keywords":"","body":" 项目需求 通过在Linux下命令行启动kettle作业实现从sql server到mysql的同步，其中mysql库中完全没有任何表，需要创建 技术攻克 1、数据库动态设置 kettle数据库同步必须指定从哪个库同步到哪个库，在开发时每个作业和转换中都要设置数据库，而在测试环境和生产环境中这些库都不一样，所以有必要进行数据库动态设置 推荐阅读： http://blog.itpub.net/27120361/viewspace-1412216/ 实战：http://note.youdao.com/noteshare?id=14eb2648fe33ad61c237e30768ecb1d3 2、命令行启动作业（包括日志配置、定时） 3、动态同步所有表 可以动态同步所有表，但是有问题1、如果2张表的定义不一样，数据有问题则会导致报错，进而同步失败 ，比如mysql中有个字段设置不能未空，但sql server中的数据有空则报错2、第一次同步过去没问题，第二次则发生错误，原因是使用了表输出，但是表输出貌似是不能更新的， 推荐阅读：http://ainidehsj.iteye.com/blog/1735434 4、mysql数据库创建(与kettle无关) 通过脚本或者Java代码实现 http://www.cnblogs.com/avivaye/p/4938592.html 5、异常处理 控制到每张表的同步，尽量减少同步错误，而且一有错误立刻邮件通知，避免错误 6、乱码 http://duguyiren3476.iteye.com/blog/1345358 7、要预防的问题 http://pentahochina.com:8080/biforum/topic-29-1.html 感悟 需要用心，静下心去看错误，不要急，不要害怕，要相信能实现这功能，除非用尽办法还是解决不了 "},"devops/maven/maven插件/maven插件.html":{"url":"devops/maven/maven插件/maven插件.html","title":"maven插件","keywords":"","body":" Maven中maven-source-plugin,maven-javadoc-plugin插件的使用 把项目通过maven生产源码包和文档包并发布到自己的私服上，经过查看mavne官网发现有两个maven插件可以做到这些工作，一个是maven-source-plugin，另一个是maven-javadoc-plugin 一：首先在你的项目的pom.xml文件中加入如下配置： org.apache.maven.plugins maven-javadoc-plugin 2.10.2 true attach-javadocs jar maven-source-plugin 2.4 true package jar-no-fork ``` "},"devops/maven/maven打包/maven更改版本号.html":{"url":"devops/maven/maven打包/maven更改版本号.html","title":"maven更改版本号","keywords":"","body":" 1、pom添加versions-maven-plugin插件 org.codehaus.mojo versions-maven-plugin false 2、设置新版本号 注意要在父项目下执行，子项目才会一起更改版本号，不是这个项目的子项目的不会更改 mvn versions:set -DnewVersion=2.1.0 3、更新所有子 Module 的版本 mvn versions:update-child-modules 4、更新顶级项目的parent版本 在使用Spring Boot的多Module项目时，我们可能需要更新项目所依赖的Spring Boot版本。我们可以使用如下命令来进行更新。 mvn versions:update-parent 参考： https://blog.csdn.net/u012921921/article/details/107557880 ``` "},"devops/maven/maven打包/maven命令行推送jar包.html":{"url":"devops/maven/maven打包/maven命令行推送jar包.html","title":"maven命令行推送jar包","keywords":"","body":" 1、命令格式： mvn deploy:deploy-file -Dfile= -DgroupId= -DartifactId= -Dversion= -Dpackaging=jar -Durl=file:./maven-repository/ -DrepositoryId=maven-repository -DupdateReleaseInfo=true 2、可以（执行命令在D:\\1） mvn deploy:deploy-file -Dfile=d:\\1\\kettle-core-7.0.0.0-25.jar -DgroupId=pentaho-kettle -DartifactId=kettle-core -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases mvn clean deploy:deploy-file -Dfile=d:\\1\\kettle-core-7.0.0.0-25.jar -DgroupId=pentaho-kettle -DartifactId=kettle-core -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases 上面命令推送过一次后，想再推送，必须改版本后才能推送，因为没法更新release的版本的，会报下面的错误 3、也可以（和上面命令不同的地方就是执行命令和jar包所在位置不一样，执行命令在D:\\idea-workspace2\\ebaysdk） mvn deploy:deploy-file -Dfile=d:\\1\\kettle-core-7.0.0.0-25.jar -DgroupId=pentaho-kettle -DartifactId=kettle-core -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases 报下面错，不能从本地的版本库位置deploy，必须像上面那样将jar包和pom包复制到其他目录下 4、未授权错误分析 mvn deploy:deploy-file -Dfile=d:\\1\\kettle-dbdialog-7.0.0.0-25.jar -DgroupId=pentaho-kettle -DartifactId=kettle-dbdialog -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releasess 和2的除了jar包名一样，为什么报下面的错，401未授权 注意是-DrepositoryId=nexus-releases这个后面多了个s, 这个-DrepositoryId的值必须和D:\\maven\\apache-maven-3.5.0\\conf\\settings.xml中配置的id一样 5、其他jar包 mvn deploy:deploy-file -Dfile=d:\\1\\kettle-dbdialog-7.0.0.0-25.jar -DgroupId=pentaho-kettle -DartifactId=kettle-dbdialog -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases mvn deploy:deploy-file -Dfile=d:\\1\\kettle-engine-7.0.0.0-25.jar -DgroupId=pentaho-kettle -DartifactId=kettle-engine -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases mvn deploy:deploy-file -Dfile=d:\\1\\kettle-jdbc-5.0.0.jar -DgroupId=pentaho-kettle -DartifactId=kettle-jdbc -Dversion=5.0.0 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases mvn deploy:deploy-file -Dfile=d:\\1\\metastore-7.0.0.0-25.jar -DgroupId=pentaho -DartifactId=metastore -Dversion=7.0.0.0-25 -Dpackaging=jar -Durl=http://192.168.1.73:8081/repository/maven-releases -DrepositoryId=nexus-releases 参考： http://www.trinea.cn/dev-tools/maven-sonatype-nexus-return-401-which-settings-xml-maven-is-using/ https://blog.csdn.net/zzb5682119/article/details/54137986 mvn deploy:deploy-file -Dfile=C:/Users/zhangzubin/Desktop/EisAPIForHA-2.1.jar -DgroupId=cn.evun -DartifactId=EisAPIForHA -Dversion=2.0 -Durl=http://218.75.72.114:8081/nexus/content/repositories/releases -DrepositoryId=nexus-release 关于安装第三方jar到Artifact, 从Artifact的官方上看到其实有很多种方法(请看这里),最简单的就是从Archiva的web 页面上找到Upload Artifact这个功能. 我使用的方法是maven的 deploy:deploy-file 命令,这种方法时要注意的是如果你要安装的jar和pom是位于本地repository的目录下,这个命令就会出错 (Cannot deploy artifact from the local repository…), 解决方法:将要安装的jar和pom copy到其它目录再安装,只要不在本地仓库目录都应该可以. https://www.jianshu.com/p/515fdbf92656 "},"devops/maven/maven打包/maven私服配置并且推送jar包.html":{"url":"devops/maven/maven打包/maven私服配置并且推送jar包.html","title":"maven私服配置并且推送jar包","keywords":"","body":" maven settings.xml修改 C:\\Users\\hoby.m2/settings.xml thirdparty admin Admin!@# releases admin Admin!@# snapshots admin Admin!@# 在需要上传jar包到私服的模块的父模块(父模块就可以，不用子模块)下添加下面的 releases http://10.20.150.115:8081/nexus/content/repositories/releases snapshots http://10.20.150.115:8081/nexus/content/repositories/snapshots 其中distributionManagement在project下 点击deploy上传 IDEA中Maven打包时如何跳过测试 方法一、直接使用IDEA提供的方式 Maven命令栏的工具栏有图标，上面就写着 Skip Tests 方法二、自己编辑maven命令 IDEA中Maven打包时如何跳过测试 "},"devops/maven/maven打包/maven引入lib文件夹下jar包.html":{"url":"devops/maven/maven打包/maven引入lib文件夹下jar包.html","title":"maven引入lib文件夹下jar包并且打包","keywords":"","body":" pom文件添加依赖 其中${pom.basedir}是指根目录，将外部jar包添加到根目录下的lib文件夹下pom文件添加依赖 pentaho-kettle kettle-jdbc 5.0.0 system ${pom.basedir}/lib/kettle-jdbc-5.0.0.jar 打包时或idea中启动Tomcat时发现没添加lib文件夹下的jar包解决办法 springboot下 org.springframework.boot spring-boot-maven-plugin true https://www.cnblogs.com/xiang--liu/p/11451521.html https://www.cnblogs.com/musarona/p/11204179.html 旧的打war包情况下 org.apache.maven.plugins maven-war-plugin ${project.basedir}/src/lib WEB-INF/lib/ **/*.jar 实际案例： org.apache.maven.plugins maven-war-plugin 2.1.1 fzsiotcard true src/main/profile WEB-INF src/main/webapp --> **/web.xml ${pom.basedir}/lib WEB-INF/lib/ **/*.jar src/main/webapp src/main/webapp/WEB-INF/web.xml false "},"devops/maven/maven用法/maven单继承问题.html":{"url":"devops/maven/maven用法/maven单继承问题.html","title":"maven单继承问题","keywords":"","body":" maven单继承问题 maven学习 ``` "},"devops/redis/redis在windows下安装.html":{"url":"devops/redis/redis在windows下安装.html","title":"redis在windows下安装","keywords":"","body":" 1、 https://www.cnblogs.com/zhaoyongjie-z/p/12548304.html 2、 3、 ``` "},"devops/uml/建模工具plantuml介绍.html":{"url":"devops/uml/建模工具plantuml介绍.html","title":"建模工具plantuml介绍","keywords":"","body":" 前言 听说过写程序画图吗，没听错吧，一般不是通过powerdesigner。没错，就是写程序画图。哈哈，本文就简单介绍下平时在项目开发中最常用的通过写程序来进行数据库建模，十分简单实用。 听说过写程序画图吗？ 没听错吧，一般不是通过powerdesigner或者visual studio来画吗，写程序怎么画 哈哈，你没听错，下面就让我简单介绍下plantuml给你 首先了解下UML是统一建模语言的意思，而PlantUML可以画UML各种图，比如类图、对象图、用例图、时序图等 那怎么开始用呢 首先要知道在很多软件上，比如sublime、notepad++、eclipse或者命令行上都可以使用PlantUML，但是必须得装一些必须的依赖软件，如果你在window下，则必须安装graphviz，下面列出安装的步骤 1、下载graphviz并安装 下载地址：http://www.graphviz.org/Download_windows.php安装目录：D:\\Program Files\\graphviz下 2、设置graphviz环境变量 a、新建GRAPHVIZ_DOT系统变量，设置其值为graphviz安装目录下的bin目录下的dot.exe文件路径D:\\Program Files\\graphviz\\bin\\dot.exeb、修改path变量，在后面添加D:\\Program Files\\graphviz\\bin; 3、验证安装和设置 进入windows命令行界面，输入dot -version，若显示graphviz相关信息即为安装和配置成功 eclipse下怎么使用呢 eclipse使用下首先得安装插件 打开 Eclipse，Help->install new software...。填入相应的 URL：http://plantuml.sourceforge.net/updatesite/搜索出来后安装即可，然后在window->show view下搜索出PlantUML然后在eclipse中显示相应的面板 那它有什么语法呢 它的语法很简单，下面就介绍下其语法以及平时开发常用的数据建模，也就是对象图 1、首先在任意工程下，新建一个后缀名为uml的文件2、该uml文件具有如下语法，先看个简单例子 @startuml class jd_doctor{ -id:String -skills:String } note left 这是个备注 end note @enduml https://www.ibm.com/developerworks/cn/opensource/os-cn-ecl-plantuml/ http://www.135editor.com/ http://plantuml.com/object-diagram http://bj.96weixin.com/ demo 待学习 PlantUML画类图(一) 类与类之间的关系 https://blog.csdn.net/u_ranfa/article/details/89646218 Java 类与类之间的关系 https://blog.csdn.net/u_ranfa/article/details/89645757 "},"elasticsearch/es实战/es实战1-常见命令.html":{"url":"elasticsearch/es实战/es实战1-常见命令.html","title":"es实战1-常见命令","keywords":"","body":" 1、增加索引 curl -XPUT '192.168.1.1:9200/twitter/tweet/1?pretty' -H 'Content-Type: application/json' -d'{ \"platformNo\": 19,\"user\" : \"kimchy\",\"post_date\" : \"2009-11-15T14:12:12\",\"message\" : \"trying out Elasticsearch\"}' 2、删除索引 curl -XDELETE '192.168.1.1:9200/pg.nsp.192.168.1.1mon.sp_on_sale_goods' 3、更新索引 重复的自动覆盖 curl -XPUT '192.168.1.1:9200/pg.nsp1/tweet/1?pretty' -H 'Content-Type: application/json' -d'{ \"platformNo\": 19,\"reason\" : \"苹果\",\"post_date\" : \"2009-11-15T14:12:12\",\"message\" : \"trying out Elasticsearch\"}' 4、查询索引 curl -XGET '192.168.1.1:9200/posts/doc/1' 5、查看集群健康 curl -XGET '192.168.1.146:9200/_cat/health?v&pretty' 6、查看索引 curl -XGET '192.168.1.1:9200/_cat/indices?v&pretty' 7、查看process curl http://192.168.1.146:9200/_nodes/process?pretty 8、查看_settings curl -XGET '192.168.1.146:9200/pg.nsp.sp_oa.oa_sp_listing/_settings?pretty' 9、设置_settings（max_result_window） curl -XPUT '192.168.1.146:9200/pg.nsp.sp_oa.oa_sp_listing/_settings?pretty' -H 'Content-Type:application/json' -d'{ \"index\" : { \"max_result_window\" : 100000001}}' 10、查看_mapping curl -XGET '192.168.1.146:9200/pg.nsp.sp_oa.oa_sp_listing/_mapping?pretty' 11、设置_mapping 备注：若要在windows下的cmder下测试，改为双引号 curl -XPUT \"192.168.1.1:9200/twitter/tweet/1?pretty\" -H \"Content-Type: application/json\" -d\"{ \\\"platformNo\\\": 19,\\\"user\\\" : \\\"kimchy\\\",\\\"post_date\\\" : \\\"2009-11-15T14:12:12\\\",\\\"message\\\" : \\\"trying out Elasticsearch\\\"}\" { \"_index\" : \"twitter\", \"_type\" : \"tweet\", \"_id\" : \"1\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"_seq_no\" : 0, \"_primary_term\" : 1 } "},"elasticsearch/es实战/es实战2-查询命令.html":{"url":"elasticsearch/es实战/es实战2-查询命令.html","title":"es实战2-查询命令","keywords":"","body":" 、精确查询(词条查询) 、匹配查询 、多个匹配查询 、短语匹配查询 GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 100, \"query\": { \"bool\": { \"must\": [ { \"multi_match\": { \"query\": \"Lightning Purple\", \"minimum_should_match\": \"100\", \"fields\": [ \"title^1.0\", \"description^1.0\", \"keywords^1.0\" ], \"type\": \"phrase\", \"operator\": \"and\", \"slop\": 0, \"prefix_length\": 0, \"max_expansions\": 50, \"zero_terms_query\": \"NONE\", \"auto_generate_synonyms_phrase_query\": true, \"fuzzy_transpositions\": true, \"boost\": 1 } } ], \"adjust_pure_negative\": true, \"boost\": 1 } } } GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 100, \"query\": { \"bool\": { \"must\": [ { \"multi_match\": { \"query\": \"SEA FAIRIES\", \"minimum_should_match\": \"100\", \"fields\": [ \"title^1.0\", \"description^1.0\", \"keywords^1.0\" ], \"type\": \"phrase\", \"operator\": \"and\", \"slop\": 0, \"prefix_length\": 0, \"max_expansions\": 50, \"zero_terms_query\": \"NONE\", \"auto_generate_synonyms_phrase_query\": true, \"fuzzy_transpositions\": true, \"boost\": 1 } } ], \"adjust_pure_negative\": true, \"boost\": 1 } } } https://blog.csdn.net/dm_vincent/article/details/41941659?utm_source=tuicool 、正则表达式查询 、聚合查询(distinct) 场景：当需要获取某个字段上的所有可用值时，可以使用terms聚合查询完成 第一个size是hits那部分数据的大小，这里聚合不需要hits那部分，第二个size是聚合所需要查询的数据site.keyword是你想对那个字段进行不同值查询group_by_site是随意起的值 类似于sql的select distinct site, count(*) from sp_oa.oa_sp_listing GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 0, \"aggregations\": { \"group_by_site\": { \"terms\": { \"field\": \"site.keyword\", \"size\": 1000, \"min_doc_count\": 1, \"shard_min_doc_count\": 0, \"show_term_doc_count_error\": false, \"order\": [ { \"_count\": \"desc\" }, { \"_key\": \"asc\" } ] } } } } https://www.cnblogs.com/qijiu/p/6876096.html 、聚合数目查询(cardinality) 类似于sql的select count( ) from (select distinct from table) GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 0, \"aggregations\": { \"count_site\": { \"cardinality\": { \"field\": \"site.keyword\" } } } } 结果： { \"took\": 1, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 16548333, \"max_score\": 0, \"hits\": [] }, \"aggregations\": { \"count_site\": { \"value\": 17 } } } "},"elasticsearch/es实战/es实战3-综合查询案例.html":{"url":"elasticsearch/es实战/es实战3-综合查询案例.html","title":"es实战3-综合查询案例","keywords":"","body":" 1、产品侵权查询 背景：将在售的侵权的sku（某些平台下的）搜索出来 1、短语匹配查询2、词条精确查询3、in查询 GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 10000, \"timeout\": \"10m\", \"query\": { \"bool\": { \"must\": [ { \"match_phrase\": { \"product_code\": { \"query\": \"SKU778231\", \"slop\": 0, \"boost\": 1 } } }, { \"term\": { \"sales_status\": { \"value\": \"online\", \"boost\": 1 } } }, { \"terms\": { \"platform\": [ \"ebay\", \"amazon\", \"aliexpress\", \"newegg\", \"wish\", \"linio\" ], \"boost\": 1 } } ], \"adjust_pure_negative\": true, \"boost\": 1 } } } 2、侵权品牌查询 1、多字段短语匹配查询 短语可以多个字符串组合在一起，而且位置固定才会搜索出来，比如Abercrombie & Fitch，特别适合短语查询 2、词条精确查询3、in查询 { \"from\": 0, \"size\": 10000, \"timeout\": \"10m\", \"query\": { \"bool\": { \"must\": [ { \"multi_match\": { \"query\": \"Abercrombie & Fitch\", \"fields\": [ \"description^1.0\", \"keywords^1.0\", \"title^1.0\" ], \"type\": \"phrase\", \"operator\": \"AND\", \"slop\": 0, \"prefix_length\": 0, \"max_expansions\": 50, \"zero_terms_query\": \"NONE\", \"auto_generate_synonyms_phrase_query\": true, \"fuzzy_transpositions\": true, \"boost\": 1 } }, { \"terms\": { \"platform\": [ \"Joom\", \"NewChic\", \"11Street\", \"Linio\", \"Lazada\", \"JD\", \"Yilinker\", \"eBay\", \"WholeSale\" ], \"boost\": 1 } } ], \"adjust_pure_negative\": true, \"boost\": 1 } } } GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 10000, \"timeout\": \"20m\", \"query\": { \"bool\": { \"must\": [ { \"multi_match\": { \"query\": \"segway\", \"fields\": [ \"description^1.0\", \"title^1.0\" ], \"type\": \"phrase\", \"operator\": \"AND\", \"slop\": 0, \"prefix_length\": 0, \"max_expansions\": 50, \"zero_terms_query\": \"NONE\", \"auto_generate_synonyms_phrase_query\": true, \"fuzzy_transpositions\": true, \"boost\": 1 } }, { \"term\": { \"sales_status\": { \"value\": \"online\", \"boost\": 1 } } }, { \"term\": { \"platform\": { \"value\": \"wish\", \"boost\": 1 } } }, { \"term\": { \"product_code\": { \"value\": \"sku894685\", \"boost\": 1 } } } ], \"adjust_pure_negative\": true, \"boost\": 1 } } } 3、es列表搜索查询 "},"elasticsearch/es实战/es实战4-java常见查询实例.html":{"url":"elasticsearch/es实战/es实战4-java常见查询实例.html","title":"es实战4-java常见查询实例","keywords":"","body":" 查询 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.from(from); searchSourceBuilder.size(size); searchSourceBuilder.query(boolQueryBuilder); //超时时间 searchSourceBuilder.timeout(new TimeValue(10, TimeUnit.MINUTES)); SearchResult searchResult = elasticSearchService.search(SpListingEsInfo.class, searchSourceBuilder); 布尔查询 BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); searchSourceBuilder.query(boolQueryBuilder); 词条精确查询 TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(\"sales_status\", \"online\"); boolQueryBuilder.must(termQueryBuilder); 词条精确查询（in范围查询） 类似sql的in查询 List countryShortCodes, List platformNames if (!platformNames.isEmpty()) { TermsQueryBuilder termsQueryBuilder = QueryBuilders.termsQuery(\"platform\", platformNames); boolQueryBuilder.must(termsQueryBuilder); } if (!countryShortCodes.isEmpty()) { TermsQueryBuilder termsQueryBuilder2 = QueryBuilders.termsQuery(\"site\", countryShortCodes); boolQueryBuilder.must(termsQueryBuilder2); } 短语查询(多字符串查询) MatchPhraseQueryBuilder matchPhraseQueryBuilder = QueryBuilders.matchPhraseQuery(\"product_code\", productInfringe.getProductCode()); boolQueryBuilder.must(matchPhraseQueryBuilder); 多字段短语匹配查询(多字段多字符串查询) MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(infringeBrand.getName(), \"title\", \"description\", \"keywords\"). operator(Operator.AND).type(MultiMatchQueryBuilder.Type.PHRASE); boolQueryBuilder.must(multiMatchQueryBuilder); 正则查询 BoolQueryBuilder boolQueryBuilder2 = QueryBuilders.boolQuery(); RegexpQueryBuilder regexpQueryBuilder = new RegexpQueryBuilder(\"description.keyword\", \".*\" + spListingPageQueryVo.getSearchText().trim() + \".*\"); boolQueryBuilder2.should(regexpQueryBuilder); RegexpQueryBuilder regexpQueryBuilder2 = new RegexpQueryBuilder(\"title.keyword\", \".*\" + spListingPageQueryVo.getSearchText().trim() + \".*\"); boolQueryBuilder2.should(regexpQueryBuilder2); RegexpQueryBuilder regexpQueryBuilder3 = new RegexpQueryBuilder(\"keywords.keyword\", \".*\" + spListingPageQueryVo.getSearchText().trim() + \".*\"); boolQueryBuilder2.should(regexpQueryBuilder3); boolQueryBuilder2.minimumShouldMatch(1); boolQueryBuilder.must(boolQueryBuilder2); 排序 if (!StringUtils.isEmpty(spListingPageQueryVo.getSortKey())) { FieldSortBuilder fieldSortBuilder = new FieldSortBuilder(spListingPageQueryVo.getSortKey()+\".keyword\"); if (spListingPageQueryVo.getSortType()) {//TRUE降序 fieldSortBuilder.order(SortOrder.DESC); } else { fieldSortBuilder.order(SortOrder.ASC); } searchSourceBuilder.sort(fieldSortBuilder); } 聚合查询（aggregation） int from=0; int size=0;//这里设置为0是不用返回hits那部分内容 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.from(from); searchSourceBuilder.size(size); searchSourceBuilder.aggregation(AggregationBuilders.terms(\"group_by_site\").field(\"site.keyword\").size(1000));//group_by_site这个只是个名字，可以随便起的 聚合查询（cardinality） int from=0; int size=0;//这里设置为0是不用返回hits那部分内容 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.from(from); searchSourceBuilder.size(size); searchSourceBuilder.aggregation(AggregationBuilders.cardinality(\"group_by_site\").field(\"site.keyword\"));//group_by_site这个只是个名字，可以随便起的 "},"elasticsearch/es实战/es实战5-聚合分组查询案例.html":{"url":"elasticsearch/es实战/es实战5-聚合分组查询案例.html","title":"es实战5-聚合分组查询案例","keywords":"","body":" 需求背景 对在售商品按照sku,平台platform来查询每个sku在对应平台下的最大价格price，sql如下 SELECT platform,product_code,max(price) from test_listing GROUP BY platform,product_code 其他辅助查询 SELECT platform,product_code,max(price) from test_listingwhere product_code='SKU466577' GROUP BY platform,product_code SELECT platform,product_code,price from test_listingwhere product_code='SKU466577' and platform='lazada' order by price desc kibana查询 思路：先对sku进行聚合，再添加平台platform的子聚合，最后再统计最大价格price GET /pg.nsp.sp_oa.oa_sp_listing/_doc/_search { \"from\": 0, \"size\": 0, \"aggregations\": { \"product_code_agg\": { \"terms\": { \"field\": \"product_code.keyword\", \"size\": 10, \"min_doc_count\": 1, \"shard_min_doc_count\": 0, \"show_term_doc_count_error\": false, \"order\": [ { \"_count\": \"desc\" }, { \"_key\": \"asc\" } ] }, \"aggregations\": { \"plaform_agg\": { \"terms\": { \"field\": \"platform.keyword\", \"size\": 10, \"min_doc_count\": 1, \"shard_min_doc_count\": 0, \"show_term_doc_count_error\": false, \"order\": [ { \"_count\": \"desc\" }, { \"_key\": \"asc\" } ] }, \"aggregations\": { \"price_max\": { \"max\": { \"field\": \"price\" } } } } } } } } 查询结果： { \"took\": 501, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 10125828, \"max_score\": 0, \"hits\": [] }, \"aggregations\": { \"product_code_agg\": { \"doc_count_error_upper_bound\": 3284, \"sum_other_doc_count\": 10094565, \"buckets\": [ { \"key\": \"SKU466577\", \"doc_count\": 5949, \"plaform_agg\": { \"doc_count_error_upper_bound\": 0, \"sum_other_doc_count\": 0, \"buckets\": [ { \"key\": \"lazada\", \"doc_count\": 5493, \"price_max\": { \"value\": 356000 } }, { \"key\": \"shopee\", \"doc_count\": 451, \"price_max\": { \"value\": 304600 } }, { \"key\": \"wish\", \"doc_count\": 5, \"price_max\": { \"value\": 0 } } ] } }, { \"key\": \"SKU564470\", \"doc_count\": 4856, \"plaform_agg\": { \"doc_count_error_upper_bound\": 0, \"sum_other_doc_count\": 0, \"buckets\": [ { \"key\": \"lazada\", \"doc_count\": 4478, \"price_max\": { \"value\": 3048000 } }, { \"key\": \"shopee\", \"doc_count\": 361, \"price_max\": { \"value\": 295400 } }, { \"key\": \"wish\", \"doc_count\": 9, \"price_max\": { \"value\": 16 } }, { \"key\": \"Aliexpress\", \"doc_count\": 6, \"price_max\": { \"value\": 28.540000915527344 } }, { \"key\": \"eBay\", \"doc_count\": 2, \"price_max\": { \"value\": 8.489999771118164 } } ] } } ] } } } 单元测试 @Test public void testAggsQuery5() { BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); int from = 0; int size = 0;//这里设置为0是不用返回hits那部分内容 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.from(from); searchSourceBuilder.size(size); TermsAggregationBuilder termsAggregationBuilder1=AggregationBuilders.terms(\"plaform_agg\").field(\"platform.keyword\"); TermsAggregationBuilder termsAggregationBuilder2=AggregationBuilders.terms(\"product_code_agg\").field(\"product_code.keyword\"); termsAggregationBuilder2.subAggregation(termsAggregationBuilder1); MaxAggregationBuilder maxAggregationBuilder= AggregationBuilders.max(\"price_max\").field(\"price\"); termsAggregationBuilder1.subAggregation(maxAggregationBuilder); searchSourceBuilder.aggregation(termsAggregationBuilder2); log.info(\"aggregations:{}\", searchSourceBuilder.toString()); SearchAggResult searchResult = elasticSearchService.searchMaxAgg(searchSourceBuilder, \"pg.nsp.sp_oa.oa_sp_listing\", \"_doc\"); System.out.println(searchResult.getTotal()); System.out.println(searchResult.getSearchBuckets()); } 参考：https://blog.csdn.net/sxf_123456/article/details/79482041 "},"elasticsearch/es实战/es实战6-springboot2.0集成elasticsearch6.html":{"url":"elasticsearch/es实战/es实战6-springboot2.0集成elasticsearch6.html","title":"es实战6-springboot2.0集成elasticsearch6","keywords":"","body":" pom.xml org.elasticsearch elasticsearch 6.2.4 org.elasticsearch.client rest 6.0.0-alpha1 org.elasticsearch.client elasticsearch-rest-high-level-client 6.2.4 ElasticSearchConfig package com.tobe.spcommon.common.config; import lombok.Data; import org.apache.http.HttpHost; import org.elasticsearch.client.RestClient; import org.elasticsearch.client.RestHighLevelClient; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.util.Assert; import java.util.List; @Configuration public class ElasticSearchConfig { @Autowired Hosts hosts; @Bean(\"restHighLevelClient\") public RestHighLevelClient clientFactory() { Assert.notEmpty(hosts.hosts, \"the host of elastic search cann't be null\"); HttpHost[] httpHosts = new HttpHost[hosts.hosts.size()]; for (int i = 0; i hosts; } @Data public static class Host { private String host; private int port; private String protocol; } } properties #----------------------- # ES new config #----------------------- es.hosts[0].host=192.168.1.1 es.hosts[0].port=9200 es.hosts[0].protocol=http ESTest package com.tobe.spcommon.es; import com.tobe.spcommon.common.config.ElasticSearchConfig; import com.tobe.spcommon.common.service.ElasticSearchService; import com.tobe.spcommon.dao.InfringeWordRepository; import com.tobe.spcommon.pojo.view.req.infringeword.InfringeWordAddVo; import com.tobe.spcommon.pojo.view.req.infringeword.InfringeWordEsInfo; import lombok.extern.slf4j.Slf4j; import org.apache.http.Header; import org.apache.http.HttpHost; import org.apache.http.message.BasicHeader; import org.elasticsearch.ElasticsearchException; import org.elasticsearch.action.bulk.BulkResponse; import org.elasticsearch.action.index.IndexRequest; import org.elasticsearch.action.index.IndexResponse; import org.elasticsearch.client.RestClient; import org.elasticsearch.client.RestHighLevelClient; import org.elasticsearch.common.xcontent.XContentType; import org.elasticsearch.index.query.QueryStringQueryBuilder; import org.elasticsearch.rest.RestStatus; import org.junit.Test; import org.junit.runner.RunWith; import org.omg.PortableInterceptor.INACTIVE; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.autoconfigure.EnableAutoConfiguration; import org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration; import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration; import org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import javax.annotation.Resource; import java.io.IOException; import java.util.ArrayList; import java.util.Iterator; import java.util.List; /** * @author Wuxi * @date 2018/5/14 */ @Slf4j @RunWith(SpringRunner.class) @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) public class ESTest { @Resource ElasticSearchService elasticSearchService; @Test public void testBulkInsert() { List infringeWordEsInfos = new ArrayList<>(); InfringeWordEsInfo infringeWordEsInfo = new InfringeWordEsInfo(); infringeWordEsInfo.setId(\"9\"); infringeWordEsInfo.setName(\"苹果9\"); infringeWordEsInfo.setFullCategory(1); infringeWordEsInfo.setPlatformNo(1); log.info(infringeWordEsInfo.toString()); InfringeWordEsInfo infringeWordEsInfo2 = new InfringeWordEsInfo(); infringeWordEsInfo2.setId(\"10\"); infringeWordEsInfo2.setName(\"苹果10\"); infringeWordEsInfo2.setFullCategory(1); infringeWordEsInfo2.setPlatformNo(1); log.info(infringeWordEsInfo2.toString()); InfringeWordEsInfo infringeWordEsInfo3 = new InfringeWordEsInfo(); infringeWordEsInfo3.setId(\"3\"); infringeWordEsInfo3.setName(\"苹果3\"); infringeWordEsInfo3.setFullCategory(1); infringeWordEsInfo3.setPlatformNo(0); log.info(infringeWordEsInfo3.toString()); InfringeWordEsInfo infringeWordEsInfo4 = new InfringeWordEsInfo(); infringeWordEsInfo4.setId(\"4\"); infringeWordEsInfo4.setName(\"苹果4\"); infringeWordEsInfo4.setFullCategory(1); infringeWordEsInfo4.setPlatformNo(0); log.info(infringeWordEsInfo4.toString()); InfringeWordEsInfo infringeWordEsInfo19 = new InfringeWordEsInfo(); infringeWordEsInfo19.setId(\"19\"); infringeWordEsInfo19.setName(\"苹果19\"); infringeWordEsInfo19.setFullCategory(1); infringeWordEsInfo19.setPlatformNo(19); log.info(infringeWordEsInfo19.toString()); infringeWordEsInfos.add(infringeWordEsInfo); infringeWordEsInfos.add(infringeWordEsInfo2); infringeWordEsInfos.add(infringeWordEsInfo3); infringeWordEsInfos.add(infringeWordEsInfo4); infringeWordEsInfos.add(infringeWordEsInfo19); //infringeWordEsInfo3 infringeWordEsInfo4不会被更新 try { BulkResponse bulkItemResponses = elasticSearchService.bulkInsert(infringeWordEsInfos); log.info(\"{}\",bulkItemResponses); } catch (Exception e) { e.printStackTrace(); } // elasticSearchService.update(infringeWordEsInfo3); } @Test public void testInsert() { InfringeWordEsInfo infringeWordEsInfo = new InfringeWordEsInfo(); infringeWordEsInfo.setId(\"6\"); infringeWordEsInfo.setName(\"苹果2\"); infringeWordEsInfo.setFullCategory(1); log.info(infringeWordEsInfo.toString()); //infringeWordRepository.save(infringeWordEsInfo); try { elasticSearchService.insert(infringeWordEsInfo); } catch (Exception e) { e.printStackTrace(); } } @Test public void test() throws IOException { RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\"192.168.1.1\", 9200, \"http\"), new HttpHost(\"192.168.1.1\", 9201, \"http\"))); String queryString = \"apple\";//搜索关键字 IndexRequest request = new IndexRequest( \"posts\", \"doc\", \"3\"); String jsonString = \"{\" + \"\\\"user\\\":\\\"kimchy\\\",\" + \"\\\"postDate\\\":\\\"2013-01-30\\\",\" + \"\\\"message\\\":\\\"trying out Elasticsearch\\\"\" + \"}\"; request.source(jsonString, XContentType.JSON); try { //RequestOptions.DEFAULT.getHeaders() IndexResponse response = client.index(request);//new RequestOptions.DEFAULT.ReqHeader());new BasicHeader() log.info(\"------------------响应：{}\", response); } catch (ElasticsearchException e) { if (e.status() == RestStatus.CONFLICT) { log.error(\"\", e); } } finally { client.close(); } } } ElasticSearchServiceImpl package com.tobe.spcommon.common.service.impl; import com.tobe.spcommon.common.exception.SearchException; import com.tobe.spcommon.common.service.ElasticSearchService; import com.tobe.spcommon.common.utils.ElasticSearchUtil; import com.tobe.spcommon.common.utils.JsonUtil; import lombok.extern.slf4j.Slf4j; import org.elasticsearch.action.bulk.BulkRequest; import org.elasticsearch.action.bulk.BulkResponse; import org.elasticsearch.action.delete.DeleteRequest; import org.elasticsearch.action.delete.DeleteResponse; import org.elasticsearch.action.get.GetRequest; import org.elasticsearch.action.get.GetResponse; import org.elasticsearch.action.get.MultiGetRequest; import org.elasticsearch.action.get.MultiGetResponse; import org.elasticsearch.action.index.IndexRequest; import org.elasticsearch.action.index.IndexResponse; import org.elasticsearch.action.search.SearchRequest; import org.elasticsearch.action.search.SearchResponse; import org.elasticsearch.action.update.UpdateRequest; import org.elasticsearch.action.update.UpdateResponse; import org.elasticsearch.client.RestHighLevelClient; import org.elasticsearch.common.xcontent.XContentType; import org.elasticsearch.search.builder.SearchSourceBuilder; import org.springframework.stereotype.Component; import javax.annotation.Resource; import java.io.IOException; import java.util.List; @Slf4j @Component public class ElasticSearchServiceImpl implements ElasticSearchService { @Resource RestHighLevelClient restHighLevelClient; public IndexResponse insert(T value) { log.info(\"请求index：{}\", value); try { ElasticSearchUtil.EsDataInfo esDataInfo = ElasticSearchUtil.assertAndReturnEsDataInfo(value); IndexRequest request = new IndexRequest( esDataInfo.getIndex(), esDataInfo.getType(), esDataInfo.getId()); request.source(JsonUtil.stringify(value), XContentType.JSON); IndexResponse response = restHighLevelClient.index(request); log.info(\"响应index：{}\", response); return response; } catch (IOException | IllegalAccessException e) { log.error(\"\", e); throw new SearchException(e); } } public DeleteResponse delete(T value) { log.info(\"请求delete：{}\", value); try { ElasticSearchUtil.EsDataInfo esDataInfo = ElasticSearchUtil.assertAndReturnEsDataInfo(value); DeleteRequest request = new DeleteRequest( esDataInfo.getIndex(), esDataInfo.getType(), esDataInfo.getId()); DeleteResponse response = restHighLevelClient.delete(request); log.info(\"响应delete：{}\", response); return response; } catch (IOException | IllegalAccessException e) { log.error(\"\", e); throw new SearchException(e); } } public UpdateResponse update(T value) { log.info(\"请求update：{}\", value); try { ElasticSearchUtil.EsDataInfo esDataInfo = ElasticSearchUtil.assertAndReturnEsDataInfo(value); UpdateRequest request = new UpdateRequest( esDataInfo.getIndex(), esDataInfo.getType(), esDataInfo.getId()); request.doc(JsonUtil.stringify(value), XContentType.JSON); UpdateResponse response = restHighLevelClient.update(request); log.info(\"响应update：{}\", response); return response; } catch (IOException | IllegalAccessException e) { log.error(\"\", e); throw new SearchException(e); } } public GetResponse get(T t) { log.info(\"请求get：{}\", t); try { ElasticSearchUtil.EsDataInfo esDataInfo = ElasticSearchUtil.assertAndReturnEsDataInfo(t); GetRequest request = new GetRequest( esDataInfo.getIndex(), esDataInfo.getType(), esDataInfo.getId()); GetResponse response = restHighLevelClient.get(request); log.info(\"响应delete：{}\", response); return response; } catch (IOException | IllegalAccessException e) { log.error(\"\", e); throw new SearchException(e); } } public MultiGetResponse multiGet(List values) { log.info(\"请求multiGet：{}\", values); try { MultiGetRequest request = new MultiGetRequest(); for (T t : values) { ElasticSearchUtil.EsDataInfo esDataInfo = ElasticSearchUtil.assertAndReturnEsDataInfo(t); request.add(esDataInfo.getIndex(), esDataInfo.getType(), esDataInfo.getId()); } MultiGetResponse response = restHighLevelClient.multiGet(request); log.info(\"响应delete：{}\", response); return response; } catch (IOException | IllegalAccessException e) { log.error(\"\", e); throw new SearchException(e); } } public BulkResponse bulkInsert(List values) { log.info(\"请求bulkInsert：{}\", values); BulkRequest request = new BulkRequest(); try { for (Object object : values) { ElasticSearchUtil.EsDataInfo esDataInfo = ElasticSearchUtil.assertAndReturnEsDataInfo(object); IndexRequest indexRequest = new IndexRequest( esDataInfo.getIndex(), esDataInfo.getType(), esDataInfo.getId()); indexRequest.source(JsonUtil.stringify(object), XContentType.JSON); request.add(indexRequest); } BulkResponse response = restHighLevelClient.bulk(request); log.info(\"响应bulkInsert：{}\", response); return response; } catch (IOException | IllegalAccessException e) { log.error(\"\", e); throw new SearchException(e); } } public SearchResponse search(List values) { log.info(\"请求multiGet：{}\", values); try { SearchRequest request = new SearchRequest(); SearchSourceBuilder source = new SearchSourceBuilder(); request.source(source); SearchResponse response = restHighLevelClient.search(request); log.info(\"响应delete：{}\", response); return response; } catch (IOException e) { log.error(\"\", e); throw new SearchException(e); } } } "},"elasticsearch/es实战/es实战7-elasticsearch实现springboot自动配置.html":{"url":"elasticsearch/es实战/es实战7-elasticsearch实现springboot自动配置.html","title":"es实战7-elasticsearch实现springboot自动配置","keywords":"","body":" 1、新建ElasticSearchProperties package com.basic.elasticsearch.autoconfigure; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; import java.util.List; @Data @Configuration @ConfigurationProperties(prefix = \"elastic\") public class ElasticSearchProperties { List hosts; } package com.basic.elasticsearch.autoconfigure; import lombok.Data; @Data public class Host { private String host; private int port; private String protocol; } 2、新建ElasticSearchAutoConfiguration自动配置类 package com.basic.elasticsearch.autoconfigure; import com.basic.elasticsearch.service.ElasticSearchService; import com.basic.elasticsearch.service.ElasticSearchTransportClientService; import com.basic.elasticsearch.service.impl.ElasticSearchServiceImpl; import com.basic.elasticsearch.service.impl.ElasticSearchTransportClientServiceImpl; import org.apache.http.HttpHost; import org.elasticsearch.client.RestClient; import org.elasticsearch.client.RestHighLevelClient; import org.elasticsearch.client.transport.TransportClient; import org.elasticsearch.common.settings.Settings; import org.elasticsearch.common.transport.TransportAddress; import org.elasticsearch.transport.client.PreBuiltTransportClient; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.autoconfigure.condition.ConditionalOnClass; import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean; import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty; import org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.util.Assert; import java.net.InetAddress; import java.net.UnknownHostException; /** * https://www.cnblogs.com/xyzmy/p/9776037.html */ @Configuration @EnableConfigurationProperties(ElasticSearchProperties.class) @ConditionalOnClass({ElasticSearchService.class, ElasticSearchTransportClientService.class}) @ConditionalOnProperty(prefix = \"elastic\", value = \"enabled\", matchIfMissing = false) //判断配置文件中是否存在elastic开头的配置,如果不存在配置，如果配置matchIfMissing为true,即使我们配置文件中配置elastic.enabled=true，也是默认生效的； // matchIfMissing必须设置为false，配置文件不存在时则不自动配置,若配置文件存在，则再判断elastic.enabled为true才会自动配置 public class ElasticSearchAutoConfiguration { @Autowired ElasticSearchProperties elasticSearchProperties; static { System.setProperty(\"es.set.netty.runtime.available.processors\", \"false\"); } @Bean @ConditionalOnMissingBean public RestHighLevelClient restHighLevelClient() { Assert.notEmpty(elasticSearchProperties.hosts, \"the host of elastic search cann't be null\"); HttpHost[] httpHosts = new HttpHost[elasticSearchProperties.hosts.size()]; for (int i = 0; i 3、在resource/METE-INF文件夹下新建spring.factories文件 文件内容如下 # Auto Configure org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.basic.elasticsearch.autoconfigure.ElasticSearchAutoConfiguration 4、用法 引入pom依赖(注意排除掉一些不要的依赖) com.basic.search elasitcsearch-starter 1.0.0 org.slf4j slf4j-log4j12 org.springframework.boot spring-boot-starter-data-elasticsearch 新建application-es.properties # ES new config elastic.hosts[0].host=192.168.1.146 elastic.hosts[0].port=9200 elastic.hosts[0].protocol=http elastic.enabled=true 测试 @Test public void testInsert() { InfringeWordEsInfo infringeWordEsInfo = new InfringeWordEsInfo(); infringeWordEsInfo.setId(\"6\"); infringeWordEsInfo.setName(\"苹果2\"); infringeWordEsInfo.setFullCategory(1); log.info(infringeWordEsInfo.toString()); //infringeWordRepository.save(infringeWordEsInfo); try { elasticSearchService.insert(infringeWordEsInfo); } catch (Exception e) { e.printStackTrace(); } } 4、另一种引入方式EnableElasticSearch 新建EnableElasticSearch.java package com.basic.elasticsearch.autoconfigure; import org.springframework.context.annotation.Import; import java.lang.annotation.*; @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Import({ElasticSearchAutoConfiguration.class}) public @interface EnableElasticSearch { } 引入 @EnableElasticSearch "},"elasticsearch/es知识点/和Elasticsearch交互.html":{"url":"elasticsearch/es知识点/和Elasticsearch交互.html","title":"和Elasticsearch交互","keywords":"","body":" Java可以使用 Elasticsearch 内置的两个客户端： 节点客户端（Node client） 节点客户端作为一个非数据节点加入到本地集群中。换句话说，它本身不保存任何数据，但是它知道数据在集群中的哪个节点中，并且可以把请求转发到正确的节点。 传输客户端（Transport client） 轻量级的传输客户端可以将请求发送到远程集群。它本身不加入集群，但是它可以将请求转发到集群中的一个节点上。 两个 Java 客户端都是通过 9300 端口并使用 Elasticsearch 的原生 传输 协议和集群交互。集群中的节点通过端口 9300 彼此通信。如果这个端口没有打开，节点将无法形成一个集群。 客户端连接elasticsearch代码 @Bean(\"transportClient\") public TransportClient transportClient() throws UnknownHostException { Assert.notEmpty(hosts.hosts, \"the host of elastic search cann't be null\"); TransportAddress[] transportAddress = new TransportAddress[hosts.hosts.size()]; for (int i = 0; i 更多代码参考本站的【springboot2.0集成elasticsearch6】或者本站搜索ElasticSearchConfig 参考： https://www.elastic.co/guide/cn/elasticsearch/guide/cn/_talking_to_elasticsearch.html https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/transport-client.html 特别注意：本环境使用的elasticsearch为6.4.2，貌似7.x后该方法为过期了，8.x后删除了，若用更高版本，自行在官网查询对应的方法 "},"elasticsearch/es知识点/Elasticsearch学习.html":{"url":"elasticsearch/es知识点/Elasticsearch学习.html","title":"Elasticsearch学习","keywords":"","body":" 待学习 时间范围查询 https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-range-query.html#querying-range-fields https://www.cnblogs.com/shoufeng/p/11266136.html "},"java/缓存/guava/guava缓存简单使用三部曲.html":{"url":"java/缓存/guava/guava缓存简单使用三部曲.html","title":"guava缓存简单使用三部曲","keywords":"","body":" 1、pom com.google.guava guava 28.1-jre 2、定义缓存变量 static LoadingCache caches = CacheBuilder.newBuilder() .expireAfterWrite(7, TimeUnit.DAYS) .build( new CacheLoader() { public String load(String key) {//key是infringeUrl log.info(\"缓存key:{}\", key); if (!StringUtils.isEmpty(key)) { } return null; } }); 3、put设值到缓存 caches.put(\"infringeUrl\", item.getItemValue()); 4、获取使用缓存 String url=caches.getUnchecked(\"infringeUrl\"); 5、存在问题 https://blog.csdn.net/codingtu/article/details/89577316 "},"java/数据源/动态数据源.html":{"url":"java/数据源/动态数据源.html","title":"动态数据源","keywords":"","body":" 数据源相关属性配置 package com.tobe.spbusiness.common.config.datasource; import lombok.Data; @Data public class DynamicDatasourceProperty { public String driverClassname; public String maxWait; public String minIdle; public String initialSize; public String url; public String username; public String password; public String removeAbandoned; public String removeAbandonedTimeout; public String logAbandoned; public String opType; public String lookupkey; public boolean defaultDb=false; } 数据源相关属性配置列表 package com.tobe.spbusiness.common.config.datasource; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; import java.util.List; @Configuration @ConfigurationProperties(prefix = \"springplus\") @Data public class DynamicDatasourcePropertyList { List dynamicDatasources; } 动态数据源 package com.tobe.spbusiness.common.config.datasource; import com.alibaba.druid.pool.DruidDataSource; import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource; import org.springframework.lang.Nullable; import javax.sql.DataSource; public class DynamicDatasource extends AbstractRoutingDataSource { @Nullable @Override protected Object determineCurrentLookupKey() { return DynamicDatasourceThreadLocal.getLookupkey(); } protected DataSource determineTargetDataSource() { DataSource dataSource = super.determineTargetDataSource(); if (this.logger.isDebugEnabled()) { if (dataSource != null && dataSource instanceof DruidDataSource) { DruidDataSource druidDataSource = (DruidDataSource) dataSource; this.logger.debug(\"Current dataSource [\" + druidDataSource.getDbType() + \"],url=\" + druidDataSource.getUrl()); } } if (this.logger.isDebugEnabled()) { Object lookupKey = determineCurrentLookupKey(); this.logger.debug(\"Current lookupKey [\" + lookupKey + \"]\"); } return dataSource; } } } 数据源本地线程 package com.tobe.spbusiness.common.config.datasource; import org.springframework.context.annotation.Configuration; //@Configuration public class DynamicDatasourceThreadLocal { static ThreadLocal lookupkeyThreadLocal = new ThreadLocal<>(); public static String getLookupkey() { return lookupkeyThreadLocal.get(); } public static void setLookupkey(String lookupkey) { lookupkeyThreadLocal.set(lookupkey); } } 数据源切面 package com.tobe.spbusiness.common.config.datasource; import lombok.extern.slf4j.Slf4j; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.core.annotation.AnnotationUtils; import org.springframework.core.annotation.Order; import org.springframework.stereotype.Component; import java.lang.reflect.Method; @Order(0) @Component @Slf4j @Aspect public class DatasourceAspect { // @Resource // DynamicDatasourceThreadLocal dynamicDatasourceHolder; @Pointcut(\"execution(* com.tobe.spbusiness..service..*.impl..*.*(..))\") public void choiceTargetDBPointcut() { } @Around(\"choiceTargetDBPointcut()\") public Object choiceTargetDB(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { Method method = ((MethodSignature) proceedingJoinPoint.getSignature()).getMethod(); Object target = proceedingJoinPoint.getTarget(); Method realMethod = target.getClass().getMethod(method.getName(), method.getParameterTypes()); TargetDB targetDB = AnnotationUtils.findAnnotation(realMethod, TargetDB.class); if (targetDB != null) { String lookupkey = targetDB.lookupkey(); DynamicDatasourceThreadLocal.setLookupkey(lookupkey); } else { } try { return proceedingJoinPoint.proceed(); } catch (Throwable throwable) { throwable.printStackTrace(); return null; } finally { //DynamicDatasourceThreadLocal.setLookupkey(null); } } } 数据源注解 package com.tobe.spbusiness.common.config.datasource; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface TargetDB { String lookupkey(); //OpType opType() default OpType.WRITE; } 数据源配置 package com.tobe.spbusiness.common.config.datasource; import com.alibaba.druid.pool.DruidDataSource; import com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceBuilder; import com.baomidou.mybatisplus.spring.MybatisSqlSessionFactoryBean; import com.baomidou.mybatisplus.spring.boot.starter.MybatisPlusProperties; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.SqlSessionTemplate; import org.mybatis.spring.annotation.MapperScan; import org.springframework.beans.BeanUtils; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.io.support.PathMatchingResourcePatternResolver; import org.springframework.jdbc.datasource.DataSourceTransactionManager; import org.springframework.transaction.PlatformTransactionManager; import javax.annotation.Resource; import javax.sql.DataSource; import java.util.HashMap; import java.util.List; import java.util.Map; @Configuration @MapperScan(basePackages = {\"com.tobe.spbusiness.catchorder.mapper.**\"}, sqlSessionFactoryRef = \"sqlSessionFactory\") public class DataSourceConfig { @Resource DynamicDatasourcePropertyList dynamicDatasourcePropertyList; @Autowired MybatisPlusProperties mybatisPlusProperties; @Bean(\"datasource\") public DataSource datasource() { DynamicDatasource dynamicDatasource = new DynamicDatasource(); Map targetDataSources = new HashMap<>(); List dynamicDatasourceProperties = dynamicDatasourcePropertyList.getDynamicDatasources(); if (dynamicDatasourceProperties != null && !dynamicDatasourceProperties.isEmpty()) { dynamicDatasourceProperties.forEach(e -> { DruidDataSource druidDataSource = DruidDataSourceBuilder.create().build(); BeanUtils.copyProperties(e, druidDataSource); //validateConn(druidDataSource, \"select now()\");//特别注意sql server没有select now() targetDataSources.put(e.getLookupkey(), druidDataSource); if (e.isDefaultDb()) { dynamicDatasource.setDefaultTargetDataSource(druidDataSource); } }); } dynamicDatasource.setTargetDataSources(targetDataSources); return dynamicDatasource; } @Bean(name = \"dsTransactionManager\") public PlatformTransactionManager dsTransactionManager(){//(@Qualifier(\"dataSource\") DataSource dataSource) { DataSourceTransactionManager dataSourceTransactionManager = new DataSourceTransactionManager(datasource()); return dataSourceTransactionManager; } @Bean public SqlSessionFactory sqlSessionFactory() throws Exception { MybatisSqlSessionFactoryBean factoryBean = new MybatisSqlSessionFactoryBean(); //DataSourceConfig.java里配置必须配置dataSource数据源对应的事务，否则事务失效 factoryBean.setDataSource(datasource()); org.springframework.core.io.Resource[] mapperLocations = new PathMatchingResourcePatternResolver() .getResources(\"classpath*:**/*Mapper.xml\"); factoryBean.setMapperLocations(mapperLocations); factoryBean.setConfiguration(mybatisPlusProperties.getConfiguration()); return factoryBean.getObject(); } @Bean public SqlSessionTemplate sqlSessionTemplate() throws Exception { SqlSessionTemplate template = new SqlSessionTemplate(sqlSessionFactory()); return template; } private void validateConn(DruidDataSource druidDataSource, String sql) { druidDataSource.setValidationQuery(sql); druidDataSource.setTestWhileIdle(true); druidDataSource.setTestOnBorrow(false); druidDataSource.setTestOnReturn(false); } } property属性配置 springplus.dynamicDatasources[0].driverClassName=org.postgresql.Driver springplus.dynamicDatasources[0].maxWait=5000 springplus.dynamicDatasources[0].minIdle=5 springplus.dynamicDatasources[0].initialSize=5 springplus.dynamicDatasources[0].url=jdbc:postgresql://172.16.11.31:5432/nsp_dev springplus.dynamicDatasources[0].username=postgres springplus.dynamicDatasources[0].password=postgres springplus.dynamicDatasources[0].removeAbandoned=true springplus.dynamicDatasources[0].removeAbandonedTimeout=18000 springplus.dynamicDatasources[0].logAbandoned=true springplus.dynamicDatasources[0].opType=write springplus.dynamicDatasources[0].lookupkey=pgwrite springplus.dynamicDatasources[0].defaultDb=true springplus.dynamicDatasources[1].driverClassName=com.microsoft.sqlserver.jdbc.SQLServerDriver springplus.dynamicDatasources[1].maxWait=5000 springplus.dynamicDatasources[1].minIdle=5 springplus.dynamicDatasources[1].initialSize=5 springplus.dynamicDatasources[1].url=jdbc:sqlserver://sqltest.tobe.cn:1433;DatabaseName=192.168.1.1mon;sendStringParametersAsUnicode=false; springplus.dynamicDatasources[1].username=skb-test springplus.dynamicDatasources[1].password=tobe!@#123 springplus.dynamicDatasources[1].removeAbandoned=true springplus.dynamicDatasources[1].removeAbandonedTimeout=18000 springplus.dynamicDatasources[1].logAbandoned=true springplus.dynamicDatasources[1].opType=read springplus.dynamicDatasources[1].lookupkey=sqlserverRead springplus.dynamicDatasources[1].defaultDb=false 用法 @TargetDB(lookupkey = \"pgwrite\") @Transactional(value = \"dsTransactionManager\") public Long add(ShopAddVo shopAddVo) { Shop shop = new Shop(); BeanUtils.copyProperties(shopAddVo, shop); boolean result = insert(shop, false); if (!result) { throw new SOAException(\"添加失败\"); } Long shopId = shop.getId(); return shopId; } "},"java/java8/java8新特性.html":{"url":"java/java8/java8新特性.html","title":"java8新特性","keywords":"","body":" 1、java8接口可以有默认方法 接口可以有实现体，但必须是默认实现，所以要在方法前加上default字段表示默认方法 public interface SmartApplicationListener extends ApplicationListener, Ordered { /** * Determine whether this listener actually supports the given event type. * @param eventType the event type (never {@code null}) */ boolean supportsEventType(Class eventType); /** * Determine whether this listener actually supports the given source type. * The default implementation always returns {@code true}. * @param sourceType the source type, or {@code null} if no source */ default boolean supportsSourceType(@Nullable Class sourceType) { return true; } /** * Determine this listener's order in a set of listeners for the same event. * The default implementation returns {@link #LOWEST_PRECEDENCE}. */ @Override default int getOrder() { return LOWEST_PRECEDENCE; } } 2、 3、 "},"java/spi/spi机制.html":{"url":"java/spi/spi机制.html","title":"spi机制","keywords":"","body":" sentinel数据源spi方式注册 https://github.com/alibaba/Sentinel/wiki/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%99%E6%89%A9%E5%B1%95 https://blog.csdn.net/BASK2311/article/details/127746690?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EAD_ESQUERY%7Eyljh-2-127746690-blog-124671361.pc_relevant_3mothn_strategy_and_data_recovery&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EAD_ESQUERY%7Eyljh-2-127746690-blog-124671361.pc_relevant_3mothn_strategy_and_data_recovery&utm_relevant_index=4 实现自定义包的自动注册bean SpringBoot根据配置文件动态创建Bean SpringBoot根据yml配置信息动态生成bean并加入Spring容器 springboot--实现自定义包的自动注册bean功能 spring4.1.8扩展实战之六：注册bean到spring容器(BeanDefinitionRegistryPostProcessor接口) 自定义BeanDefinitionRegistryPostProcessor注册bean SpringBoot 应用篇之从 0 到 1 实现一个自定义 Bean 注册器 判断当前是否Web环境 https://blog.csdn.net/cg_Amaz1ng/article/details/81180138 https://blog.csdn.net/m0_43448868/article/details/111874385 ``` "},"java/spring/动态创建bean.html":{"url":"java/spring/动态创建bean.html","title":"动态创建bean","keywords":"","body":" GenericBeanDefinition hiveConfigBean = new GenericBeanDefinition(); hiveConfigBean.setBeanClass(LiveConfig.class); registry.registerBeanDefinition(\"liveConfig\", hiveConfigBean); GenericBeanDefinition deviceBean = new GenericBeanDefinition(); deviceBean.setBeanClass(DeviceLiveServiceImpl.class); OkHttpClient okHttpClient = new OkHttpClient(); HttpFactory httpFactory = new OkHttpHttpFactory(okHttpClient); ConstructorArgumentValues constructorArgumentValues= new ConstructorArgumentValues(); constructorArgumentValues.addIndexedArgumentValue(0,hiveConfigBean); constructorArgumentValues.addIndexedArgumentValue(1,httpFactory); deviceBean.setConstructorArgumentValues(constructorArgumentValues); registry.registerBeanDefinition(\"deviceLiveService\", deviceBean); 5种方式获取ApplicationContext Properties properties = new Properties(); try { properties = PropertiesLoaderUtils.loadAllProperties(\"/conf/live.properties\"); } catch (IOException e) { log.error(\"加载live配置文件出错\"); e.printStackTrace(); } SpringBoot基础篇Bean之动态注册 项目源码 SpringBoot根据配置文件动态创建Bean springboot如何读取自定义properties并注入到bean中 自动装配如果没有生效，会不会是没有引入下面包导致的？ org.springframework.boot spring-boot-configuration-processor true https://www.jianshu.com/p/57f06f92fbb2 springboot项目将自定义的properties配置文件注入到实体Bean中 @Data @Configuration @PropertySource(\"classpath:/mail.properties\") @ConfigurationProperties(prefix = \"mail\") public class MailProperties { private String host; private Integer port; private Smtp smtp; private String from; private String username; private String password; } @RestController public class TestController { @Autowired private MailProperties mailProperties; @RequestMapping(\"/test\") public String test() { return mailProperties.toString(); } } springboot如何读取自定义properties并注入到bean中 package com.shanqis.parking.properties; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import java.io.IOException; import java.io.InputStream; import java.util.HashMap; import java.util.Map; import java.util.Properties; /** * 读取resource下的.properties文件，将文件中的内容封装到map中，注入到bean中方便依赖注入 * * @author Administrator */ @Configuration public class PropertiesClassLoader { private Logger logger = LoggerFactory.getLogger(PropertiesClassLoader.class); private Map versionProperties = new HashMap<>(16); private void init(String name) { try { Properties properties = new Properties(); InputStream in = PropertiesClassLoader.class.getClassLoader().getResourceAsStream(name + \".properties\"); properties.load(in); logger.info(\"加载{}.properties参数\", name); for (String keyName : properties.stringPropertyNames()) { String value = properties.getProperty(keyName); if (\"version\".equals(name)) { versionProperties.put(keyName, value); } logger.info(\"{}.properties---------key:{},value:{}\", name, keyName, value); } logger.info(\"{}.properties参数加载完毕\", name); } catch (IOException ignored) { } } @Bean(name = \"versionProperties\") public Map commonMap() { init(\"version\"); return versionProperties; } } @PropertySource如何加载配置文件 Spring注解驱动开发第19讲——使用@PropertySource加载配置文件，我只看这一篇！！ "},"java/spring/spring事件.html":{"url":"java/spring/spring事件.html","title":"spring事件","keywords":"","body":" 定义事件 自定义事件,继承ApplicationEvent package com.basic.eventlistener.event; import com.basic.eventlistener.model.JumiaListing; import lombok.Data; import org.springframework.context.ApplicationEvent; import java.util.List; @Data public class ListingSaveEvent extends ApplicationEvent { private List jumiaListings; /** * 这里参数可以自己定义，可以多个 */ public ListingSaveEvent(Object source, List jumiaListings) { super(source); this.jumiaListings = jumiaListings; } } 定义Listener监听器(业务处理) 在方法上加上@Async和 @EventListener主键即可 package com.basic.eventlistener.listener; import com.basic.eventlistener.model.JumiaListing; import com.basic.eventlistener.event.ListingSaveEvent; import lombok.extern.slf4j.Slf4j; import org.springframework.context.event.EventListener; import org.springframework.scheduling.annotation.Async; import org.springframework.stereotype.Component; import java.util.List; @Slf4j @Component public class ListingSaveListener { @Async @EventListener public void listingSave(ListingSaveEvent listingSaveEvent) { log.info(\"线程名称：\", Thread.currentThread().getName()); List jumiaListings = listingSaveEvent.getJumiaListings(); if (jumiaListings == null) { return; } } } 调用 package com.basic.eventlistener; import com.basic.eventlistener.event.ListingSaveEvent; import com.basic.eventlistener.model.JumiaListing; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.ApplicationContext; import org.springframework.stereotype.Component; import java.util.ArrayList; import java.util.List; @Component public class EventDemo { @Autowired private ApplicationContext applicationContext; public void publishEvent() { // 业务处理 List listingList = new ArrayList<>(); // 发布订阅模式，有一个业务 event 专门存储这些数据到数据库 applicationContext.publishEvent(new ListingSaveEvent(this, listingList)); } } 实体 package com.basic.eventlistener.model; import com.baomidou.mybatisplus.extension.activerecord.Model; import lombok.Data; @Data public class JumiaListing extends Model { private static final long serialVersionUID = -7585917820758380041L; private String id; private String productCode; private String propertyCode; } "},"java/swagger/更改swagger上下文.html":{"url":"java/swagger/更改swagger上下文.html","title":"更改swagger上下文","keywords":"","body":" 由于应用配置的请求上下文地址和swagger里的地址有可能不同，比如线上的是/business/tobe/country/getList 而本地的则是/country/getList,所以有必要配置swagger的上下文地址 pom.xml 2.7.0 io.springfox springfox-swagger2 ${swagger.version} io.springfox springfox-swagger-ui ${swagger.version} properties swagger.context=/ SwaggerConfig package com.tobe.spcommon.common.config; import com.tobe.spcommon.common.bean.AppcliationSwaggerPathProvider; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.ParameterBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.schema.ModelRef; import springfox.documentation.service.ApiInfo; import springfox.documentation.service.Contact; import springfox.documentation.service.Parameter; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; import javax.annotation.Resource; import java.util.ArrayList; import java.util.List; @Configuration @EnableSwagger2 public class SwaggerConfig { public static final String BASE_PACKAGE_PREFFIX = \"com.tobe.spcommon.controller\"; @Resource AppcliationSwaggerPathProvider appcliationSwaggerPathProvider; private ApiInfo apiInfo() { // TODO: 修改下面描叙 return new ApiInfoBuilder().title(\"侵权项目\").description(\"侵权项目\") .termsOfServiceUrl(\"\") .contact(new Contact(\"liangqingxiang\", \"\", \"liangqingxiang@tobe.com\")).version(\"1.0.0\").build(); } @Bean public Docket createRestApi() { ParameterBuilder ticketPar = new ParameterBuilder(); List pars = new ArrayList(); ticketPar.name(\"Auth\").description(\"侵权接口授权码\") .modelRef(new ModelRef(\"string\")).parameterType(\"header\") .required(false).build(); //header中的ticket参数非必填，传空也可以 pars.add(ticketPar.build()); //根据每个方法名也知道当前方法在设置什么参数 return getDocketInstance(\"0、全部接口\", BASE_PACKAGE_PREFFIX) .pathProvider(appcliationSwaggerPathProvider) ;//.globalOperationParameters(pars); } /*@Bean public Docket groupRestApi1() { return getDocketInstance(\"1、订单模块\", BASE_PACKAGE_PREFFIX + \".order\"); } }*/ private Docket getDocketInstance(String groupName, String basePackage) { return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo()).groupName(groupName).select() .apis(RequestHandlerSelectors.basePackage(basePackage)).paths(PathSelectors.any()) .build(); } } AppcliationSwaggerPathProvider package com.tobe.spcommon.common.bean; import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Component; import springfox.documentation.spring.web.paths.AbstractPathProvider; /* https://www.jianshu.com/p/a62aa157942c */ @Component public class AppcliationSwaggerPathProvider extends AbstractPathProvider { @Value(\"${swagger.context}\") private String swaggerContext; public AppcliationSwaggerPathProvider() { } @Override protected String applicationPath() { return swaggerContext;//\"/business/tobe\"; } @Override protected String getDocumentationPath() { return swaggerContext;//\"/business/tobe\"; } } "},"java/util/日志/logback日志文件配置.html":{"url":"java/util/日志/logback日志文件配置.html","title":"logback日志文件配置","keywords":"","body":" level设置为DEBUG,则下面2个日志都打印出来 log.debug(\"这个是debug日志\"); log.info(\"这个是info日志\"); 若设置为info，则只打印 log.info(\"这个是info日志\"); 若想设置不同环境不同级别，则利用springProfile,如下： logback.xml demo %d %t %p %C{3000}:%L [%t] %m%n%n /logs/basic-server/basic-server.log /logs/basic-server/%d{YYYYMMdd}/basic-server.%i.log.zip 20MB 300 %d %p %C{30}:%L [%t] %m%n%n /logs/basic-server/basic-server_interface.log /logs/basic-server/%d{YYYYMMdd}/basic-server_interface.%i.log.zip 20MB 300 %d %m%n 0 512 true 0 512 true 　 参考：https://blog.csdn.net/qq_27886997/article/details/83178948 阅读： springboot日志变量配置 "},"java/util/http/RestTemplate用法.html":{"url":"java/util/http/RestTemplate用法.html","title":"RestTemplate用法","keywords":"","body":" 引用 @Autowired private RestTemplate restTemplate; 简单get请求 Map uriVariables = new HashMap<>(); HttpHeaders requestHeaders = new HttpHeaders(); HttpEntity requestEntity = new HttpEntity<>(requestHeaders); ResponseEntity response = restTemplate.exchange(url, org.springframework.http.HttpMethod.GET, requestEntity, String.class, uriVariables); HttpStatus status = response.getStatusCode(); String responseBody = response.getBody(); 简单post请求（不带参数） Map uriVariables = new HashMap<>(); HttpHeaders requestHeaders = new HttpHeaders(); HttpEntity requestEntity = new HttpEntity<>(requestHeaders); ResponseEntity response = restTemplate.exchange(url, org.springframework.http.HttpMethod.GET, requestEntity, String.class, uriVariables); HttpStatus status = response.getStatusCode(); String responseBody = response.getBody(); 简单post请求（带参数） Map uriVariables = new HashMap<>(); HttpHeaders requestHeaders = new HttpHeaders(); HttpEntity requestEntity = new HttpEntity<>(requestHeaders); ResponseEntity response = restTemplate.exchange(url, org.springframework.http.HttpMethod.GET, requestEntity, String.class, uriVariables); HttpStatus status = response.getStatusCode(); String responseBody = response.getBody(); 设置请求头 HttpHeaders requestHeaders = new HttpHeaders(); requestHeaders.add(\"Authorization\", \"Basic \" + Base64.getEncoder().encodeToString(Authorization.getBytes(\"utf-8\"))); requestHeaders.add(\"Accept\", \"application/json\"); 设置form表单提交（请求参数要用MultiValueMap） HttpHeaders requestHeaders = new HttpHeaders(); requestHeaders.setContentType(org.springframework.http.MediaType.APPLICATION_FORM_URLENCODED); 注意请求参数要用MultiValueMap MultiValueMap postParameters = new LinkedMultiValueMap<>(); postParameters.add(\"grant_type\", \"client_credentials\"); HttpEntity> requestEntity = new HttpEntity<>(postParameters, requestHeaders); "},"java/util/json/json序列化和反序列化工具.html":{"url":"java/util/json/json序列化和反序列化工具.html","title":"json序列化和反序列化工具","keywords":"","body":" 利用TypeReference将json反序列化成复杂对象 用法如下: String responseBody = \"\"; CommonResult resultCommonResult = JsonUtil.getObjectMapper() .readValue(responseBody, new TypeReference>() { }); 其中CommonResult如下 package com.basic.bean; import com.fasterxml.jackson.databind.PropertyNamingStrategy; import com.fasterxml.jackson.databind.annotation.JsonNaming; import lombok.Data; import lombok.extern.slf4j.Slf4j; import java.util.List; /** * 通用结果 */ @Slf4j @Data @JsonNaming(PropertyNamingStrategy.SnakeCaseStrategy.class) public class CommonResult { private String targetUrl = null; private T result = null; private boolean success = false; private boolean authorizedRequest = false; private List errorInfos; private String seqNo; private long costTime = -1L; } "},"java/xxl-job/xxl-job定时任务教程.html":{"url":"java/xxl-job/xxl-job定时任务教程.html","title":"xxl-job定时任务教程","keywords":"","body":" 1、pom引入 com.xuxueli xxl-job-core 1.9.0 2、配置文件 xxl: job: admin: addresses: http://192.168.1.1:8480/xxl-job-admin #调度中心url executor: appname: accountTask #当前任务器的名字 ip: port: 9502 #调度中心调度任务的端口 logpath: ../logs/xxl-job-executor-demo/ # 日志位置 accessToken: emVuZ3FpLWJhbmdnb29k #简单安全AccessToken package com.tobe.erp.fit.account.config; import com.xxl.job.core.executor.XxlJobExecutor; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration //@ComponentScan(basePackages = \"com.tobe.erp.cashweb.task\") public class XxlJobConfig { private Logger logger = LoggerFactory.getLogger(XxlJobConfig.class); @Value(\"${xxl.job.admin.addresses}\") private String addresses; @Value(\"${xxl.job.executor.appname}\") private String appname; @Value(\"${xxl.job.executor.ip}\") private String ip; @Value(\"${xxl.job.executor.port}\") private int port; @Value(\"${xxl.job.executor.logpath}\") private String logpath; @Value(\"${xxl.job.accessToken}\") private String accessToken; @Bean(initMethod = \"start\", destroyMethod = \"destroy\") public XxlJobExecutor xxlJobExecutor() { logger.info(\">>>>>>>>>>> xxl-job config init.\"); XxlJobExecutor xxlJobExecutor = new XxlJobExecutor(); xxlJobExecutor.setIp(ip); xxlJobExecutor.setPort(port); xxlJobExecutor.setAppName(appname); xxlJobExecutor.setAdminAddresses(addresses); xxlJobExecutor.setLogPath(logpath); xxlJobExecutor.setAccessToken(accessToken); return xxlJobExecutor; } } 3、调用 package com.tobe.erp.fit.account.task; import com.xxl.job.core.biz.model.ReturnT; import com.xxl.job.core.handler.IJobHandler; import com.xxl.job.core.handler.annotation.JobHandler; import com.xxl.job.core.log.XxlJobLogger; import fit.basic.convert.StringToDateConvert; import fit.basic.util.aop.WebExceptionConfig; import fit.basic.util.idwork.IdUtil; import org.springframework.stereotype.Component; import org.springframework.util.StringUtils; import java.util.Date; @JobHandler(value=\"notifyTask\") @Component public class notifyTask extends IJobHandler { @Override public ReturnT execute(String param) throws Exception { Date excuteDate = new Date(); StringBuffer message = new StringBuffer(); XxlJobLogger.log(\"开始任务。\"); try{ }catch (Exception e){ XxlJobLogger.log(\"信息: \"+ WebExceptionConfig.printStackTraceToString(e),e); } XxlJobLogger.log(\"结束任务\"); return SUCCESS; } } 官网：http://www.xuxueli.com/xxl-job/#/?id=%e6%ba%90%e7%a0%81%e4%bb%93%e5%ba%93%e5%9c%b0%e5%9d%80 "},"java/xxl-job/xxl-job执行shell脚本问题分析.html":{"url":"java/xxl-job/xxl-job执行shell脚本问题分析.html","title":"xxl-job执行shell脚本问题分析","keywords":"","body":" ``` "},"micro-service/安全/xss攻击.html":{"url":"micro-service/安全/xss攻击.html","title":"xss攻击","keywords":"","body":" xss攻击 ``` "},"micro-service/架构/项目目录架构设计.html":{"url":"micro-service/架构/项目目录架构设计.html","title":"项目目录架构设计","keywords":"","body":" 设计1-分模块 如上图： 优点：如果要搞新的项目，system下基本上都是有用的，可以保留下来， 而business里的可以随便删除 如图：每个模块的controller、service、entity都分开，模块与模块直接不影响 缺点： 1、每个模块下都有controller、service、entity，导致包名重复 2、一个service模块调用另外个service模块跨度较大 3、service api和serviceImpl没分开，后期改造成微服务不太好操作 设计2-分模块 设计1-分模块 "},"micro-service/配置中心/appollo/apollo客户端配置使用.html":{"url":"micro-service/配置中心/appollo/apollo客户端配置使用.html","title":"apollo客户端配置使用.md","keywords":"","body":" 1、pom添加依赖 com.ctrip.framework.apollo apollo-client 1.4.0 2、启动类添加@EnableApolloConfig @SpringBootApplication(exclude = {DataSourceAutoConfiguration.class, HibernateJpaAutoConfiguration.class, DruidDataSourceAutoConfigure.class}) @EnableSwagger2 @EnableApolloConfig public class FzsIotCardApplication { public static void main(String[] args) { SpringApplication app = new SpringApplication(FzsIotCardApplication.class); app.setBannerMode(Banner.Mode.OFF); app.run(args); } } 3、application.properties增加配置 # 方式1 springboot的配置properties或yml文件添加下面的 app.id=fzs_iot_card2 # 方式2：环境变量里加-Dapp.id=YOUR-APP-ID # 方式3：classpath:/META-INF/app.properties文件存在 内容：app.id=YOUR-APP-ID apollo.meta=http://config-service-url:port ##下面这个不配也可以的 #env=DEV 4.使用 新建controller，里面通过${}引用，例如${swagger.context} @Slf4j @Api(value = \"API\", description = \"API\") @RestController @RequestMapping(\"/tIotCard\") public class TIotCardController { @Value(\"${swagger.context}\") private String swaggerContext; @Value(\"${test.testabc}\") private String testabc; @GetMapping(value = \"/get\") @ApiOperation(value = \"获取\", notes = \"\") public String get() { return swaggerContext+testabc; } } 使用参考： https://github.com/ctripcorp/apollo/wiki/Java%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97#3213-spring-boot%E9%9B%86%E6%88%90%E6%96%B9%E5%BC%8F%E6%8E%A8%E8%8D%90 "},"micro-service/配置中心/appollo/apollo手动监听接收变更的配置.html":{"url":"micro-service/配置中心/appollo/apollo手动监听接收变更的配置.html","title":"apollo手动监听接收变更的配置","keywords":"","body":" @ApolloConfigChangeListener 应用端监控Apollo配置改变后，接收消息，然后自定义处理，主要通过注解@ApolloConfigChangeListener来实现，如下： @ApolloConfigChangeListener(\"application\") public void configChangListener(ConfigChangeEvent changeEvent) { for (String key : changeEvent.changedKeys()) { log.info(\"监听到变化的配置key:{}\", key); if (\"cluster-flow-rules\".equalsIgnoreCase(key)) { ConfigChange configChange = changeEvent.getChange(key); String newFlowRules = configChange.getNewValue(); //更新redis stringRedisTemplate.opsForValue().set(clusterFlowRulesKey, newFlowRules); //更新sentinel stringRedisTemplate.convertAndSend(channel + clusterFlowRulesKey, newFlowRules); }else { log.info(\"变化的key不是cluster-flow-rules，不用操作\"); } } } 另外Apollo配置改变时，调试发现会跳到下面这个类中 com.ctrip.framework.apollo.spring.property.AutoUpdateConfigChangeListener#updateSpringValue Apollo客户端监听配置变化、动态刷新 "},"micro-service/配置中心/nacos/nacos-spring-cloud学习.html":{"url":"micro-service/配置中心/nacos/nacos-spring-cloud学习.html","title":"nacos-spring-cloud学习","keywords":"","body":" 1、 2、 3、 ``` "},"micro-service/配置中心/nacos/nacos安装和入门学习.html":{"url":"micro-service/配置中心/nacos/nacos安装和入门学习.html","title":"nacos安装和入门学习","keywords":"","body":" 安装和配置启动 1、下载nacos 下载地址： https://github.com/alibaba/nacos/releases 解压到某目录，cd 到nacos\\conf文件夹下 2、修改nacos\\conf\\application.properties配置数据库信息 文件内容如下： ### Count of DB: db.num=1 ### Connect URL of DB: db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC db.user=root db.password=root 3、执行nacos\\conf\\nacos-mysql.sql数据库脚本 在mysql中创建nacos数据库，然后执行nacos\\conf\\nacos-mysql.sql数据库脚本 4、 startup.cmd -m standalone启动nacos cd到nacos\\bin目录，执行 startup.cmd -m standalone 注意单机模式下要加上参数 -m standalone 否则启动失败的 5、登录Console看后台 启动完成后，登录http://10.20.11.161:8848/nacos/index.html 默认用户名和密码都是nacos 服务注册&发现和配置管理 1、服务注册 curl -X POST \"http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName&ip=20.18.7.10&port=8080\" 2、服务发现 curl -X GET \"http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=nacos.naming.serviceName\" 返回 {\"dom\":\"nacos.naming.serviceName\",\"hosts\":[],\"name\":\"DEFAULT_GROUP@@nacos.naming.serviceName\",\"cacheMillis\":3000,\"lastRefTime\":1600085004554,\"checksum\":\"7f882d81002bc22181203d423a20a16d\",\"useSpecifiedURL\":false,\"clusters\":\"\",\"env\":\"\",\"metadata\":{}} 3、发布配置 curl -X POST \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&group=test&content=HelloWorld\" 4、获取配置 curl -X GET \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&group=test\" 参考： https://nacos.io/zh-cn/docs/quick-start.html "},"micro-service/日志/log4j日志配置例子.html":{"url":"micro-service/日志/log4j日志配置例子.html","title":"log4j日志配置例子","keywords":"","body":" #log4j.rootLogger=debug,INFO, CONSOLE, FILE log4j.rootLogger=info, CONSOLE, FILE,stdout,debug # for console log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout log4j.appender.CONSOLE.layout.ConversionPattern=%d{YYYY-MM-dd HH:mm:ss.SSS} pid[${PID:- }] thread[%thread] %p %c{3}%x:%L - %m%n ## for file log4j.appender.FILE=org.apache.log4j.DailyRollingFileAppender log4j.appender.FILE.File=${profiles.logDir} #log4j.appender.FILE.Threshold =DEBUG log4j.appender.FILE.Append = true log4j.appender.FILE.layout=org.apache.log4j.PatternLayout log4j.appender.R.DatePattern = '.'yyyy-MM-dd log4j.appender.FILE.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss.SSS} pid[${PID:- }] thread[%thread] %p %c{3}%x:%L - %m%n #log4j.logger.com.ibatis=debug #log4j.logger.java.sql=debug #log4j.logger.com.sf.egmas.dcn.web.mapper=debug ###显示SQL语句部分 log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n # #log4j.logger.com.web=DEBUG #log4j.logger.com.ibatis=DEBUG #log4j.logger.com.ibatis.common.jdbc.SimpleDataSource=DEBUG #log4j.logger.com.ibatis.common.jdbc.ScriptRunner=DEBUG #log4j.logger.com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate=DEBUG #log4j.logger.Java.sql.Connection=DEBUG #log4j.logger.java.sql.Statement=DEBUG #log4j.logger.java.sql.PreparedStatement=DEBUG,stdout #log4j.logger.virtual.pkg.logger.mybatis=DEBUG #virtual.pkg.logger.mybatis=DEBUG # #log4j.logger.rabbit=ERROR #log4j.logger.org.springframework.amqp=ERROR 显示 sql语句配置 #log4j.logger.com.web=DEBUG #log4j.logger.com.ibatis=DEBUG #log4j.logger.com.ibatis.common.jdbc.SimpleDataSource=DEBUG #log4j.logger.com.ibatis.common.jdbc.ScriptRunner=DEBUG #log4j.logger.com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate=DEBUG #log4j.logger.Java.sql.Connection=DEBUG #log4j.logger.java.sql.Statement=DEBUG #log4j.logger.java.sql.PreparedStatement=DEBUG,stdout #log4j.logger.virtual.pkg.logger.mybatis=DEBUG #virtual.pkg.logger.mybatis=DEBUG ``` "},"micro-service/文档管理/japidoc文档管理.html":{"url":"micro-service/文档管理/japidoc文档管理.html","title":"japidoc文档管理","keywords":"","body":" pom引入 io.github.yedaxia japidocs 1.4.4 新建个测试类来执行就可以 package com.tobe.apidoc; import io.github.yedaxia.apidocs.Docs; import io.github.yedaxia.apidocs.DocsConfig; import io.github.yedaxia.apidocs.plugin.markdown.MarkdownDocPlugin; public class JapiDocTest { public static void main(String args[]) { DocsConfig config = new DocsConfig(); // 项目根目录 config.setProjectPath(\"D:\\\\idea-workspace-blog\\\\lqx-project-demo-github\\\\basic-server\"); // 项目名称 config.setProjectName(\"japi-docs\"); // 声明该API的版本 config.setApiVersion(\"V1.2\"); // 生成API 文档所在目录 config.setDocsPath(\"d:\\\\japi\"); // 配置自动生成 config.setAutoGenerate(Boolean.TRUE); //导出markdown config.addPlugin(new MarkdownDocPlugin()); // 执行生成文档 Docs.buildHtmlDocs(config); } } 查看结果 "},"micro-service/文档管理/pandoc教程.html":{"url":"micro-service/文档管理/pandoc教程.html","title":"pandoc教程","keywords":"","body":" 转换Markdown为HTML pandoc -s input.md -o output.html 其中“-s input.md”表示将Markdown文件转换为HTML文件，“-o output.html”表示将结果输出到output.html文件中。 我的 pandoc -s v7.5-门户短信-技术设计.md -o output.html 转换Markdown为PDFpandoc -s input.md -o output.pdf 和将Markdown转换为HTML的命令类似，只是输出的文件类型不同，需要使用PDF。 我的 pandoc -s v7.5-门户短信-技术设计.md -o output.pdf 报错： pdflatex not found. Please select a different --pdf-engine or install pdflatex 替换为：pandoc --pdf-engine=xelatex test.md -o test.pdf pandoc --pdf-engine=xelatex v7.5-门户短信-技术设计.md -o output.pdf 转换多个文件 pandoc -s file1.md file2.md -o output.html 可以同时将多个Markdown文件转换为同一个格式的文件。 引入CSS样式 pandoc -s input.md -o output.html --css=mycss.css 可以使用--css选项引入自定义的CSS样式。 生成目录 pandoc -s input.md -o output.html --toc 可以在生成的HTML文件中自动生成目录。 转换为其他格式 pandoc -s input.md -o output.docx ``` "},"micro-service/限流/限流算法/限流算法.html":{"url":"micro-service/限流/限流算法/限流算法.html","title":"限流算法","keywords":"","body":" 流量控制算法——漏桶算法和令牌桶算法 分布式接口幂等性、分布式限流（Guava 、nginx和lua限流） Sentinel如何实现接口流量控制？ 接口的屏蔽和限流很难么？Redis全搞定！ 5种限流算法，7种限流方式，挡住突发流量？ ``` "},"micro-service/限流/sentinel/基础/sentinel通过spi方式注册数据源.html":{"url":"micro-service/限流/sentinel/基础/sentinel通过spi方式注册数据源.html","title":"sentinel通过spi方式注册数据源","keywords":"","body":" 1、 Sentinel初始化之InitFunc实现类加载 参考： https://github.com/alibaba/Sentinel/wiki/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%99%E6%89%A9%E5%B1%95 ApolloDataSourceProperties SentinelProperties sentinel加载Apollo数据源相关入口 SentinelWebAutoConfiguration com.alibaba.cloud.sentinel.custom.SentinelDataSourceHandler com.alibaba.cloud.sentinel.custom.SentinelDataSourceHandler#afterSingletonsInstantiated com.alibaba.cloud.sentinel.datasource.factorybean.ApolloDataSourceFactoryBean#getObject com.alibaba.csp.sentinel.datasource.apollo.ApolloDataSource#ApolloDataSource private void loadAndUpdateRules() { try { T newValue = this.loadConfig(); if (newValue == null) { RecordLog.warn(\"[ApolloDataSource] WARN: rule config is null, you may have to check your data source\", new Object[0]); } this.getProperty().updateValue(newValue); } catch (Throwable var2) { RecordLog.warn(\"[ApolloDataSource] Error when loading rule config\", var2); } } 其他：少量参考，有些配置不适用 http://blog.didispace.com/spring-cloud-alibaba-sentinel-2-2/ 2、 3、 ``` "},"micro-service/限流/sentinel/基础/sentinel学习.html":{"url":"micro-service/限流/sentinel/基础/sentinel学习.html","title":"sentinel学习","keywords":"","body":" 技术攻克 本地测试流量控制(流量规则存在内存中) 控制台如何发送规则到应用的，发送的规则是什么样的格式的 应用如何连到控制台,心跳检测怎么实现 本地测试流量控制(流量规则配置在apollo) 控制台如何设置规则并发送到Apollo的原理，发送到apollo的数据是怎么样的 应用集群如何配置， springboot下，流量规则在Apollo，如何初始化流量规则 外来流量，在账号授权情况下，如何控制某账号的速率 集群失效，单机默认限流规则 调接口后异常处理 项目启动，自动获取Apollo上的集群配置信息，而不用手动触发推送 sentinel如何做到有访问流量时，才实例化集群?? 故障切换如何实现 集群总体阀值原理 http://localhost:19988/testBlock?t=-1 http://localhost:8719/getRules?type=flow 相关文档 新手指南 注解支持 Sentinel 控制台 启动配置项 控制台接入 动态规则扩展 在生产环境中使用 Sentinel 如何使用 Sentinel工作主流程 博客学习 Spring Cloud Alibaba Sentinel 集群流控 Sentinel 控制台（集群流控管理） com.alibaba.csp.sentinel.slots.block.flow.FlowRuleUtil#isValidRule "},"micro-service/限流/sentinel/集群流控/sentinel集群流控.html":{"url":"micro-service/限流/sentinel/集群流控/sentinel集群流控.html","title":"sentinel集群流控","keywords":"","body":" 若在生产环境使用集群限流，管控端还需要关注以下的问题： Token Server 自动管理（分配/选举 Token Server） Token Server 高可用，在某个 server 不可用时自动 failover 到其它机器 如何实现心跳检测 如何发放令牌和获取令牌 "},"micro-service/限流/sentinel/集群流控/sentinel集群流控1-配置说明.html":{"url":"micro-service/限流/sentinel/集群流控/sentinel集群流控1-配置说明.html","title":"sentinel集群流控1-配置说明","keywords":"","body":" 集群流量规则限流配置 [ { \"resource\": \"sayHelloResource3\", \"count\": 12, \"clusterMode\": true, \"clusterConfig\": { \"flowId\": \"1\", \"thresholdType\": 0, \"fallbackToLocalWhenFail\": true } }, { \"resource\": \"test3\", \"count\": 60, \"clusterMode\": true, \"clusterConfig\": { \"flowId\": \"2\", \"thresholdType\": 0, \"fallbackToLocalWhenFail\": true } } ] resource //要限流的资源名称,对应@SentinelResource注解里的name count //每秒限流的数目 fallbackToLocalWhenFail // 在 client 连接失败或通信失败时，是否退化到本地的限流模式 flowId // （必需）全局唯一的规则 ID，由集群限流管控端分配. thresholdType // 阈值模式，默认（0）为单机均摊，1 为全局阈值. https://github.com/alibaba/Sentinel/wiki/%E9%9B%86%E7%BE%A4%E6%B5%81%E6%8E%A7#%E9%9B%86%E7%BE%A4%E6%B5%81%E6%8E%A7%E8%A7%84%E5%88%99 集群相关ip和端口配置 [ { \"clientSet\": [ \"10.20.11.237@8721\", \"10.20.11.237@8719\" ], \"ip\": \"10.20.11.237\", \"machineId\": \"10.20.11.237@8719\", \"port\": 17631 } ] ip : 分配token的tokenServer的ip port ： 分配token的tokenServer的端口(注：这个端口应该是给控制台推送规则到tokenServer时使用的，具体看下面的分析。 这个port也用在tokenServer和tokenClient之间通信，) machineId : tokenServer的机器ip加port端口(这端口是tokenServer和tokenClient之间通信的？？？还是干嘛的 是用来区分同一台机器的同个应用的不同启动服务？？？) clientSet ： 客户端集合 上面配置对应类com.fzs.iotcard.sentinel.cluster.core.entity.ClusterGroupEntity @Data @ToString public class ClusterGroupEntity { private String machineId; private String ip; private Integer port; private Set clientSet; } 启动配置参数 -Dserver.port=8090 -Dcsp.sentinel.log.use.pid=true -Dcsp.sentinel.log.use.pid是防止本地启动同一应用的多个服务而导致日志不正常用的 "},"micro-service/限流/sentinel/集群流控/sentinel集群流控2-ServerTransportConfig.html":{"url":"micro-service/限流/sentinel/集群流控/sentinel集群流控2-ServerTransportConfig.html","title":"sentinel集群流控2-ServerTransportConfig","keywords":"","body":" ServerTransportConfig\\配置transport.port用途 8719端口配置如下： iotcard.cloud.sentinel.transport.port=8719 对应配置类为com.alibaba.csp.sentinel.cluster.server.config.ServerTransportConfig public class ServerTransportConfig { public static final int DEFAULT_IDLE_SECONDS = 600; private int port; private int idleSeconds; 调试发现当点击控制台的集群流控，就跳到 com.alibaba.csp.sentinel.cluster.server.command.handler.FetchClusterServerInfoCommandHandler#handle public CommandResponse handle(CommandRequest request) { JSONObject info = new JSONObject(); JSONArray connectionGroups = new JSONArray(); Set namespaceSet = ClusterServerConfigManager.getNamespaceSet(); Iterator var5 = namespaceSet.iterator(); while(var5.hasNext()) { String namespace = (String)var5.next(); ConnectionGroup group = ConnectionManager.getOrCreateConnectionGroup(namespace); if (group != null) { connectionGroups.add(group); } } ServerTransportConfig transportConfig = (new ServerTransportConfig()).setPort(ClusterServerConfigManager.getPort()).setIdleSeconds(ClusterServerConfigManager.getIdleSeconds()); ServerFlowConfig flowConfig = (new ServerFlowConfig()).setExceedCount(ClusterServerConfigManager.getExceedCount()).setMaxOccupyRatio(ClusterServerConfigManager.getMaxOccupyRatio()).setIntervalMs(ClusterServerConfigManager.getIntervalMs()).setSampleCount(ClusterServerConfigManager.getSampleCount()).setMaxAllowedQps(ClusterServerConfigManager.getMaxAllowedQps()); JSONArray requestLimitData = this.buildRequestLimitData(namespaceSet); info.fluentPut(\"port\", ClusterServerConfigManager.getPort()).fluentPut(\"connection\", connectionGroups).fluentPut(\"requestLimitData\", requestLimitData).fluentPut(\"transport\", transportConfig).fluentPut(\"flow\", flowConfig).fluentPut(\"namespaceSet\", namespaceSet).fluentPut(\"embedded\", ClusterServerConfigManager.isEmbedded()); info.put(\"appName\", AppNameUtil.getAppName()); return CommandResponse.ofSuccess(info.toJSONString()); } 其中这行设置端口 ServerTransportConfig transportConfig = (new ServerTransportConfig()).setPort(ClusterServerConfigManager.getPort()).setIdleSeconds(ClusterServerConfigManager.getIdleSeconds()); 分析：由于控制台要推送规则到配置中心或者客户端，则必须要连接到客户端，所以客户端必须提供个端口 才能建立连接，所以有默认个18730端口,所以ServerTransportConfig中的port就是这个端口 服务端配置类： 调用链： setPort:45, ServerTransportConfig (com.alibaba.csp.sentinel.cluster.server.config) handle:54, FetchClusterServerInfoCommandHandler (com.alibaba.csp.sentinel.cluster.server.command.handler) run:103, HttpEventTask (com.alibaba.csp.sentinel.transport.command.http) call:511, Executors$RunnableAdapter (java.util.concurrent) run$$$capture:266, FutureTask (java.util.concurrent) run:-1, FutureTask (java.util.concurrent) - Async stack trace :151, FutureTask (java.util.concurrent) newTaskFor:87, AbstractExecutorService (java.util.concurrent) submit:111, AbstractExecutorService (java.util.concurrent) run:191, SimpleHttpCommandCenter$ServerThread (com.alibaba.csp.sentinel.transport.command) call:511, Executors$RunnableAdapter (java.util.concurrent) run$$$capture:266, FutureTask (java.util.concurrent) run:-1, FutureTask (java.util.concurrent) - Async stack trace :151, FutureTask (java.util.concurrent) newTaskFor:87, AbstractExecutorService (java.util.concurrent) submit:111, AbstractExecutorService (java.util.concurrent) submit:678, Executors$DelegatedExecutorService (java.util.concurrent) run:106, SimpleHttpCommandCenter$2 (com.alibaba.csp.sentinel.transport.command) run:745, Thread (java.lang) 分析： 调用ClusterStateManager.registerProperty(clusterModeDs.getProperty());设置服务端状态时， 触发 init:40, CommandCenterInitFunc (com.alibaba.csp.sentinel.transport.init) 继续触发 start:75, SimpleHttpCommandCenter (com.alibaba.csp.sentinel.transport.command) 而在SimpleHttpCommandCenter.start里会新建个serverSocket来监听接收消息 executor.submit(new ServerThread(serverSocket)); 如下： 这里收到消息时会开线程调用执行HttpEventTask这个任务 class ServerThread extends Thread { private ServerSocket serverSocket; ServerThread(ServerSocket s) { this.serverSocket = s; setName(\"sentinel-courier-server-accept-thread\"); } @Override public void run() { while (true) { Socket socket = null; try { socket = this.serverSocket.accept(); setSocketSoTimeout(socket); HttpEventTask eventTask = new HttpEventTask(socket); bizExecutor.submit(eventTask); } catch (Exception e) { CommandCenterLog.info(\"Server error\", e); if (socket != null) { try { socket.close(); } catch (Exception e1) { CommandCenterLog.info(\"Error when closing an opened socket\", e1); } } try { // In case of infinite log. Thread.sleep(10); } catch (InterruptedException e1) { // Indicates the task should stop. break; } } } } } 那什么时候触发这里的接收消息，当在sentinel控制台里点击集群监控，就会触发到这里 如下： 控制台调用cluster/server/info这个http请求获取集群服务器的信息，上面的ServerSocket这个监听 会根据请求路径来解析到FetchClusterServerInfoCommandHandler处理器所以会有下面的HttpEventTask任务跳转到FetchClusterServerInfoCommandHandler处理 handle:54, FetchClusterServerInfoCommandHandler (com.alibaba.csp.sentinel.cluster.server.command.handler) run:103, HttpEventTask (com.alibaba.csp.sentinel.transport.command.http) 问题： 看了sentinel控制台集群流控的源码，好像没有调用http请求，那这个接收到的socket请求来自哪里的？？？ 难度是在新建ServerThread这个serverSocket线程时 new HttpEventTask(socket)这个时执行的，应该是?? 但是为什么点击sentinel控制台的集群监控会触发这个调试呢？？ sentinel控制台调用地方： 直接搜索cluster/server/info点调用即可出来 前端入口： Request URL: http://localhost:9090/cluster/server_state/FlowSyncApplication com.alibaba.csp.sentinel.dashboard.controller.cluster.ClusterConfigController#apiGetClusterServerStateOfApp com.alibaba.csp.sentinel.dashboard.service.ClusterConfigService#getClusterUniversalState(java.lang.String) public CompletableFuture> getClusterUniversalState(String app) { if (StringUtil.isBlank(app)) { return AsyncUtils.newFailedFuture(new IllegalArgumentException(\"app cannot be empty\")); } AppInfo appInfo = appManagement.getDetailApp(app); if (appInfo == null || appInfo.getMachines() == null) { return CompletableFuture.completedFuture(new ArrayList<>()); } List> futures = appInfo.getMachines().stream() .filter(e -> e.isHealthy()) .map(machine -> getClusterUniversalState(app, machine.getIp(), machine.getPort()) .thenApply(e -> new ClusterUniversalStatePairVO(machine.getIp(), machine.getPort(), e))) .collect(Collectors.toList()); return AsyncUtils.sequenceSuccessFuture(futures); } 可以看到是根据machine的ip和port端口(默认8719)来请求客户端的，这个machine来自appManagement，具体是由心跳检测上报在sentinel控制台的 具体又调到getClusterUniversalState方法 public CompletableFuture getClusterUniversalState(String app, String ip, int port) { return sentinelApiClient.fetchClusterMode(ip, port) .thenApply(e -> new ClusterUniversalStateVO().setStateInfo(e)) .thenCompose(vo -> { if (vo.getStateInfo().getClientAvailable()) { return sentinelApiClient.fetchClusterClientInfoAndConfig(ip, port) .thenApply(cc -> vo.setClient(new ClusterClientStateVO().setClientConfig(cc))); } else { return CompletableFuture.completedFuture(vo); } }).thenCompose(vo -> { if (vo.getStateInfo().getServerAvailable()) { return sentinelApiClient.fetchClusterServerBasicInfo(ip, port) .thenApply(vo::setServer); } else { return CompletableFuture.completedFuture(vo); } }); } 又调到sentinelApiClient.fetchClusterServerBasicInfo(ip, port) 下面其中FETCH_CLUSTER_SERVER_BASIC_INFO_PATH就是cluster/server/info public CompletableFuture fetchClusterServerBasicInfo(String ip, int port) { if (StringUtil.isBlank(ip) || port JSON.parseObject(r, ClusterServerStateVO.class)); } catch (Exception ex) { logger.warn(\"Error when fetching cluster sever all config and basic info\", ex); return AsyncUtils.newFailedFuture(ex); } } 看日志Socket[addr=/10.20.11.237,port=13019,localport=8720] 可以看到接收到的端口是8720 另外关于port和localport的: java.net.SocketImpl /** * The port number on the remote host to which this socket is connected. */ protected int port; /** * The local port number to which this socket is connected. */ protected int localport; localport 是本机端口， socket port 应该是 server port 吧，表示对端端口 tcp/ip 中使用 本地ip:port 远程 ip :port 表示一个通信 参考：https://zhidao.baidu.com/question/691871712846751924.html 而FetchClusterServerInfoCommandHandler setPort:45, ServerTransportConfig (com.alibaba.csp.sentinel.cluster.server.config) handle:54, FetchClusterServerInfoCommandHandler (com.alibaba.csp.sentinel.cluster.server.command.handler) "},"micro-service/限流/sentinel/集群流控/sentinel集群流控3-TransportConfig.html":{"url":"micro-service/限流/sentinel/集群流控/sentinel集群流控3-TransportConfig.html","title":"sentinel集群流控3-TransportConfig","keywords":"","body":" TransportConfig TransportConfig.runtimePort这个是配置 \"machineId\": \"10.20.11.237@8719\" 用的 public class TransportConfig { public static final String CONSOLE_SERVER = \"csp.sentinel.dashboard.server\"; public static final String SERVER_PORT = \"csp.sentinel.api.port\"; public static final String HEARTBEAT_INTERVAL_MS = \"csp.sentinel.heartbeat.interval.ms\"; public static final String HEARTBEAT_CLIENT_IP = \"csp.sentinel.heartbeat.client.ip\"; public static final String HEARTBEAT_API_PATH = \"csp.sentinel.heartbeat.api.path\"; public static final String HEARTBEAT_DEFAULT_PATH = \"/registry/machine\"; private static int runtimePort = -1; 有三个调用的地方 第一个地方： com.alibaba.csp.sentinel.transport.command.netty.HttpServer#start int retryCount = 0; ChannelFuture channelFuture = null; // loop for an successful binding while (true) { int newPort = getNewPort(port, retryCount); try { channelFuture = b.bind(newPort).sync(); TransportConfig.setRuntimePort(newPort); CommandCenterLog.info(\"[NettyHttpCommandCenter] Begin listening at port \" + newPort); break; } catch (Exception e) { TimeUnit.MILLISECONDS.sleep(30); RecordLog.warn(\"[HttpServer] Netty server bind error, port={}, retry={}\", newPort, retryCount); retryCount ++; } } /** * Increase port number every 3 tries. * * @param basePort base port to start * @param retryCount retry count * @return next calculated port */ private int getNewPort(int basePort, int retryCount) { return basePort + retryCount / 3; } io.netty.bootstrap.AbstractBootstrap#bind(int) public ChannelFuture bind(int inetPort) { return this.bind(new InetSocketAddress(inetPort)); } 分析： 1、先获取端口getNewPort(port, retryCount)2、绑定端口b.bind(newPort).sync(); 3、绑定失败则retryCount ++循环重新获取端口,所以端口会递增 问题： 1、什么时候HttpServer#start方法会调用到??? 第二个地方： com.alibaba.csp.sentinel.transport.command.SimpleHttpCommandCenter#start @Override public void run() { boolean success = false; ServerSocket serverSocket = getServerSocketFromBasePort(port); if (serverSocket != null) { CommandCenterLog.info(\"[CommandCenter] Begin listening at port \" + serverSocket.getLocalPort()); socketReference = serverSocket; executor.submit(new ServerThread(serverSocket)); success = true; port = serverSocket.getLocalPort(); } else { CommandCenterLog.info(\"[CommandCenter] chooses port fail, http command center will not work\"); } if (!success) { port = PORT_UNINITIALIZED; } TransportConfig.setRuntimePort(port); executor.shutdown(); } } private static ServerSocket getServerSocketFromBasePort(int basePort) { int tryCount = 0; while(true) { try { ServerSocket server = new ServerSocket(basePort + tryCount / 3, 100); server.setReuseAddress(true); return server; } catch (IOException var5) { ++tryCount; try { TimeUnit.MILLISECONDS.sleep(30L); } catch (InterruptedException var4) { return null; } } } } 创建的ServerSocket如下： ServerSocket[addr=0.0.0.0/0.0.0.0,localport=8720] 分析： 1、这里也是尝试根据port建立ServerSocket new ServerSocket(basePort + tryCount / 3, 100); 2、然后获取建立的ServerSocket对应真正的端口 this.port = serverSocket.getLocalPort(); 3、将端口重新设置回TransportConfig TransportConfig.setRuntimePort(this.port); 调用链： start:75, SimpleHttpCommandCenter (com.alibaba.csp.sentinel.transport.command) init:40, CommandCenterInitFunc (com.alibaba.csp.sentinel.transport.init) doInit:53, InitExecutor (com.alibaba.csp.sentinel.init) :51, ClusterStateManager (com.alibaba.csp.sentinel.cluster) initStateProperty:323, RedisClusterInitFunc (com.fzs.iotcard.sentinel.cluster.redis) init:155, RedisClusterInitFunc (com.fzs.iotcard.sentinel.cluster.redis) 从下往上看： 触发点是在这： com.fzs.iotcard.sentinel.cluster.redis.RedisClusterInitFunc#initStateProperty{ ClusterStateManager.registerProperty(clusterModeDs.getProperty()); } ClusterStateManager static { InitExecutor.doInit(); stateProperty.addListener(PROPERTY_LISTENER); } @InitOrder(-1) public class CommandCenterInitFunc implements InitFunc { public CommandCenterInitFunc() { } public void init() throws Exception { CommandCenter commandCenter = CommandCenterProvider.getCommandCenter(); if (commandCenter == null) { RecordLog.warn(\"[CommandCenterInitFunc] Cannot resolve CommandCenter\", new Object[0]); } else { commandCenter.beforeStart(); commandCenter.start(); RecordLog.info(\"[CommandCenterInit] Starting command center: \" + commandCenter.getClass().getCanonicalName(), new Object[0]); } } } 而CommandCenterProvider.getCommandCenter()取出的是SimpleHttpCommandCenter com.alibaba.csp.sentinel.transport.command.SimpleHttpCommandCenter#start{ TransportConfig.setRuntimePort(this.port); } 第三个地方 com.alibaba.csp.sentinel.transport.command.SimpleHttpCommandCenter#stop @Override public void stop() throws Exception { if (socketReference != null) { try { socketReference.close(); } catch (IOException e) { CommandCenterLog.warn(\"Error when releasing the server socket\", e); } } bizExecutor.shutdownNow(); executor.shutdownNow(); TransportConfig.setRuntimePort(PORT_UNINITIALIZED); handlerMap.clear(); } 这个地方是http服务关闭后重新设置TransportConfig中端口为-1 TransportConfig.setRuntimePort(PORT_UNINITIALIZED); TransportConfig#getPort获取配置文件配置的端口 com.alibaba.csp.sentinel.transport.config.TransportConfig#getPort public static String getPort() { return runtimePort > 0 ? String.valueOf(runtimePort) : SentinelConfig.getConfig(\"csp.sentinel.api.port\"); } 1、先判断当前TransportConfig的runtimePort是否大于0，小于0则从SentinelConfig.getConfig(\"csp.sentinel.api.port\")取 2、而csp.sentinel.api.port来源于下面 com.fzs.iotcard.sentinel.cluster.core.autoconfigure.ClusterSentinelAutoConfiguration#init if (StringUtils.isEmpty(System.getProperty(TransportConfig.SERVER_PORT)) && StringUtils.hasText(properties.getTransport().getPort())) { System.setProperty(TransportConfig.SERVER_PORT, properties.getTransport().getPort()); } 其中TransportConfig.SERVER_PORT为 public class TransportConfig { public static final String SERVER_PORT = \"csp.sentinel.api.port\"; } "},"micro-service/限流/sentinel/集群流控/sentinel集群流控4-ClusterClientAssignConfig.html":{"url":"micro-service/限流/sentinel/集群流控/sentinel集群流控4-ClusterClientAssignConfig.html","title":"sentinel集群流控4-ClusterClientAssignConfig","keywords":"","body":" ClusterClientAssignConfig客户端分配配置 com.alibaba.csp.sentinel.cluster.client.config.ClusterClientAssignConfig public class ClusterClientAssignConfig { private String serverHost; private Integer serverPort; 看下面知道是将ClusterGroupEntity中的ip和port设置到ClusterClientAssignConfig中的， 也就是说这个port也用在tokenServer和tokenClient之间通信，那machineId(例如10.20.11.237@8719) 中@后面的8719又是干嘛用的 protected Optional extractClientAssignment(List groupList) { if (groupList.stream().anyMatch(this::machineEqual)) { return Optional.empty(); } // Build client assign config from the client set of target server group. for (ClusterGroupEntity group : groupList) { if (group.getClientSet().contains(getCurrentMachineId())) { String ip = group.getIp(); Integer port = group.getPort(); return Optional.of(new ClusterClientAssignConfig(ip, port)); } } return Optional.empty(); } 集群流控 "},"micro-service/限流/sentinel/集群流控/sentinel集群流控5-心跳检测.html":{"url":"micro-service/限流/sentinel/集群流控/sentinel集群流控5-心跳检测.html","title":"sentinel集群流控5-心跳检测","keywords":"","body":" "},"micro-service/限流/sentinel/控制台/sentinel控制台部署和应用接入.html":{"url":"micro-service/限流/sentinel/控制台/sentinel控制台部署和应用接入.html","title":"sentinel控制台部署和应用接入","keywords":"","body":" 启动和访问控制台： java -Dserver.port=9090 -Dcsp.sentinel.dashboard.server=localhost:9090 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard-1.8.0.jar 默认用户名和密码都是 sentinel 应用连接 Sentinel 控制台 Sentinel 开源控制台支持实时监控和规则管理。接入控制台的步骤如下： （1）下载控制台 jar 包并在本地启动：可以参见 此处文档。 （2）客户端接入控制台，需要： 客户端需要引入 Transport 模块来与 Sentinel 控制台进行通信。您可以通过 pom.xml 引入 JAR 包: com.alibaba.csp sentinel-transport-simple-http 1.8.0 启动时加入 JVM 参数 -Dcsp.sentinel.dashboard.server=consoleIp:port 指定控制台地址和端口。更多的参数参见 启动参数文档。 确保应用端有访问量 比如我的： 在edit configurations -> vm opitons添加如下即可： -Dcsp.sentinel.dashboard.server=localhost:9090 -Dserver.port=8091 -Dcsp.sentinel.log.use.pid=true springboot的或者cloud可以在配置文件中指定控制台的地址和端口，参考如下： Spring Cloud Alibaba Sentinel 参考： Sentinel 控制台 启动配置项 注意：若在本地启动多个 Demo 示例，需要加上 -Dcsp.sentinel.log.use.pid=true 参数，否则控制台显示监控会不准确。 1、 2、 3、 ``` "},"micro-service/限流/sentinel/控制台/sentinel控制台改造.html":{"url":"micro-service/限流/sentinel/控制台/sentinel控制台改造.html","title":"sentinel控制台改造","keywords":"","body":" 1、pomx.ml增加redis依赖引用 org.springframework.boot spring-boot-starter-data-redis ${spring.boot.version} 2、新增类 FlowRuleRedisProvider：自定义实现基于redis的拉取规则 FlowRuleRedisPublisher：自定义实现流控配置推送规则 RedisConfig：redis配置类 RuleConstants：自定义常量类 说明：本次个人新增的类均在包com.alibaba.csp.sentinel.dashboard.rule.redis下面 上面具体的类内容看项目 3、新增redis和流控规则配置 # Redis\\u6570\\u636E\\u5E93\\u7D22\\u5F15\\uFF08\\u9ED8\\u8BA4\\u4E3A0\\uFF09 spring.redis.database=2 # Redis\\u670D\\u52A1\\u5668\\u5730\\u5740 spring.redis.host=10.20.100.167 # Redis\\u670D\\u52A1\\u5668\\u8FDE\\u63A5\\u7AEF\\u53E3 spring.redis.port=7003 # \\u8FDE\\u63A5\\u8D85\\u65F6\\u65F6\\u95F4\\uFF08\\u6BEB\\u79D2\\uFF09 spring.redis.timeout=30000 ##\\u7AEF\\u53E3\\u53F7 server.port=9090 #\\u6D41\\u63A7\\u89C4\\u5219key\\u524D\\u7F00 rule.flow=cluster-flow-rules- rule.channel=sentinel-channel- 1、 上面redis配置可以配置在Apollo中2、 rule.flow 是用来获取集群流控规则的key前缀 rule.channel 是发送流控规则变化消息到redis的channel前缀， 这2个在上面新增的类FlowRuleRedisProvider和FlowRuleRedisPublisher中会利用到 4、修改com.alibaba.csp.sentinel.dashboard.controller.v2.FlowControllerV2类 替换为自定义拉取和推送规则实现类 @Autowired @Qualifier(\"flowRuleRedisProvider\") private DynamicRuleProvider> ruleProvider; @Autowired @Qualifier(\"flowRuleRedisPublisher\") private DynamicRulePublisher> rulePublisher; 5、修改src\\main\\webapp\\resources\\app\\scripts\\directives\\sidebar\\sidebar.html将dashboard.flowV1替换为dashboard.flow 修改前源码 &nbsp;&nbsp;流控规则 修改后源码 &nbsp;&nbsp;流控规则 改造参考： Sentinel 控制台（集群流控管理） https://gitee.com/lvlaotou/sentinel-dashboard-redis/ 编译sentinel-dashbord遇到的问题 问题1： Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.12.4:test 加上下面插件解决： org.apache.maven.plugins maven-surefire-plugin 2.4.2 true 参考： https://www.cnblogs.com/lxcy/p/8279899.html 问题2： Error:java: Compilation failed: internal java compiler error 解决: 查看java编译器版本,发现是1.5的，将本项目对应的版本改为1.8 "},"micro-service/限流/sentinel/源码分析/sentinel源码解析1-SentinelResource注解源码分析.html":{"url":"micro-service/限流/sentinel/源码分析/sentinel源码解析1-SentinelResource注解源码分析.html","title":"SentinelResource注解源码分析","keywords":"","body":" SentinelResource注解切面处理类源码如下： com.alibaba.csp.sentinel.annotation.aspectj.SentinelResourceAspect @Aspect public class SentinelResourceAspect extends AbstractSentinelAspectSupport { @Pointcut(\"@annotation(com.alibaba.csp.sentinel.annotation.SentinelResource)\") public void sentinelResourceAnnotationPointcut() { } @Around(\"sentinelResourceAnnotationPointcut()\") public Object invokeResourceWithSentinel(ProceedingJoinPoint pjp) throws Throwable { Method originMethod = resolveMethod(pjp); SentinelResource annotation = originMethod.getAnnotation(SentinelResource.class); if (annotation == null) { // Should not go through here. throw new IllegalStateException(\"Wrong state for SentinelResource annotation\"); } String resourceName = getResourceName(annotation.value(), originMethod); EntryType entryType = annotation.entryType(); int resourceType = annotation.resourceType(); Entry entry = null; try { entry = SphU.entry(resourceName, resourceType, entryType, pjp.getArgs()); Object result = pjp.proceed(); return result; } catch (BlockException ex) { return handleBlockException(pjp, annotation, ex); } catch (Throwable ex) { Class[] exceptionsToIgnore = annotation.exceptionsToIgnore(); // The ignore list will be checked first. if (exceptionsToIgnore.length > 0 && exceptionBelongsTo(ex, exceptionsToIgnore)) { throw ex; } if (exceptionBelongsTo(ex, annotation.exceptionsToTrace())) { traceException(ex); return handleFallback(pjp, annotation, ex); } // No fallback function can handle the exception, so throw it out. throw ex; } finally { if (entry != null) { entry.exit(1, pjp.getArgs()); } } } } 分析： 可以看到，关键入口都是 entry = SphU.entry(resourceName, resourceType, entryType, pjp.getArgs()); 其中resourceName是从注解那里获取的，所以在这个步骤上，如果我们要实现账号级别的 限流控制，可以这样设计：1、定义一个账号-资源关联表，缓存起来2、SentinelResource注解标注在controller或serviceImpl层，resourceName可以固定某个字符串，但是这个还不是真正的 资源名称，3、自己写个类似SentinelResourceAspect的，请求进来时，从请求头中获取账号信息，从缓存(步骤1)中获取账号对应的资源，将resourceName(步骤2)加上资源 这个才是真正要限流的资源 举例子： @SentinelResource(value = \"flowSyncResource\",blockHandler = \"sayHelloBlockHandler\") public String sayHello(String name) { System.out.println(getCurrentMachineId() + \",\" + name + \",\" + new Date()); return \"Hello, \" + name; } 然后自己定义个MySentinelResourceAspect,在里面组装资源名为flowSyncResource-AAA等 ``` "},"micro-service/限流/sentinel/源码分析/sentinel源码解析2-sentinel命名空间namespace分析.html":{"url":"micro-service/限流/sentinel/源码分析/sentinel源码解析2-sentinel命名空间namespace分析.html","title":"sentinel命名空间namespace分析","keywords":"","body":" Namespace注册和获取以及设值 appName取值 设值入口com.alibaba.csp.sentinel.config.SentinelConfig#resolveAppName 取值顺序逻辑如下： 环境变量system env中取csp.sentinel.app.name property中取csp.sentinel.app.name property中取project.name 从property中取sun.java.command(正在执行的类) 根据上面的取值，我们可以如下配置启动参数，这个会影响sentinel的namespace 例如启动参数配置： -Dserver.port=19988 -Dproject.name=ClusterDemoApplication -Dcsp.sentinel.log.use.pid=true -Dcsp.sentinel.app.name=SYS_IOT.flow-sync-sentinel -Dserver.port=19989 -Dproject.name=ClusterDemoApplication2 -Dcsp.sentinel.log.use.pid=true -Dcsp.sentinel.app.name=SYS_IOT.flow-sync-sentinel -Dserver.port=19990 -Dproject.name=ClusterDemoApplication3 -Dcsp.sentinel.log.use.pid=true -Dcsp.sentinel.app.name=SYS_IOT.flow-sync-sentinel 上面由于设置了-Dcsp.sentinel.app.name=SYS_IOT.flow-sync-sentinel 所以在sentinel-dashbord控制台上左边菜单栏看到的是SYS_IOT.flow-sync-sentinel 另外启动参数配置的，参考类SentinelConfig appName用途 入口：com.alibaba.csp.sentinel.cluster.server.SentinelDefaultTokenServer#handleEmbeddedStart 嵌入式集群启动 com.alibaba.csp.sentinel.cluster.server.SentinelDefaultTokenServer#handleEmbeddedStart 配置供应者注册器获取Namespace com.alibaba.csp.sentinel.cluster.registry.ConfigSupplierRegistry#getNamespaceSupplier 配置供应者注册器返回默认Namespace com.alibaba.csp.sentinel.cluster.registry.ConfigSupplierRegistry#DEFAULT_APP_NAME_SUPPLIER 配置供应者注册器实际上返回AppNameUtil.getAppName() com.alibaba.csp.sentinel.util.AppNameUtil#getAppName AppNameUtil.getAppName()里返回的是SentinelConfig#getAppName com.alibaba.csp.sentinel.config.SentinelConfig#getAppName namespace加载分析 namespace 入口：com.alibaba.csp.sentinel.cluster.server.SentinelDefaultTokenServer#handleEmbeddedStart private void handleEmbeddedStart() { //先从环境变量参数，配置文件属性里，或者启动的类中获取namespace String namespace = ConfigSupplierRegistry.getNamespaceSupplier().get();//(1) if (StringUtil.isNotEmpty(namespace)) { // Mark server global mode as embedded. ClusterServerConfigManager.setEmbedded(true);//(2) if (!ClusterServerConfigManager.getNamespaceSet().contains(namespace)) {//(3) Set namespaceSet = new HashSet<>(ClusterServerConfigManager.getNamespaceSet()); namespaceSet.add(namespace); ClusterServerConfigManager.loadServerNamespaceSet(namespaceSet);//(4) } // Register self to connection group. ConnectionManager.addConnection(namespace, HostNameUtil.getIp()); } } 分析： (1)先从环境变量参数，配置文件属性里，或者启动的类中获取namespace (2)若获取到namespace不为空，则集群配置管理器ClusterServerConfigManager设置为嵌入式 (3)若ClusterServerConfigManager中的namespaceSet命名集合不包含namespace，则新建namespaceSet集合， 新建实例化时添加默认namespace为default (4)调用loadServerNamespaceSet加载步骤(1)的namespace 这个会从Apollo获取该命名空间最新的配置的 ``` "},"micro-service/限流/sentinel/sentinel问题汇总/sentinel问题汇总.html":{"url":"micro-service/限流/sentinel/sentinel问题汇总/sentinel问题汇总.html","title":"sentinel问题汇总","keywords":"","body":" Sentinel流控-排队等待 Java高并发大流量限流（摘选） ``` "},"micro-service/rabbitmq/rabbitmq相关问题/rabbitmq相关问题.html":{"url":"micro-service/rabbitmq/rabbitmq相关问题/rabbitmq相关问题.html","title":"rabbitmq相关问题","keywords":"","body":" Channel shutdown问题、 rabbit 406问题、basicAck导致项目一直重启问题 2021-02-05 00:00:05.706 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.654 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.665 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.668 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.673 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.676 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#12-1896] ERROR c.f.i.f.mq.consumer.FlowSyncBusinessHandleListener - IotCardHistoryBatchInsert onMessage error org.springframework.amqp.AmqpException: PublisherCallbackChannel is closed at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:1166) at com.sun.proxy.$Proxy161.basicAck(Unknown Source) at com.fzs.iotcard.flowsync.mq.consumer.FlowSyncBusinessHandleListener.flowSyncBusinessHandleListener(FlowSyncBusinessHandleListener.java:62) at sun.reflect.GeneratedMethodAccessor234.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120) at org.springframework.amqp.rabbit.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:53) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:220) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandlerAndProcessResult(MessagingMessageListenerAdapter.java:148) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.onMessage(MessagingMessageListenerAdapter.java:133) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:1591) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.actualInvokeListener(AbstractMessageListenerContainer.java:1510) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:1498) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:1489) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:1433) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:970) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:916) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$1600(SimpleMessageListenerContainer.java:83) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.mainLoop(SimpleMessageListenerContainer.java:1291) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1197) at java.lang.Thread.run(Thread.java:748) 2021-02-05 00:00:06.685 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.688 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.690 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#12-1897] ERROR c.f.i.f.mq.consumer.FlowSyncBusinessHandleListener - IotCardHistoryBatchInsert onMessage error org.springframework.amqp.AmqpException: PublisherCallbackChannel is closed at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:1166) at com.sun.proxy.$Proxy161.basicAck(Unknown Source) at com.fzs.iotcard.flowsync.mq.consumer.FlowSyncBusinessHandleListener.flowSyncBusinessHandleListener(FlowSyncBusinessHandleListener.java:62) at sun.reflect.GeneratedMethodAccessor234.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120) at org.springframework.amqp.rabbit.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:53) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:220) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandlerAndProcessResult(MessagingMessageListenerAdapter.java:148) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.onMessage(MessagingMessageListenerAdapter.java:133) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:1591) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.actualInvokeListener(AbstractMessageListenerContainer.java:1510) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:1498) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:1489) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:1433) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:970) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:916) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$1600(SimpleMessageListenerContainer.java:83) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.mainLoop(SimpleMessageListenerContainer.java:1291) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1197) at java.lang.Thread.run(Thread.java:748) 网上搜索了好久没结果，后来发现网上有说406是double 确认消息导致，然后又仔细看了下日志，发现有行 at com.fzs.iotcard.flowsync.mq.consumer.FlowSyncBusinessHandleListener.flowSyncBusinessHandleListener(FlowSyncBusinessHandleListener.java:62) 然后对比代码,发现有行 channel.basicAck(message2.getMessageProperties().getDeliveryTag(), false); 然后finally里面也有行一样的代码，所以就是这里导致的，删掉第一个就可以了 同时在下面rabbitmq的配置代码里改为手动确认消息模式AcknowledgeMode.MANUAL @Autowired private CachingConnectionFactory connectionFactory; @Bean(name = \"defaultRabbitContainerFactory\") public SimpleRabbitListenerContainerFactory defaultContainer() { SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); connectionFactory.setPublisherConfirms(true); connectionFactory.setPublisherReturns(true); connectionFactory.setConnectionTimeout(0); factoryConfigurer.configure(factory, connectionFactory); factory.setAcknowledgeMode(AcknowledgeMode.MANUAL); factory.setConcurrentConsumers(concurrentConsumers); factory.setMaxConcurrentConsumers(maxConcurrentConsumers); factory.setPrefetchCount(prefetch); return factory; } 另外，注意这里由于用Autowired注入CachingConnectionFactory，所以配置文件里加上下面这些可能会无效 spring.rabbitmq.listener.max-concurrency = 20 spring.rabbitmq.listener.prefetch = 3 spring.rabbitmq.publisher-confirm-type = correlated spring.rabbitmq.publisher-returns = true spring.rabbitmq.listener.simple.acknowledge-mode = manual 另外当时也怀疑是不是并发连接rabbitmq线程数,所以就把下面的配置concurrentConsumers改为2000了 factory.setConcurrentConsumers(concurrentConsumers); 参考：http://blog.chinaunix.net/uid-192452-id-5837248.html https://blog.csdn.net/more_try/article/details/82804387 https://www.cnblogs.com/littleatp/p/6087856.html 连接超时问题 2021-02-05 17:29:44.868 INFO 11360 --- [tContainer#3-38] o.s.a.r.l.SimpleMessageListenerContainer : Restarting Consumer@4aa5edf: tags=[[amq.ctag-9EeR86pC4jHA0zXYAFdrag]], channel=Cached Rabbit Channel: PublisherCallbackChannelImpl: AMQChannel(amqp://iot_test@10.20.70.228:5672/,111), conn: Proxy@2fb48970 Shared Rabbit Connection: SimpleConnection@37ab8291 [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 59376], acknowledgeMode=MANUAL local queue size=0 2021-02-05 17:29:44.870 INFO 11360 --- [Container#12-35] o.s.a.r.l.SimpleMessageListenerContainer : Restarting Consumer@71be1c4d: tags=[[amq.ctag-99PRhByyfPPeGfusdSyeeg]], channel=Cached Rabbit Channel: PublisherCallbackChannelImpl: AMQChannel(amqp://iot_test@10.20.70.228:5672/,109), conn: Proxy@2fb48970 Shared Rabbit Connection: SimpleConnection@37ab8291 [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 59376], acknowledgeMode=MANUAL local queue size=0 2021-02-05 17:29:44.870 INFO 11360 --- [tContainer#0-38] o.s.a.r.l.SimpleMessageListenerContainer : Restarting Consumer@472d1192: tags=[[amq.ctag-f9UHqoKjMD-vZlTlSEAjiw]], channel=Cached Rabbit Channel: PublisherCallbackChannelImpl: AMQChannel(amqp://iot_test@10.20.70.228:5672/,113), conn: Proxy@2fb48970 Shared Rabbit Connection: SimpleConnection@37ab8291 [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 59376], acknowledgeMode=MANUAL local queue size=0 2021-02-05 17:29:44.870 INFO 11360 --- [Container#15-28] o.s.a.r.l.SimpleMessageListenerContainer : Restarting Consumer@55267225: tags=[[amq.ctag-epbtQkURKWHwXEw0tOQleQ]], channel=Cached Rabbit Channel: PublisherCallbackChannelImpl: AMQChannel(amqp://iot_test@10.20.70.228:5672/,108), conn: Proxy@2fb48970 Shared Rabbit Connection: SimpleConnection@37ab8291 [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 59376], acknowledgeMode=MANUAL local queue size=0 2021-02-05 17:29:44.874 WARN 11360 --- [.20.70.228:5672] c.r.c.impl.ForgivingExceptionHandler : An unexpected connection driver error occured (Exception message: Connection reset) 2021-02-05 17:29:44.878 ERROR 11360 --- [tContainer#5-42] o.s.a.r.c.CachingConnectionFactory : Could not configure the channel to receive publisher confirms java.io.IOException: null at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:129) at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:125) at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:147) at com.rabbitmq.client.impl.ChannelN.confirmSelect(ChannelN.java:1558) at com.rabbitmq.client.impl.ChannelN.confirmSelect(ChannelN.java:46) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.doCreateBareChannel(CachingConnectionFactory.java:726) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createBareChannel(CachingConnectionFactory.java:706) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.getCachedChannelProxy(CachingConnectionFactory.java:676) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.getChannel(CachingConnectionFactory.java:567) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.access$1600(CachingConnectionFactory.java:102) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$ChannelCachingConnectionProxy.createChannel(CachingConnectionFactory.java:1439) at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:2095) at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2062) at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2042) at org.springframework.amqp.rabbit.core.RabbitAdmin.initialize(RabbitAdmin.java:604) at org.springframework.amqp.rabbit.core.RabbitAdmin.lambda$null$10(RabbitAdmin.java:532) at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:287) at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:164) at org.springframework.amqp.rabbit.core.RabbitAdmin.lambda$afterPropertiesSet$11(RabbitAdmin.java:531) at org.springframework.amqp.rabbit.connection.CompositeConnectionListener.onCreate(CompositeConnectionListener.java:36) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createConnection(CachingConnectionFactory.java:757) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createBareChannel(CachingConnectionFactory.java:702) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.getCachedChannelProxy(CachingConnectionFactory.java:676) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.getChannel(CachingConnectionFactory.java:567) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.access$1600(CachingConnectionFactory.java:102) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$ChannelCachingConnectionProxy.createChannel(CachingConnectionFactory.java:1439) at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:2095) at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2062) at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2042) at org.springframework.amqp.rabbit.core.RabbitAdmin.getQueueInfo(RabbitAdmin.java:407) at org.springframework.amqp.rabbit.core.RabbitAdmin.getQueueProperties(RabbitAdmin.java:391) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.attemptDeclarations(AbstractMessageListenerContainer.java:1842) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.redeclareElementsIfNecessary(AbstractMessageListenerContainer.java:1823) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.initialize(SimpleMessageListenerContainer.java:1349) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1195) at java.lang.Thread.run(Thread.java:748) Caused by: com.rabbitmq.client.ShutdownSignalException: connection error at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:66) at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:36) at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:502) at com.rabbitmq.client.impl.AMQChannel.privateRpc(AMQChannel.java:293) at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:141) ... 33 common frames omitted Caused by: java.net.SocketException: Connection reset at java.net.SocketInputStream.read(SocketInputStream.java:210) at java.net.SocketInputStream.read(SocketInputStream.java:141) at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) at java.io.BufferedInputStream.read(BufferedInputStream.java:265) at java.io.DataInputStream.readUnsignedByte(DataInputStream.java:288) at com.rabbitmq.client.impl.Frame.readFrom(Frame.java:91) at com.rabbitmq.client.impl.SocketFrameHandler.readFrame(SocketFrameHandler.java:184) at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:665) ... 1 common frames omitted 2021-02-05 17:29:44.878 ERROR 11360 --- [tContainer#5-42] o.s.a.r.c.CachingConnectionFactory : Channel shutdown: connection error 2021-02-05 17:29:44.881 INFO 11360 --- [tContainer#6-37] o.s.a.r.l.SimpleMessageListenerContainer : Restarting Consumer@51b6c389: tags=[[amq.ctag-guPwnFBcx45Hqz6wErsN4w]], channel=Cached Rabbit Channel: PublisherCallbackChannelImpl: AMQChannel(amqp://iot_test@10.20.70.228:5672/,115), conn: Proxy@2fb48970 Shared Rabbit Connection: SimpleConnection@37ab8291 [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 59376], acknowledgeMode=MANUAL local queue size=0 2021-02-05 17:29:44.882 INFO 11360 --- [tContainer#1-37] o.s.a.r.l.SimpleMessageListenerContainer : Restarting Consumer@7b342267: tags=[[amq.ctag-SBgkb06moG6nE69lNlGwBg]], channel=Cached Rabbit Channel: PublisherCallbackChannelImpl: AMQChannel(amqp://iot_test@10.20.70.228:5672/,104), conn: Proxy@2fb48970 Shared Rabbit Connection: SimpleConnection@37ab8291 [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 59376], acknowledgeMode=MANUAL local queue size=0 2 连接超时问题是由于spring.rabbitmq.connection-timeout 设置过小引起 后来将其设置为0就好了，好像0表示无穷大，不超时 rabbitmq基本配置 spring.rabbitmq.host: 服务Host spring.rabbitmq.port: 服务端口 spring.rabbitmq.username: 登陆用户名 spring.rabbitmq.password: 登陆密码 spring.rabbitmq.virtual-host: 连接到rabbitMQ的vhost spring.rabbitmq.addresses: 指定client连接到的server的地址，多个以逗号分隔(优先取addresses，然后再取host) spring.rabbitmq.requested-heartbeat: 指定心跳超时，单位秒，0为不指定；默认60s spring.rabbitmq.publisher-confirms: 是否启用【发布确认】 spring.rabbitmq.publisher-returns: 是否启用【发布返回】 spring.rabbitmq.connection-timeout: 连接超时，单位毫秒，0表示无穷大，不超时 spring.rabbitmq.parsed-addresses: https://www.cnblogs.com/imfx/p/12454299.html https://www.cnblogs.com/qts-hope/p/11242559.html ForgivingExceptionHandler : An unexpected connection driver error occured 下面这个还没找到具体是什么问题 2021-02-05 17:43:31.989 INFO 12156 --- [nio-9090-exec-1] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Start completed. 2021-02-05 17:43:34.540 INFO 12156 --- [ main] o.s.a.r.l.SimpleMessageListenerContainer : Broker not available; cannot force queue declarations during start: java.util.concurrent.TimeoutException 2021-02-05 17:43:34.542 ERROR 12156 --- [.20.70.228:5672] c.r.c.impl.ForgivingExceptionHandler : An unexpected connection driver error occured java.net.SocketException: Socket Closed at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) at java.net.SocketInputStream.read(SocketInputStream.java:171) at java.net.SocketInputStream.read(SocketInputStream.java:141) at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) at java.io.BufferedInputStream.read(BufferedInputStream.java:265) at java.io.DataInputStream.readUnsignedByte(DataInputStream.java:288) at com.rabbitmq.client.impl.Frame.readFrom(Frame.java:91) at com.rabbitmq.client.impl.SocketFrameHandler.readFrame(SocketFrameHandler.java:184) at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:665) at java.lang.Thread.run(Thread.java:748) 2021-02-05 17:43:34.547 INFO 12156 --- [nio-9090-exec-2] o.s.a.r.c.CachingConnectionFactory : Attempting to connect to: [10.20.70.228:5672] 2021-02-05 17:43:34.934 INFO 12156 --- [nio-9090-exec-2] o.s.a.r.c.CachingConnectionFactory : Created new connection: rabbitConnectionFactory#708eb310:1/SimpleConnection@2175c78b [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 61567] log4j:WARN No appenders could be found for logger (freemarker.cache). log4j:WARN Please initialize the log4j system properly. log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info. log4j:WARN No appenders could be found for logger (freemarker.cache). log4j:WARN Please initialize the log4j system properly. ConcurrentModificationException问题 2021-02-06 10:00:12.428 INFO 12 --- [tContainer#12-4] f.i.f.m.c.FlowSyncBusinessHandleListener : iotCardId:40700000149846,总耗时：1 2021-02-06 10:00:12.427 ERROR 12 --- [tContainer#12-1] f.i.f.m.c.FlowSyncBusinessHandleListener : IotCardHistoryBatchInsert onMessage error:{} org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: ### Error updating database. Cause: java.util.ConcurrentModificationException ### The error may exist in URL [jar:file:/usr/local/flow-sync-service/flow-sync-service-master.jar!/BOOT-INF/classes!/mapper/FlowSyncCardMonitorHistoryMapper.xml] ### The error may involve com.fzs.iotcard.flowsync.mapper.FlowSyncCardMonitorHistoryMapper.insertHistoryBatch ### The error occurred while executing an update ### Cause: java.util.ConcurrentModificationException at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:92) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) at com.sun.proxy.$Proxy89.insert(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:271) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:60) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) at com.sun.proxy.$Proxy110.insertHistoryBatch(Unknown Source) at com.fzs.iotcard.flowsync.service.impl.FlowSyncCardMonitorHistoryServiceImpl.insertHistoryBatch(FlowSyncCardMonitorHistoryServiceImpl.java:40) at com.fzs.iotcard.flowsync.mq.consumer.FlowSyncBusinessHandleListener.flowSyncBusinessHandleListener(FlowSyncBusinessHandleListener.java:71) at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120) at org.springframework.amqp.rabbit.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:53) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:220) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandlerAndProcessResult(MessagingMessageListenerAdapter.java:148) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.onMessage(MessagingMessageListenerAdapter.java:133) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:1591) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.actualInvokeListener(AbstractMessageListenerContainer.java:1510) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:1498) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:1489) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:1433) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:970) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:916) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$1600(SimpleMessageListenerContainer.java:83) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.mainLoop(SimpleMessageListenerContainer.java:1291) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1197) at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.ibatis.exceptions.PersistenceException: ### Error updating database. Cause: java.util.ConcurrentModificationException ### The error may exist in URL [jar:file:/usr/local/flow-sync-service/flow-sync-service-master.jar!/BOOT-INF/classes!/mapper/FlowSyncCardMonitorHistoryMapper.xml] ### The error may involve com.fzs.iotcard.flowsync.mapper.FlowSyncCardMonitorHistoryMapper.insertHistoryBatch ### The error occurred while executing an update ### Cause: java.util.ConcurrentModificationException at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:199) at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:184) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) ... 28 common frames omitted Caused by: java.util.ConcurrentModificationException: null at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:909) at java.util.ArrayList$Itr.next(ArrayList.java:859) at org.apache.ibatis.scripting.xmltags.ForEachSqlNode.apply(ForEachSqlNode.java:61) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.lambda$apply$0(MixedSqlNode.java:32) at java.util.ArrayList.forEach(ArrayList.java:1257) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:32) at org.apache.ibatis.scripting.xmltags.DynamicSqlSource.getBoundSql(DynamicSqlSource.java:39) at org.apache.ibatis.mapping.MappedStatement.getBoundSql(MappedStatement.java:305) at org.apache.ibatis.executor.statement.BaseStatementHandler.(BaseStatementHandler.java:64) at org.apache.ibatis.executor.statement.PreparedStatementHandler.(PreparedStatementHandler.java:41) at org.apache.ibatis.executor.statement.RoutingStatementHandler.(RoutingStatementHandler.java:46) at org.apache.ibatis.session.Configuration.newStatementHandler(Configuration.java:636) at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:48) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Invocation.proceed(Invocation.java:49) at com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor.intercept(MybatisPlusInterceptor.java:82) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) at com.sun.proxy.$Proxy168.update(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:197) ... 34 common frames omitted 这个貌似是删除ArrayList的问题，还没找到解决办法 由于全局定义了个ArrayList，而在mq接收信息里存在并发修改这个，代码如下： List historyList = Lists.newArrayList(); int defaultCount = 100; @RabbitListener(containerFactory = \"defaultRabbitContainerFactory\", bindings = @QueueBinding( exchange = @Exchange(value = QueueConstant.FLOWSYN_INSERT_DB_EXCHANGE), value = @Queue(value = QueueConstant.FLOWSYN_INSERT_DB_QUEUE, durable = \"true\"), key = QueueConstant.FLOWSYN_INSERT_DB_ROUTINGKEY ), admin = RabbitMqCoreConfig.adminName, concurrency = \"1\") public void flowSyncBusinessHandleListener(Message message, Channel channel, Message message2) { try { long beginTime = System.currentTimeMillis(); log.info(\"IotCardHistoryBatchInsert receive queue: {},hashCode:{}\", message.getMessageProperties().getReceivedRoutingKey(), hashCode()); String msg = new String(message.getBody(), \"utf-8\"); CardMonitorHistory iotCardMonitorHistory = Jacksons.parse(msg, CardMonitorHistory.class); historyList.add(iotCardMonitorHistory); String countStr = BeanFactory.getMessageFromApollo(\"historyBatchInsert\"); if (StringUtil.isNEmpty(countStr)) { defaultCount = Integer.valueOf(countStr); } if (historyList.size() == defaultCount) { log.info(\"IotCardHistoryBatchInsert 批量插入数据库限制数量数量={}\", defaultCount); flowSyncCardMonitorHistoryService.insertHistoryBatch(historyList); log.info(\"IotCardHistoryBatchInsert 已批量插入数据库\"); for (CardMonitorHistory cardMonitorHistory : historyList) { flowSyncBusinessHandleService.syncHistoryToTrans(cardMonitorHistory); } historyList.clear(); log.info(\"IotCardHistoryBatchInsert 清空list数据\"); } log.info(\"iotCardId:{},总耗时：{}\", iotCardMonitorHistory.getIotCardId(), System.currentTimeMillis() - beginTime); } catch (Exception e) { historyList.clear(); log.error(\"IotCardHistoryBatchInsert onMessage error:{}\", e); } finally { //告诉服务器收到这条消息 已经被我消费了 可以在队列删掉 这样以后就不会再发了 否则消息服务器以为这条消息没处理掉 后续还会在发 //手动应答消息　　第一个参数是所确认消息的标识，第二参数是是否批量确认 try { channel.basicAck(message2.getMessageProperties().getDeliveryTag(), false); } catch (IOException e) { log.error(\"basicAck异常:{}\", e); } } } SpringBoot2.x下RabbitMQ的并发参数（concurrency和prefetch） https://www.cnblogs.com/dolphin0520/p/3933551.html Java ConcurrentModificationException异常原因和解决方法 "},"micro-service/rabbitmq/rabbitmq相关问题/rabbitmq-channel-shutdown问题.html":{"url":"micro-service/rabbitmq/rabbitmq相关问题/rabbitmq-channel-shutdown问题.html","title":"rabbitmq-channel-shutdown问题","keywords":"","body":" Channel shutdown问题、 rabbit 406问题、basicAck导致项目一直重启问题 2021-02-05 00:00:05.706 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.654 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.665 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.668 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.673 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.676 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#12-1896] ERROR c.f.i.f.mq.consumer.FlowSyncBusinessHandleListener - IotCardHistoryBatchInsert onMessage error org.springframework.amqp.AmqpException: PublisherCallbackChannel is closed at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:1166) at com.sun.proxy.$Proxy161.basicAck(Unknown Source) at com.fzs.iotcard.flowsync.mq.consumer.FlowSyncBusinessHandleListener.flowSyncBusinessHandleListener(FlowSyncBusinessHandleListener.java:62) at sun.reflect.GeneratedMethodAccessor234.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120) at org.springframework.amqp.rabbit.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:53) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:220) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandlerAndProcessResult(MessagingMessageListenerAdapter.java:148) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.onMessage(MessagingMessageListenerAdapter.java:133) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:1591) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.actualInvokeListener(AbstractMessageListenerContainer.java:1510) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:1498) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:1489) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:1433) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:970) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:916) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$1600(SimpleMessageListenerContainer.java:83) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.mainLoop(SimpleMessageListenerContainer.java:1291) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1197) at java.lang.Thread.run(Thread.java:748) 2021-02-05 00:00:06.685 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.688 [AMQP Connection 10.20.70.228:5672] ERROR o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) 2021-02-05 00:00:06.690 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#12-1897] ERROR c.f.i.f.mq.consumer.FlowSyncBusinessHandleListener - IotCardHistoryBatchInsert onMessage error org.springframework.amqp.AmqpException: PublisherCallbackChannel is closed at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:1166) at com.sun.proxy.$Proxy161.basicAck(Unknown Source) at com.fzs.iotcard.flowsync.mq.consumer.FlowSyncBusinessHandleListener.flowSyncBusinessHandleListener(FlowSyncBusinessHandleListener.java:62) at sun.reflect.GeneratedMethodAccessor234.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120) at org.springframework.amqp.rabbit.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:53) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:220) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandlerAndProcessResult(MessagingMessageListenerAdapter.java:148) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.onMessage(MessagingMessageListenerAdapter.java:133) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:1591) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.actualInvokeListener(AbstractMessageListenerContainer.java:1510) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:1498) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:1489) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:1433) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:970) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:916) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$1600(SimpleMessageListenerContainer.java:83) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.mainLoop(SimpleMessageListenerContainer.java:1291) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1197) at java.lang.Thread.run(Thread.java:748) 网上搜索了好久没结果，后来发现网上有说406是double 确认消息导致，然后又仔细看了下日志，发现有行 at com.fzs.iotcard.flowsync.mq.consumer.FlowSyncBusinessHandleListener.flowSyncBusinessHandleListener(FlowSyncBusinessHandleListener.java:62) 然后对比代码,发现有行 channel.basicAck(message2.getMessageProperties().getDeliveryTag(), false); 然后finally里面也有行一样的代码，所以就是这里导致的，删掉第一个就可以了 同时在下面rabbitmq的配置代码里改为手动确认消息模式AcknowledgeMode.MANUAL @Autowired private CachingConnectionFactory connectionFactory; @Bean(name = \"defaultRabbitContainerFactory\") public SimpleRabbitListenerContainerFactory defaultContainer() { SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); connectionFactory.setPublisherConfirms(true); connectionFactory.setPublisherReturns(true); connectionFactory.setConnectionTimeout(0); factoryConfigurer.configure(factory, connectionFactory); factory.setAcknowledgeMode(AcknowledgeMode.MANUAL); factory.setConcurrentConsumers(concurrentConsumers); factory.setMaxConcurrentConsumers(maxConcurrentConsumers); factory.setPrefetchCount(prefetch); return factory; } 另外，注意这里由于用Autowired注入CachingConnectionFactory，所以配置文件里加上下面这些可能会无效 spring.rabbitmq.listener.max-concurrency = 20 spring.rabbitmq.listener.prefetch = 3 spring.rabbitmq.publisher-confirm-type = correlated spring.rabbitmq.publisher-returns = true spring.rabbitmq.listener.simple.acknowledge-mode = manual 另外当时也怀疑是不是并发连接rabbitmq线程数,所以就把下面的配置concurrentConsumers改为2000了 factory.setConcurrentConsumers(concurrentConsumers); 参考：http://blog.chinaunix.net/uid-192452-id-5837248.htmlhttps://blog.csdn.net/more_try/article/details/82804387https://www.cnblogs.com/littleatp/p/6087856.html 连接超时问题 2021-02-05 17:29:44.868 INFO 11360 --- [tContainer#3-38] o.s.a.r.l.SimpleMessageListenerContainer : Restarting Consumer@4aa5edf: tags=[[amq.ctag-9EeR86pC4jHA0zXYAFdrag]], channel=Cached Rabbit Channel: PublisherCallbackChannelImpl: AMQChannel(amqp://iot_test@10.20.70.228:5672/,111), conn: Proxy@2fb48970 Shared Rabbit Connection: SimpleConnection@37ab8291 [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 59376], acknowledgeMode=MANUAL local queue size=0 2021-02-05 17:29:44.870 INFO 11360 --- [Container#12-35] o.s.a.r.l.SimpleMessageListenerContainer : Restarting Consumer@71be1c4d: tags=[[amq.ctag-99PRhByyfPPeGfusdSyeeg]], channel=Cached Rabbit Channel: PublisherCallbackChannelImpl: AMQChannel(amqp://iot_test@10.20.70.228:5672/,109), conn: Proxy@2fb48970 Shared Rabbit Connection: SimpleConnection@37ab8291 [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 59376], acknowledgeMode=MANUAL local queue size=0 2021-02-05 17:29:44.870 INFO 11360 --- [tContainer#0-38] o.s.a.r.l.SimpleMessageListenerContainer : Restarting Consumer@472d1192: tags=[[amq.ctag-f9UHqoKjMD-vZlTlSEAjiw]], channel=Cached Rabbit Channel: PublisherCallbackChannelImpl: AMQChannel(amqp://iot_test@10.20.70.228:5672/,113), conn: Proxy@2fb48970 Shared Rabbit Connection: SimpleConnection@37ab8291 [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 59376], acknowledgeMode=MANUAL local queue size=0 2021-02-05 17:29:44.870 INFO 11360 --- [Container#15-28] o.s.a.r.l.SimpleMessageListenerContainer : Restarting Consumer@55267225: tags=[[amq.ctag-epbtQkURKWHwXEw0tOQleQ]], channel=Cached Rabbit Channel: PublisherCallbackChannelImpl: AMQChannel(amqp://iot_test@10.20.70.228:5672/,108), conn: Proxy@2fb48970 Shared Rabbit Connection: SimpleConnection@37ab8291 [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 59376], acknowledgeMode=MANUAL local queue size=0 2021-02-05 17:29:44.874 WARN 11360 --- [.20.70.228:5672] c.r.c.impl.ForgivingExceptionHandler : An unexpected connection driver error occured (Exception message: Connection reset) 2021-02-05 17:29:44.878 ERROR 11360 --- [tContainer#5-42] o.s.a.r.c.CachingConnectionFactory : Could not configure the channel to receive publisher confirms java.io.IOException: null at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:129) at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:125) at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:147) at com.rabbitmq.client.impl.ChannelN.confirmSelect(ChannelN.java:1558) at com.rabbitmq.client.impl.ChannelN.confirmSelect(ChannelN.java:46) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.doCreateBareChannel(CachingConnectionFactory.java:726) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createBareChannel(CachingConnectionFactory.java:706) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.getCachedChannelProxy(CachingConnectionFactory.java:676) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.getChannel(CachingConnectionFactory.java:567) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.access$1600(CachingConnectionFactory.java:102) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$ChannelCachingConnectionProxy.createChannel(CachingConnectionFactory.java:1439) at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:2095) at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2062) at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2042) at org.springframework.amqp.rabbit.core.RabbitAdmin.initialize(RabbitAdmin.java:604) at org.springframework.amqp.rabbit.core.RabbitAdmin.lambda$null$10(RabbitAdmin.java:532) at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:287) at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:164) at org.springframework.amqp.rabbit.core.RabbitAdmin.lambda$afterPropertiesSet$11(RabbitAdmin.java:531) at org.springframework.amqp.rabbit.connection.CompositeConnectionListener.onCreate(CompositeConnectionListener.java:36) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createConnection(CachingConnectionFactory.java:757) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createBareChannel(CachingConnectionFactory.java:702) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.getCachedChannelProxy(CachingConnectionFactory.java:676) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.getChannel(CachingConnectionFactory.java:567) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.access$1600(CachingConnectionFactory.java:102) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$ChannelCachingConnectionProxy.createChannel(CachingConnectionFactory.java:1439) at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:2095) at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2062) at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2042) at org.springframework.amqp.rabbit.core.RabbitAdmin.getQueueInfo(RabbitAdmin.java:407) at org.springframework.amqp.rabbit.core.RabbitAdmin.getQueueProperties(RabbitAdmin.java:391) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.attemptDeclarations(AbstractMessageListenerContainer.java:1842) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.redeclareElementsIfNecessary(AbstractMessageListenerContainer.java:1823) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.initialize(SimpleMessageListenerContainer.java:1349) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1195) at java.lang.Thread.run(Thread.java:748) Caused by: com.rabbitmq.client.ShutdownSignalException: connection error at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:66) at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:36) at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:502) at com.rabbitmq.client.impl.AMQChannel.privateRpc(AMQChannel.java:293) at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:141) ... 33 common frames omitted Caused by: java.net.SocketException: Connection reset at java.net.SocketInputStream.read(SocketInputStream.java:210) at java.net.SocketInputStream.read(SocketInputStream.java:141) at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) at java.io.BufferedInputStream.read(BufferedInputStream.java:265) at java.io.DataInputStream.readUnsignedByte(DataInputStream.java:288) at com.rabbitmq.client.impl.Frame.readFrom(Frame.java:91) at com.rabbitmq.client.impl.SocketFrameHandler.readFrame(SocketFrameHandler.java:184) at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:665) ... 1 common frames omitted 2021-02-05 17:29:44.878 ERROR 11360 --- [tContainer#5-42] o.s.a.r.c.CachingConnectionFactory : Channel shutdown: connection error 2021-02-05 17:29:44.881 INFO 11360 --- [tContainer#6-37] o.s.a.r.l.SimpleMessageListenerContainer : Restarting Consumer@51b6c389: tags=[[amq.ctag-guPwnFBcx45Hqz6wErsN4w]], channel=Cached Rabbit Channel: PublisherCallbackChannelImpl: AMQChannel(amqp://iot_test@10.20.70.228:5672/,115), conn: Proxy@2fb48970 Shared Rabbit Connection: SimpleConnection@37ab8291 [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 59376], acknowledgeMode=MANUAL local queue size=0 2021-02-05 17:29:44.882 INFO 11360 --- [tContainer#1-37] o.s.a.r.l.SimpleMessageListenerContainer : Restarting Consumer@7b342267: tags=[[amq.ctag-SBgkb06moG6nE69lNlGwBg]], channel=Cached Rabbit Channel: PublisherCallbackChannelImpl: AMQChannel(amqp://iot_test@10.20.70.228:5672/,104), conn: Proxy@2fb48970 Shared Rabbit Connection: SimpleConnection@37ab8291 [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 59376], acknowledgeMode=MANUAL local queue size=0 2 连接超时问题是由于spring.rabbitmq.connection-timeout 设置过小引起 后来将其设置为0就好了，好像0表示无穷大，不超时 rabbitmq基本配置 spring.rabbitmq.host: 服务Host spring.rabbitmq.port: 服务端口 spring.rabbitmq.username: 登陆用户名 spring.rabbitmq.password: 登陆密码 spring.rabbitmq.virtual-host: 连接到rabbitMQ的vhost spring.rabbitmq.addresses: 指定client连接到的server的地址，多个以逗号分隔(优先取addresses，然后再取host) spring.rabbitmq.requested-heartbeat: 指定心跳超时，单位秒，0为不指定；默认60s spring.rabbitmq.publisher-confirms: 是否启用【发布确认】 spring.rabbitmq.publisher-returns: 是否启用【发布返回】 spring.rabbitmq.connection-timeout: 连接超时，单位毫秒，0表示无穷大，不超时 spring.rabbitmq.parsed-addresses: https://www.cnblogs.com/imfx/p/12454299.html https://www.cnblogs.com/qts-hope/p/11242559.html ForgivingExceptionHandler : An unexpected connection driver error occured 下面这个还没找到具体是什么问题 2021-02-05 17:43:31.989 INFO 12156 --- [nio-9090-exec-1] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Start completed. 2021-02-05 17:43:34.540 INFO 12156 --- [ main] o.s.a.r.l.SimpleMessageListenerContainer : Broker not available; cannot force queue declarations during start: java.util.concurrent.TimeoutException 2021-02-05 17:43:34.542 ERROR 12156 --- [.20.70.228:5672] c.r.c.impl.ForgivingExceptionHandler : An unexpected connection driver error occured java.net.SocketException: Socket Closed at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) at java.net.SocketInputStream.read(SocketInputStream.java:171) at java.net.SocketInputStream.read(SocketInputStream.java:141) at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) at java.io.BufferedInputStream.read(BufferedInputStream.java:265) at java.io.DataInputStream.readUnsignedByte(DataInputStream.java:288) at com.rabbitmq.client.impl.Frame.readFrom(Frame.java:91) at com.rabbitmq.client.impl.SocketFrameHandler.readFrame(SocketFrameHandler.java:184) at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:665) at java.lang.Thread.run(Thread.java:748) 2021-02-05 17:43:34.547 INFO 12156 --- [nio-9090-exec-2] o.s.a.r.c.CachingConnectionFactory : Attempting to connect to: [10.20.70.228:5672] 2021-02-05 17:43:34.934 INFO 12156 --- [nio-9090-exec-2] o.s.a.r.c.CachingConnectionFactory : Created new connection: rabbitConnectionFactory#708eb310:1/SimpleConnection@2175c78b [delegate=amqp://iot_test@10.20.70.228:5672/, localPort= 61567] log4j:WARN No appenders could be found for logger (freemarker.cache). log4j:WARN Please initialize the log4j system properly. log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info. log4j:WARN No appenders could be found for logger (freemarker.cache). log4j:WARN Please initialize the log4j system properly. ConcurrentModificationException问题 2021-02-06 10:00:12.428 INFO 12 --- [tContainer#12-4] f.i.f.m.c.FlowSyncBusinessHandleListener : iotCardId:40700000149846,总耗时：1 2021-02-06 10:00:12.427 ERROR 12 --- [tContainer#12-1] f.i.f.m.c.FlowSyncBusinessHandleListener : IotCardHistoryBatchInsert onMessage error:{} org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: ### Error updating database. Cause: java.util.ConcurrentModificationException ### The error may exist in URL [jar:file:/usr/local/flow-sync-service/flow-sync-service-master.jar!/BOOT-INF/classes!/mapper/FlowSyncCardMonitorHistoryMapper.xml] ### The error may involve com.fzs.iotcard.flowsync.mapper.FlowSyncCardMonitorHistoryMapper.insertHistoryBatch ### The error occurred while executing an update ### Cause: java.util.ConcurrentModificationException at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:92) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) at com.sun.proxy.$Proxy89.insert(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:271) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:60) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) at com.sun.proxy.$Proxy110.insertHistoryBatch(Unknown Source) at com.fzs.iotcard.flowsync.service.impl.FlowSyncCardMonitorHistoryServiceImpl.insertHistoryBatch(FlowSyncCardMonitorHistoryServiceImpl.java:40) at com.fzs.iotcard.flowsync.mq.consumer.FlowSyncBusinessHandleListener.flowSyncBusinessHandleListener(FlowSyncBusinessHandleListener.java:71) at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120) at org.springframework.amqp.rabbit.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:53) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:220) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandlerAndProcessResult(MessagingMessageListenerAdapter.java:148) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.onMessage(MessagingMessageListenerAdapter.java:133) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:1591) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.actualInvokeListener(AbstractMessageListenerContainer.java:1510) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:1498) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:1489) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:1433) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:970) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:916) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$1600(SimpleMessageListenerContainer.java:83) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.mainLoop(SimpleMessageListenerContainer.java:1291) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1197) at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.ibatis.exceptions.PersistenceException: ### Error updating database. Cause: java.util.ConcurrentModificationException ### The error may exist in URL [jar:file:/usr/local/flow-sync-service/flow-sync-service-master.jar!/BOOT-INF/classes!/mapper/FlowSyncCardMonitorHistoryMapper.xml] ### The error may involve com.fzs.iotcard.flowsync.mapper.FlowSyncCardMonitorHistoryMapper.insertHistoryBatch ### The error occurred while executing an update ### Cause: java.util.ConcurrentModificationException at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:199) at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:184) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) ... 28 common frames omitted Caused by: java.util.ConcurrentModificationException: null at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:909) at java.util.ArrayList$Itr.next(ArrayList.java:859) at org.apache.ibatis.scripting.xmltags.ForEachSqlNode.apply(ForEachSqlNode.java:61) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.lambda$apply$0(MixedSqlNode.java:32) at java.util.ArrayList.forEach(ArrayList.java:1257) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:32) at org.apache.ibatis.scripting.xmltags.DynamicSqlSource.getBoundSql(DynamicSqlSource.java:39) at org.apache.ibatis.mapping.MappedStatement.getBoundSql(MappedStatement.java:305) at org.apache.ibatis.executor.statement.BaseStatementHandler.(BaseStatementHandler.java:64) at org.apache.ibatis.executor.statement.PreparedStatementHandler.(PreparedStatementHandler.java:41) at org.apache.ibatis.executor.statement.RoutingStatementHandler.(RoutingStatementHandler.java:46) at org.apache.ibatis.session.Configuration.newStatementHandler(Configuration.java:636) at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:48) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Invocation.proceed(Invocation.java:49) at com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor.intercept(MybatisPlusInterceptor.java:82) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) at com.sun.proxy.$Proxy168.update(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:197) ... 34 common frames omitted 这个貌似是删除ArrayList的问题，还没找到解决办法 由于全局定义了个ArrayList，而在mq接收信息里存在并发修改这个，代码如下： List historyList = Lists.newArrayList(); int defaultCount = 100; @RabbitListener(containerFactory = \"defaultRabbitContainerFactory\", bindings = @QueueBinding( exchange = @Exchange(value = QueueConstant.FLOWSYN_INSERT_DB_EXCHANGE), value = @Queue(value = QueueConstant.FLOWSYN_INSERT_DB_QUEUE, durable = \"true\"), key = QueueConstant.FLOWSYN_INSERT_DB_ROUTINGKEY ), admin = RabbitMqCoreConfig.adminName, concurrency = \"1\") public void flowSyncBusinessHandleListener(Message message, Channel channel, Message message2) { try { long beginTime = System.currentTimeMillis(); log.info(\"IotCardHistoryBatchInsert receive queue: {},hashCode:{}\", message.getMessageProperties().getReceivedRoutingKey(), hashCode()); String msg = new String(message.getBody(), \"utf-8\"); CardMonitorHistory iotCardMonitorHistory = Jacksons.parse(msg, CardMonitorHistory.class); historyList.add(iotCardMonitorHistory); String countStr = BeanFactory.getMessageFromApollo(\"historyBatchInsert\"); if (StringUtil.isNEmpty(countStr)) { defaultCount = Integer.valueOf(countStr); } if (historyList.size() == defaultCount) { log.info(\"IotCardHistoryBatchInsert 批量插入数据库限制数量数量={}\", defaultCount); flowSyncCardMonitorHistoryService.insertHistoryBatch(historyList); log.info(\"IotCardHistoryBatchInsert 已批量插入数据库\"); for (CardMonitorHistory cardMonitorHistory : historyList) { flowSyncBusinessHandleService.syncHistoryToTrans(cardMonitorHistory); } historyList.clear(); log.info(\"IotCardHistoryBatchInsert 清空list数据\"); } log.info(\"iotCardId:{},总耗时：{}\", iotCardMonitorHistory.getIotCardId(), System.currentTimeMillis() - beginTime); } catch (Exception e) { historyList.clear(); log.error(\"IotCardHistoryBatchInsert onMessage error:{}\", e); } finally { //告诉服务器收到这条消息 已经被我消费了 可以在队列删掉 这样以后就不会再发了 否则消息服务器以为这条消息没处理掉 后续还会在发 //手动应答消息　　第一个参数是所确认消息的标识，第二参数是是否批量确认 try { channel.basicAck(message2.getMessageProperties().getDeliveryTag(), false); } catch (IOException e) { log.error(\"basicAck异常:{}\", e); } } } SpringBoot2.x下RabbitMQ的并发参数（concurrency和prefetch） https://www.cnblogs.com/dolphin0520/p/3933551.html Java ConcurrentModificationException异常原因和解决方法 "},"micro-service/rabbitmq/rabbitmq学习.html":{"url":"micro-service/rabbitmq/rabbitmq学习.html","title":"rabbitmq学习","keywords":"","body":" rabbitmq channel参数详解 RabbitMQ的下载和安装 spring.rabbitmq.publisher-confirms过时解决 rabbitmq：publisher confirms发送消息确认扩展 spring.rabbitmq.publisher-confirm-type详解 Spring Boot系列(8)——RabbitMQ确认、退回模式及死信队列——RabbitMQ确认、退回模式及死信队列) RabbitMQ（四）消息Ack确认机制 Concurrency与Prefetch参数\\RabbitMQ消费者的几个参数 消费RabbitMQ时的注意事项，如何禁止大量的消息涌到Consumer rabbitMq消费者如何设置同时处理的消息数？ node 使用 amqplib 库连接 rabbitMq，消费者采用需要手动ack方式。最近消息生产速度越来越快，消费者已经吃满cpu了，rabbitMq只要有消息就会马上发给消费者处理，如何才能让rabbitmq一次只给每个消费者几条消息，每ack一条消息再发一条呢？ 如何才能让rabbitmq一次只给每个消费者几条消息 消费消息的两种方式 第一种是@RabbitListener注解， @RabbitListener(containerFactory = \"defaultRabbitContainerFactory\", bindings = @QueueBinding( exchange = @Exchange(value = QueueConstant.FLOWSYN_YDZG_GZ_EXCHANGE), value = @Queue(value = QueueConstant.FLOWSYN_YDZG_GZ_QUEUE, durable = \"false\"), key = QueueConstant.FLOWSYN_YDZG_GZ_ROUTINGKEY ), admin = RabbitMqCoreConfig.adminName, concurrency = \"1\", ackMode = \"MANUAL\") public void guangzhouListener(@Payload String message, Channel channel, Message message2) { ///log.info(\"消息数据：{}\", message); } 第二种是实现ChannelAwareMessageListener接口。 public class BillDetailsPushBackCus implements ChannelAwareMessageListener { @Override public void onMessage(Message message, Channel channel) throws Exception { try { String msg = new String(message.getBody(), \"utf-8\"); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); } catch (Exception e) { log.error(\":\", e); } } } com.rabbitmq.client.impl.recovery.AutorecoveringChannel#recoverState org.springframework.amqp.rabbit.listener.BlockingQueueConsumer#setQosAndreateConsumers ``` "},"micro-service/rabbitmq/rabbitmq延迟队列.html":{"url":"micro-service/rabbitmq/rabbitmq延迟队列.html","title":"rabbitmq延迟队列","keywords":"","body":" 安装和启动插件 切换到/d/Program Files/RabbitMQ Server/rabbitmq_server-3.8.9/sbin下 hoby@LAPTOP-6VJBADD9 MINGW64 /d/Program Files/RabbitMQ Server/rabbitmq_server-3.8.9/sbin $ rabbitmq-plugins.bat list Listing plugins with pattern \".*\" ... Configured: E = explicitly enabled; e = implicitly enabled | Status: * = running on rabbit@LAPTOP-6VJBADD9 |/ [ ] rabbitmq_amqp1_0 3.8.9 [ ] rabbitmq_auth_backend_cache 3.8.9 [ ] rabbitmq_auth_backend_http 3.8.9 [ ] rabbitmq_auth_backend_ldap 3.8.9 [ ] rabbitmq_auth_backend_oauth2 3.8.9 [ ] rabbitmq_auth_mechanism_ssl 3.8.9 [ ] rabbitmq_consistent_hash_exchange 3.8.9 [E*] rabbitmq_delayed_message_exchange 3.8.9.0199d11c [ ] rabbitmq_event_exchange 3.8.9 [ ] rabbitmq_federation 3.8.9 [ ] rabbitmq_federation_management 3.8.9 [ ] rabbitmq_jms_topic_exchange 3.8.9 [E*] rabbitmq_management 3.8.9 [e*] rabbitmq_management_agent 3.8.9 [ ] rabbitmq_mqtt 3.8.9 [ ] rabbitmq_peer_discovery_aws 3.8.9 [ ] rabbitmq_peer_discovery_common 3.8.9 [ ] rabbitmq_peer_discovery_consul 3.8.9 [ ] rabbitmq_peer_discovery_etcd 3.8.9 [ ] rabbitmq_peer_discovery_k8s 3.8.9 [ ] rabbitmq_prometheus 3.8.9 [ ] rabbitmq_random_exchange 3.8.9 [ ] rabbitmq_recent_history_exchange 3.8.9 [ ] rabbitmq_sharding 3.8.9 [ ] rabbitmq_shovel 3.8.9 [ ] rabbitmq_shovel_management 3.8.9 [ ] rabbitmq_stomp 3.8.9 [ ] rabbitmq_top 3.8.9 [ ] rabbitmq_tracing 3.8.9 [ ] rabbitmq_trust_store 3.8.9 [e*] rabbitmq_web_dispatch 3.8.9 [ ] rabbitmq_web_mqtt 3.8.9 [ ] rabbitmq_web_mqtt_examples 3.8.9 [ ] rabbitmq_web_stomp 3.8.9 [ ] rabbitmq_web_stomp_examples 3.8.9 定义队列和交换机 package com.fzs.iotcard.business.mq.consumer; import com.fzs.iotcard.common.business.constant.CommonConstant; import org.springframework.amqp.core.Binding; import org.springframework.amqp.core.BindingBuilder; import org.springframework.amqp.core.CustomExchange; import org.springframework.amqp.core.Queue; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import java.util.HashMap; import java.util.Map; @Configuration public class SmsTaskDelayConfig { // 创建一个立即消费队列 @Bean public Queue immediateQueue() { // 第一个参数是创建的queue的名字，第二个参数是是否支持持久化 return new Queue(CommonConstant.SMS_TASK_QUEUE, true); } @Bean public CustomExchange delayExchange() { Map args = new HashMap(); args.put(\"x-delayed-type\", \"direct\"); return new CustomExchange(CommonConstant.SMS_TASK_EXCHANGE, \"x-delayed-message\", true, false, args); } @Bean public Binding bindingNotify() { return BindingBuilder.bind(immediateQueue()).to(delayExchange()).with(CommonConstant.SMS_TASK_ROUTINGKEY).noargs(); } } 消费者 @RabbitListener(queues = CommonConstant.SMS_TASK_QUEUE) public void smsTask(@Payload String message, Channel channel, Message message2) { try { String taskNo = message; if (StringUtils.hasText(taskNo)) { businessSmsTaskRecordService.dealSmsOrder(taskNo); } else { log.info(\"taskNo为空\"); } } catch (Exception e) { log.error(\"exception queue message:\", e); throw new AmqpRejectAndDontRequeueException(e); } finally { try { channel.basicAck(message2.getMessageProperties().getDeliveryTag(), false); } catch (IOException e) { log.error(\"basicAck异常:{}\", e); } } } 注意用消费者的注解老是报错，弄不了，如下 Caused by: com.rabbitmq.client.ShutdownSignalException: connection error; protocol method: #method(reply-code=503, reply-text=COMMAND_INVALID - invalid exchange type 'x-delayed-message', class-id=40, method-id=10) at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:66) at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:36) at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:505) at com.rabbitmq.client.impl.AMQChannel.privateRpc(AMQChannel.java:296) at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:144) ... 33 common frames omitted 2024-02-26 16:59:15.467 ERROR 25040 --- [ 127.0.0.1:5672] o.s.a.r.c.CachingConnectionFactory : Shutdown Signal: channel error; protocol method: #method(reply-code=406, reply-text=PRECONDITION_FAILED - Invalid argument, 'x-delayed-message' can't be used for 'x-delayed-type', class-id=40, method-id=10) 参考： https://blog.csdn.net/qq_41293765/article/details/125506964 https://blog.csdn.net/wootengxjj/article/details/87871398 https://www.cnblogs.com/walkingcamel/p/13525026.html https://www.jianshu.com/p/04e414d1ae97 https://blog.csdn.net/wootengxjj/article/details/87871398 https://blog.csdn.net/zhangyuxuan2/article/details/82986802 ``` "},"micro-service/redis/批量删除redis.html":{"url":"micro-service/redis/批量删除redis.html","title":"批量删除redis","keywords":"","body":" REDIS 批量删除命令说明 ``` "},"micro-service/springboot/springboot多环境配置.html":{"url":"micro-service/springboot/springboot多环境配置.html","title":"springboot多环境配置","keywords":"","body":" springboot-profiles 多环境配置整合避坑（保姆级入门） ``` "},"micro-service/springboot/springBoot接口防抖防重复提交.html":{"url":"micro-service/springboot/springBoot接口防抖防重复提交.html","title":"springBoot接口防抖防重复提交","keywords":"","body":" SpringBoot接口防抖(防重复提交)的一些实现方案 ``` "},"micro-service/springboot/springboot整合hikari数据源.html":{"url":"micro-service/springboot/springboot整合hikari数据源.html","title":"springboot整合hikari数据源","keywords":"","body":" 缺少hikari相关配置问题 刚开始配置数据源是下面这样，hikari相关的没配置,其他也没配置 spring.datasource.driver-class-name=oracle.jdbc.driver.OracleDriver spring.datasource.url = jdbc:oracle:thin:@ (DESCRIPTION =(ADDRESS = (PROTOCOL = TCP)(HOST = 10.20.100.63)(PORT = 1521))(CONNECT_DATA =(SERVER = DEDICATED)(SERVICE_NAME = fzsdbdev))) spring.datasource.username = UIOTSYSTEM_DEV spring.datasource.password = fzs123321 然后同事发现偶尔出现下面错误： Invalid Operation, NOT Connected). Possibly consider using a shorter maxLifetime value 数据源自动装配分析 org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration org.springframework.boot.autoconfigure.jdbc.DataSourceConfiguration.Hikari @Configuration(proxyBeanMethods = false) @ConditionalOnClass(HikariDataSource.class) @ConditionalOnMissingBean(DataSource.class) @ConditionalOnProperty(name = \"spring.datasource.type\", havingValue = \"com.zaxxer.hikari.HikariDataSource\", matchIfMissing = true) static class Hikari { @Bean @ConfigurationProperties(prefix = \"spring.datasource.hikari\") HikariDataSource dataSource(DataSourceProperties properties) { HikariDataSource dataSource = createDataSource(properties, HikariDataSource.class); if (StringUtils.hasText(properties.getName())) { dataSource.setPoolName(properties.getName()); } return dataSource; } } com.zaxxer.hikari.HikariConfig SpringBoot：关于默认连接池Hikari的源码剖析 Hikari 数据库连接池配置详解 ``` "},"micro-service/springboot/springboot整合log4j打印mybatis的sql日志.html":{"url":"micro-service/springboot/springboot整合log4j打印mybatis的sql日志.html","title":"springboot整合log4j打印mybatis的sql日志","keywords":"","body":" pom文件中假如依赖 org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-logging org.springframework.boot spring-boot-starter-log4j 1.3.8.RELEASE 在application.yml中配置mybatis输出日志： yml mybatis: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl property #mybatis.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl mybatis.configuration.log-impl=org.apache.ibatis.logging.log4j.Log4jImpl 上面2个StdOutImpl和Log4jImpl选其中一个就可以 配置扫描的包路径，不配置打印不了 logging.level.com.fzs.iotcard.common.business.mapper=DEBUG 参考： SpringBoot+MyBatis如何配置log4j日志输出（sql） "},"micro-service/springboot/springboot整合redisTemplate.html":{"url":"micro-service/springboot/springboot整合redisTemplate.html","title":"springboot整合redisTemplate","keywords":"","body":" import com.fasterxml.jackson.annotation.JsonAutoDetect; import com.fasterxml.jackson.annotation.PropertyAccessor; import com.fasterxml.jackson.databind.ObjectMapper; import com.fasterxml.jackson.databind.jsontype.impl.LaissezFaireSubTypeValidator; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.RedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; @Configuration public class RedisTemplateConfig { /** * redisTemplate 默认序列化使用的 jdkSerializeable, 存储二进制字节码, 所以一般需要自定义序列化类 * https://www.cnblogs.com/puzhiwei/p/12519304.html * @return */ @Bean public RedisTemplate redisTemplateSerializer(LettuceConnectionFactory lettuceConnectionFactory) { // 设置序列化 Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper objectMapper = new ObjectMapper(); // 指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和public objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer等会跑出异常 objectMapper.activateDefaultTyping(LaissezFaireSubTypeValidator.instance, ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); RedisSerializer stringSerializer = new StringRedisSerializer(); // 配置redisTemplate RedisTemplate redisTemplate = new RedisTemplate(); redisTemplate.setConnectionFactory(lettuceConnectionFactory); // key序列化 redisTemplate.setKeySerializer(stringSerializer); // value序列化 redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); // Hash key序列化 redisTemplate.setHashKeySerializer(stringSerializer); // Hash value序列化 redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; } } 参考： https://www.cnblogs.com/puzhiwei/p/12519304.html "},"python/python入门.html":{"url":"python/python入门.html","title":"python入门","keywords":"","body":" Window CMD 中运行python 显示乱码问题解决办法 在CMD窗中输入 chcp 65001 后，直接运行Python文件就不会显示乱码了。 windows下安装python 且 安装pip https://www.cnblogs.com/baiyuer/p/9606773.html 安装pip 下载地址是：https://pypi.org/project/pip/#files 1、下载完成之后，解压到一个文件夹，用CMD控制台进入解压文件的目录 （目录中不要包含汉字。放到比较好找的位置）2、然后，在文件目录下，输入： python setup.py install 3、安装好之后，我们直接在命令行输入pip，同样会显示‘pip’不是内部命令，也不是可运行的程序。因为我们还没有添加环境变量。4、按照之前介绍的添加环境变量的方法，我们在PATH最后添加：（添加变量的时候，g用“;”英文分号的分号隔开） D:\\Program Files\\python27\\Scripts 到现在我们才算完整安装好了pip 注：上面添加pip到环境变量是安装pip命令python setup.py install 时从打印的日志里看的 removing 'build\\bdist.win32\\egg' (and everything under it) Processing pip-20.3.3-py2.7.egg removing 'd:\\program files\\python27\\lib\\site-packages\\pip-20.3.3-py2.7.egg' (and everything under it) creating d:\\program files\\python27\\lib\\site-packages\\pip-20.3.3-py2.7.egg Extracting pip-20.3.3-py2.7.egg to d:\\program files\\python27\\lib\\site-packages pip 20.3.3 is already the active version in easy-install.pth Installing pip-script.py script to D:\\Program Files\\python27\\Scripts Installing pip.exe script to D:\\Program Files\\python27\\Scripts Installing pip.exe.manifest script to D:\\Program Files\\python27\\Scripts Installing pip2.7-script.py script to D:\\Program Files\\python27\\Scripts Installing pip2.7.exe script to D:\\Program Files\\python27\\Scripts Installing pip2.7.exe.manifest script to D:\\Program Files\\python27\\Scripts Installing pip2-script.py script to D:\\Program Files\\python27\\Scripts Installing pip2.exe script to D:\\Program Files\\python27\\Scripts Installing pip2.exe.manifest script to D:\\Program Files\\python27\\Scripts Installed d:\\program files\\python27\\lib\\site-packages\\pip-20.3.3-py2.7.egg Processing dependencies for pip==20.3.3 Finished processing dependencies for pip==20.3.3 hoby@LAPTOP-6VJBADD9 MINGW64 /d/Program Files/pip-20.3.3 如何利用Intellij Idea搭建python编译运行环境 https://blog.csdn.net/qq_38188725/article/details/80623710 无法打开.xlsx文件，xlrd.biffh.XLRDError: Excel xlsx file； not supported https://blog.csdn.net/weixin_44073728/article/details/111054157 ``` "},"python/python小牛试刀-获取微信关注用户信息.html":{"url":"python/python小牛试刀-获取微信关注用户信息.html","title":"python小牛试刀-获取微信关注用户信息","keywords":"","body":" 本文内容介绍：1、背景和需求2、解决思路3、解决语言4、python-requests和python-redis5、获取关注公众号的所有用户的openid6、根据openid获取用户详细的用户信息7、总结 1、背景和需求   现在要统计还有多少用户关注橙医生,导出微信上用户的基本信息和注册信息，但是存在以下问题：1、数据库现在只记录用户关注的记录，没有记录用户取消关注的记录，2、用户基本信息比如所在地区和用户年龄没有记录到数据库中，需要调用微信api去重新获取3、导出关注记录的时候，同时要导出该用户的基本注册信息 2、解决思路 1、从数据库导出现在所有关注过的记录(openid),现在统计到有80多万记录2、调用微信api获取现在所有关注的记录(openid)，统计到有50万条记录3、将步骤2中获取到openid，先调用微信api去获取所有用户具体的基本用户信息4、对比数据库中的openid和步骤3获取到的用户信息中的openid，然后查询数据库查询出该用户的注册信息,导出到excel，完。 3、解决语言 打算用python，因为python是脚本语言，方便对导出数据进行处理，同时还由于调用微信api需要access_token，而这个token在我们服务器由其他java项目生成的，放在redis里面。 4、python-requests和python-redis基础模块知识 python-requests模块 先下载安装 git clone git://github.com/kennethreitz/requests.git python setup.py install 导入Requests模块,发起get请求,响应文本内容用r.text获取,若要变成json，直接 r.json()即可 import requests r = requests.get('https://github.com/timeline.json') d=r.json() python-redis模块 编译安装： wget https://pypi.python.org/packages/source/r/redis/redis-2.9.1.tar.gz tar xvzf redis-2.9.1.tar.gz cd redis-2.9.1 python setup.py install 用法： import redis r=redis.Redis(host='localhost',port=6379,db=0,password='密码') token=r.get('wxtoken:PATIENT_TOKEN') 5、获取关注我们公众号的所有用户的openid 详细代码如下：涉及调用微信api，还有从redis里面获取token等知识 #! /usr/bin/python # encoding=utf-8 import requests import demjson import json import sys reload(sys) sys.setdefaultencoding( \"utf-8\" ) import time import socket import redis import traceback token='your token' baseurl='http://api.weixin.qq.com/cgi-bin/user/get?access_token=' redis_host='your redis_host' redis_password='your redis_password' #调用微信api获取关注的所有openid函数 def getFollowOpenids( baseurl , token ,nextopenid): if nextopenid: geturl=baseurl + token + '&next_openid='+nextopenid else: geturl=baseurl + token print \"geturl=%s\"%(geturl) r=requests.get(geturl,timeout=10) d=r.json() return d #获取redis里面的微信access_token def getToken(): r=redis.Redis(host=redis_host,port=6379,db=0,password=redis_password) token=r.get('wxtoken:PATIENT_TOKEN') while not token: print \"再次取到的token是空的token=%s\"%token time.sleep(30) token=getToken() return token fo=open(\"wx-openid.csv\",\"a+\"); def writeToCsv( d ): for x in d['data']['openid']: fo.write(\"%s\\n\"%x) token=getToken() nextopenid='' d=getFollowOpenids( baseurl , token ,nextopenid ) #将第一次获取到的所有关注记录写入wx-openid.csv文件中 writeToCsv( d ) #获取下一次调用需要开始的nextopenid nextopenid=d['next_openid'] print \"第一次获取到的nextopenid=%s\"%nextopenid #统计需要调用多少次微信api，打印所有的记录数 total_time=d['total']/10000 print \"total_time=%s,total=%d\"%(total_time,d['total']) #循环调用微信api去获取关注的openid while total_time > 0: d=getFollowOpenids( baseurl , token ,nextopenid ) writeToCsv( d ) nextopenid=d['next_openid'] print \"获取到下次next_openid=%s\"%nextopenid total_time=total_time-1 print \"\\n\" fo.close(); 6、根据openid获取用户详细的用户信息 #! /usr/bin/python # encoding=utf-8 import requests import demjson import json import sys reload(sys) sys.setdefaultencoding( \"utf-8\" ) import time import socket import redis import traceback token='your token' baseurl='http://api.weixin.qq.com/cgi-bin/user/info?access_token=' redis_host='your redis_host' redis_password='your redis_password' def getUserInfo( baseurl , token ,openid ): geturl=baseurl + token+'&openid='+openid r=requests.get(geturl,timeout=10) d=r.json() print r.text return d def getToken(): r=redis.Redis(host=redis_host,port=6379,db=0,password=redis_password) token=r.get('wxtoken:PATIENT_TOKEN') while not token: print \"再次取到的token是空的token=%s\"%token time.sleep(30) token=getToken() return token fo=open(\"common-userinfo.csv\",\"wb\"); with open(\"wx-openid.csv\",\"r\") as wxf: for strs in wxf.readlines(): try: d=getUserInfo(baseurl,token,strs.strip()) if 'errcode' in d and d['errcode']==42001: print \"token=%s过期了\"%token token=getToken() print \"新token=%s\"%token d=getUserInfo(baseurl,token,strs.strip()) if d['subscribe']==1: subtime=d['subscribe_time'] timeArray=time.localtime(subtime) otherStyleTime=time.strftime(\"%Y-%m-%d %H:%M-%S\",timeArray) info=d['openid']+\",\"+d['nickname']+\",\"+otherStyleTime+\",\"+d['city']+\",\"+str(d['sex'])+\"\\n\" else: info=strs.strip()+\",,,,\" fo.write(info) except: info=sys.exc_info() print info[0],\":\",info[1] traceback.print_exc(file=sys.stdout) print \"异常json:%s\"%strs #pass fo.close(); 7、总结   上面的python代码都是刚学刚用的，由于时间比较匆忙，需要及时完成需求，所以上面代码还没进行很好封装，后面连接数据库查询注册信息方面的也没写。本文只提供获取微信关注用户信息的例子参考，如有问题，可联系我。可参考的知识链接：1、python连接redishttp://debugo.com/python-redis/2、http请求框架python-requestshttp://docs.python-requests.org/zh_CN/latest/user/quickstart.html "}}